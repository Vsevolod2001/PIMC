{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbee9da4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T14:57:07.548155Z",
     "iopub.status.busy": "2024-03-24T14:57:07.547352Z",
     "iopub.status.idle": "2024-03-24T14:57:07.563389Z",
     "shell.execute_reply": "2024-03-24T14:57:07.562313Z",
     "shell.execute_reply.started": "2024-03-24T14:57:07.548106Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Callable, List, Tuple\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.distributions.distribution import Distribution\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c93eb4f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T14:57:08.938550Z",
     "iopub.status.busy": "2024-03-24T14:57:08.937614Z",
     "iopub.status.idle": "2024-03-24T14:57:09.209096Z",
     "shell.execute_reply": "2024-03-24T14:57:09.207354Z",
     "shell.execute_reply.started": "2024-03-24T14:57:08.938514Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "from NFconstants import N_nod, Beta, a\n",
    "from NFandist import get_O\n",
    "from NFandist import get_diag\n",
    "from NFandist import get_C\n",
    "\n",
    "def set_random_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "O=(torch.tensor(get_O(N_nod)).float()).to(device)\n",
    "Ot=(torch.t(O)).to(device)\n",
    "print(Ot.requires_grad)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4850dcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThetaNetwork(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_dim: int,\n",
    "        out_dim: int,\n",
    "        num_hidden: int,\n",
    "        hidden_dim: int,\n",
    "        num_params: int,\n",
    "        p_drop: float,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.input = nn.Linear(in_dim, hidden_dim)\n",
    "        self.hidden = nn.ModuleList(\n",
    "            [nn.Sequential(\n",
    "                nn.Linear(hidden_dim, hidden_dim),\n",
    "                nn.Dropout(p=p_drop),\n",
    "                nn.LayerNorm(hidden_dim)\n",
    "            ) for _ in range(num_hidden)]\n",
    "        )\n",
    "\n",
    "        self.num_params = num_params\n",
    "        self.out_dim = out_dim\n",
    "        self.dims = nn.Linear(hidden_dim, out_dim * num_params)\n",
    "        \n",
    "    def configure_theta(num_hidden,hidden_dim,p_drop,in_dim=N_nod//2,out_dim=N_nod//2):\n",
    "        theta=ThetaNetwork(\n",
    "                in_dim = in_dim,\n",
    "                out_dim = out_dim,\n",
    "                num_hidden = num_hidden,  #2 to 6\n",
    "                hidden_dim = hidden_dim , #100-1024\n",
    "                num_params = 2,\n",
    "                p_drop=p_drop,\n",
    "        )\n",
    "        return theta    \n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = torch.reshape(x,(x.shape[0],x.shape[1]*x.shape[2]))\n",
    "        x = F.leaky_relu(self.input(x),negative_slope=0.01)\n",
    "        for h in self.hidden:\n",
    "            x = F.leaky_relu(h(x),negative_slope=0.01)\n",
    "\n",
    "        batch_params = self.dims(x).reshape(x.size(0), self.out_dim, -1) \n",
    "        params = batch_params.chunk(self.num_params, dim=-1) \n",
    "        return [p.squeeze(-1) for p in params]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0df8632a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 64])\n"
     ]
    }
   ],
   "source": [
    "N_samp = 100\n",
    "DIM=4\n",
    "theta = ThetaNetwork.configure_theta(5,hidden_dim=DIM*N_nod,p_drop=0,in_dim=(DIM//2)*N_nod,out_dim=N_nod)\n",
    "x =  torch.normal(mean=torch.zeros(N_samp,N_nod//2,DIM), std=torch.ones(N_samp,N_nod//2,DIM))\n",
    "y = theta(x)\n",
    "print(y[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b66bc606",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T14:57:09.373621Z",
     "iopub.status.busy": "2024-03-24T14:57:09.372589Z",
     "iopub.status.idle": "2024-03-24T14:57:09.390240Z",
     "shell.execute_reply": "2024-03-24T14:57:09.389240Z",
     "shell.execute_reply.started": "2024-03-24T14:57:09.373569Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AffineCouplingLayer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        theta: nn.Module,\n",
    "        split,\n",
    "        swap: int\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.theta = theta\n",
    "        self.split = split\n",
    "        self.swap = swap\n",
    "\n",
    "    def g(self, z: torch.Tensor,params=torch.tensor([])) -> torch.Tensor:\n",
    "        \"\"\"g : z -> x. The inverse of f.\"\"\"\n",
    "        mask1=self.split[self.swap]\n",
    "        mask2=self.split[(self.swap+1)%2]\n",
    "        z1, z2 = z[:,mask1,:], z[:,mask2,:]\n",
    "        z1 = torch.cat((z1,params),dim=1)\n",
    "        t, s = self.theta(z1)\n",
    "        x2 = z2 * torch.exp(s) + t\n",
    "        log_det = s.sum(-1) \n",
    "        z[:,mask2]=x2\n",
    "        return z, log_det\n",
    "\n",
    "    def f(self, x: torch.Tensor,params=torch.tensor([])) -> torch.Tensor:\n",
    "        mask1=self.split[self.swap]\n",
    "        mask2=self.split[(self.swap+1)%2]\n",
    "        x1, x2 = x[:,mask1], x[:,mask2]\n",
    "        x1 = torch.cat((x1,params),dim=-1)\n",
    "        t, s = self.theta(x1)\n",
    "        z1, z2 = x1, torch.exp(-s)*(x2-t) \n",
    "        log_det = s.sum(-1) \n",
    "        x[:,mask2] = z2\n",
    "        return x, log_det    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e117795",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split_masks(dim=N_nod):\n",
    "    mask1=list(range(0,dim,2))\n",
    "    mask2=list(range(1,dim,2))\n",
    "    split_masks=[mask1,mask2]\n",
    "    return split_masks\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "978ab07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pair_split_masks(dim=N_nod):\n",
    "    mask1=list(range(0,dim,4))\n",
    "    mask2=list(range(2,dim,4))\n",
    "    mask1=(mask1+list(map(lambda x:x+1,mask1)))\n",
    "    mask2=(mask2+list(map(lambda x:x+1,mask2)))\n",
    "    mask1.sort()\n",
    "    mask2.sort()\n",
    "    split_masks=[mask1,mask2]\n",
    "    return split_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f17f095c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T14:57:11.579784Z",
     "iopub.status.busy": "2024-03-24T14:57:11.578684Z",
     "iopub.status.idle": "2024-03-24T14:57:11.604072Z",
     "shell.execute_reply": "2024-03-24T14:57:11.602987Z",
     "shell.execute_reply.started": "2024-03-24T14:57:11.579709Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    def g_steps(self, z: torch.Tensor) -> List[torch.Tensor]:\\n        Maps latent variable z to observation x\\n        and stores intermediate results.\\n        \\n        xs = [z]\\n        for flow in reversed(self.flows):\\n            xs.append(flow.g(xs[-1]))\\n        return xs\\n\\n    \\n    def latent_log_prob(self, z: torch.Tensor) -> torch.Tensor:\\n        llp=self.latent.log_prob(z)\\n        sum_llp= torch.sum(llp,axis=-1)\\n        return sum_llp\\n \\n    \\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NormalizingFlow(nn.Module):\n",
    "    \n",
    "    def __init__(self, latent: Distribution, flows: List[nn.Module], conv_flows = [], ort=False):\n",
    "        super().__init__()\n",
    "        self.latent = latent\n",
    "        self.flows = flows\n",
    "        self.ort = ort\n",
    "        self.conv_flows = conv_flows\n",
    "        \n",
    "    def configure_flows(n_flows,num_hidden,hidden_dim,p_drop,dim=N_nod,param_dim=0):  # n_flows=8,...,12\n",
    "        flows = []\n",
    "        split_masks_d = get_pair_split_masks(dim)\n",
    "        #split_masks_d = get_split_masks(dim)\n",
    "    \n",
    "        for k in range(n_flows):\n",
    "            theta = ThetaNetwork.configure_theta( num_hidden = num_hidden, hidden_dim = hidden_dim, p_drop=p_drop ,in_dim = dim//2+param_dim,out_dim = dim//2)\n",
    "            flows.append(AffineCouplingLayer(theta,split=split_masks_d,swap=k%2))\n",
    "   \n",
    "        flows = nn.ModuleList(flows)\n",
    "        return flows     \n",
    "\n",
    "    def latent_sample(self, num_samples: int = 1) -> torch.Tensor:\n",
    "        z=self.latent.sample((num_samples,))\n",
    "        return z        \n",
    "\n",
    "    def sample(self, num_samples: int = 1) -> torch.Tensor:\n",
    "        \"\"\"Sample a new observation x by sampling z from\n",
    "        the latent distribution and pass through g.\"\"\"\n",
    "        z=(self.latent_sample(num_samples))\n",
    "        with torch.no_grad():\n",
    "            x, _ = self.g(z)\n",
    "        return x \n",
    "    \n",
    "\n",
    "    def g(self, z: torch.Tensor,params=torch.tensor([])) -> torch.Tensor:\n",
    "        \n",
    "        x, sum_log_abs_det = z, torch.zeros(z.size(0)).to(z.device)\n",
    "        for flow in reversed(self.flows):\n",
    "            x, log_abs_det = flow.g(x,params)\n",
    "            sum_log_abs_det += log_abs_det\n",
    "        \n",
    "        if self.ort:\n",
    "            x=torch.matmul(x,Ot.to(x.device))\n",
    "          \n",
    "        \n",
    "        for flow in reversed(self.conv_flows):\n",
    "            x, log_abs_det = flow.g(x)\n",
    "            sum_log_abs_det += log_abs_det\n",
    "        return x, sum_log_abs_det\n",
    "    \n",
    "        \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.flows)\n",
    "    \n",
    "    def f(self, x: torch.Tensor,params=torch.tensor([])) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            if self.ort:\n",
    "                x=torch.matmul(x,O.to(x.device))\n",
    "        \n",
    "            z, sum_log_abs_det = x, torch.zeros(x.size(0)).to(x.device)\n",
    "        \n",
    "            for flow in self.flows:\n",
    "                z, log_abs_det = flow.f(z,params)\n",
    "                sum_log_abs_det += log_abs_det\n",
    "        \n",
    "        return z, sum_log_abs_det\n",
    "    \n",
    " \n",
    "\"\"\"\n",
    "    def g_steps(self, z: torch.Tensor) -> List[torch.Tensor]:\n",
    "        Maps latent variable z to observation x\n",
    "        and stores intermediate results.\n",
    "        \n",
    "        xs = [z]\n",
    "        for flow in reversed(self.flows):\n",
    "            xs.append(flow.g(xs[-1]))\n",
    "        return xs\n",
    "\n",
    "    \n",
    "    def latent_log_prob(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        llp=self.latent.log_prob(z)\n",
    "        sum_llp= torch.sum(llp,axis=-1)\n",
    "        return sum_llp\n",
    " \n",
    "    \n",
    "\"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe44d6d8-c33a-47b3-b43f-fe4b44072701",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T14:57:14.121776Z",
     "iopub.status.busy": "2024-03-24T14:57:14.120696Z",
     "iopub.status.idle": "2024-03-24T14:57:14.136257Z",
     "shell.execute_reply": "2024-03-24T14:57:14.135247Z",
     "shell.execute_reply.started": "2024-03-24T14:57:14.121728Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from Data import normal_dist\n",
    "\n",
    "def configure_theta():\n",
    "    theta=ThetaNetwork(\n",
    "                in_dim = N_nod//2,\n",
    "                out_dim = N_nod//2,\n",
    "                num_hidden = 16,  #2 to 6\n",
    "                hidden_dim = 2 * N_nod , #100-1024\n",
    "                num_params = 2,\n",
    "                p_drop=0.0,\n",
    "    )\n",
    "    return theta\n",
    "\n",
    "def configure_flows(n_flows):  # n_flows=8,...,12\n",
    "    flows=[]\n",
    "    \n",
    "    #flows.append(CubicCouplingLayer(configure_theta(),split=pair_SplitFunc,swap=0))\n",
    "    #flows.append(CubicCouplingLayer(configure_theta(),split=pair_SplitFunc,swap=1))\n",
    "    \n",
    "    flows.append(D(N_nod))\n",
    "\n",
    "    for k in range(n_flows):\n",
    "        flows.append(AffineCouplingLayer(configure_theta(),split=pair_SplitFunc,swap=k%2))\n",
    "\n",
    "\n",
    "    flows = nn.ModuleList(flows)\n",
    "    return flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5401fb59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T14:57:14.564738Z",
     "iopub.status.busy": "2024-03-24T14:57:14.563712Z",
     "iopub.status.idle": "2024-03-24T14:57:14.583112Z",
     "shell.execute_reply": "2024-03-24T14:57:14.581963Z",
     "shell.execute_reply.started": "2024-03-24T14:57:14.564692Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Pipeline(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        criterion,\n",
    "        optimizer_class=torch.optim.Adam,\n",
    "        optimizer_kwargs={\"lr\": 0.001,\"weight_decay\": 0}\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.loss = criterion\n",
    "        self.optimizer_class = optimizer_class\n",
    "        self.optimizer_kwargs = optimizer_kwargs\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = self.optimizer_class(\n",
    "            self.model.parameters(), **self.optimizer_kwargs\n",
    "        )\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        z = batch\n",
    "        x, log_abs_det = self.model.g(z)\n",
    "        loss = self.loss(x,log_abs_det)\n",
    "        self.log('train_loss', loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        #print(\"---------------------------end epoch---------------------------------\")\n",
    "        pass\n",
    "    \n",
    "    def on_validation_end(self) -> None:\n",
    "        if not self.automatic_optimization:\n",
    "            # Save a checkpoint of the model\n",
    "            ckpt_path = os.path.join(self.trainer.log_dir, 'checkpoints', 'ckpt.pt')\n",
    "            self.trainer.save_checkpoint(ckpt_path, weights_only=True)\n",
    "        return super().on_validation_end()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3857c540-6428-46f4-ac0a-31aa76f83ad2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T15:05:51.472691Z",
     "iopub.status.busy": "2024-03-24T15:05:51.471541Z",
     "iopub.status.idle": "2024-03-24T15:05:51.494113Z",
     "shell.execute_reply": "2024-03-24T15:05:51.492968Z",
     "shell.execute_reply.started": "2024-03-24T15:05:51.472640Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from NFoscillator import Oscillator\n",
    "from NFrel_oscillator import Rel_Oscillator\n",
    "from NFur_oscillator import Ur_Oscillator\n",
    "from NFx4 import X4\n",
    "from NFMorse import Morse\n",
    "from NFrel_Morse import Rel_Morse\n",
    "from NFrel_Columb import Rel_Columb\n",
    "from NFnonrel_Columb import NonRel_Columb\n",
    "from NFbadur_oscillator import BadUr_Oscillator\n",
    "from NFtwowells import Two_wells\n",
    "from NFcircle import Circle\n",
    "from NFrel_twowells import Rel_two_wells \n",
    "\n",
    "osc=Oscillator(N_nod,Beta)\n",
    "KL_osc=osc.get_KL()\n",
    "\n",
    "rel1=Rel_Oscillator(N_nod,Beta,sigma=1)\n",
    "KL_rel1=rel1.get_KL()\n",
    "\n",
    "ur=Ur_Oscillator(N_nod,Beta)\n",
    "KL_ur=ur.get_KL()\n",
    "\n",
    "rel_columb=Rel_Columb(N_nod,Beta,alpha=1,R=1)\n",
    "KL_rel_columb=rel_columb.get_KL()\n",
    "\n",
    "tw = Two_wells(N_nod,Beta,g=1,x0=1.41)\n",
    "KL_tw = tw.get_KL()\n",
    "\n",
    "\n",
    "morse = Morse(N_nod,Beta,alpha=0.125)\n",
    "KL_morse = morse.get_KL()\n",
    "\n",
    "circ = Circle(N_nod,Beta,g=1,x0=4)\n",
    "KL_circ = circ.get_KL()\n",
    "\n",
    "rel_morse = Rel_Morse(N_nod,Beta,m=1,alpha=0.125)\n",
    "KL_rel_morse = rel_morse.get_KL()\n",
    "\n",
    "rel_tw = Rel_two_wells(N_nod,Beta,m=1,g=1,x0=1.41)\n",
    "KL_rel_tw = rel_tw.get_KL()\n",
    "\n",
    "KL_rel001=Rel_Oscillator(N_nod,Beta,sigma=0.01).get_KL()\n",
    "KL_rel01=Rel_Oscillator(N_nod,Beta,sigma=0.1).get_KL()\n",
    "KL_rel10=Rel_Oscillator(N_nod,Beta,sigma=10).get_KL()\n",
    "KL_rel29=Rel_Oscillator(N_nod,Beta,sigma = 2 ** 9).get_KL()\n",
    "KL_X4=X4(N_nod,Beta,g=0.05).get_KL()\n",
    "KL_rel_morse=Rel_Morse(N_nod,Beta,alpha=1,m=1000).get_KL()\n",
    "KL_nonrel_columb=NonRel_Columb(N_nod,Beta,alpha=1,R=1).get_KL()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1a57e465-dbf6-4418-b2c3-176c57510c63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T14:59:13.865906Z",
     "iopub.status.busy": "2024-03-24T14:59:13.864964Z",
     "iopub.status.idle": "2024-03-24T14:59:13.882117Z",
     "shell.execute_reply": "2024-03-24T14:59:13.880737Z",
     "shell.execute_reply.started": "2024-03-24T14:59:13.865852Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    }
   ],
   "source": [
    "print(Beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "558e4bef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T15:06:02.086235Z",
     "iopub.status.busy": "2024-03-24T15:06:02.085298Z",
     "iopub.status.idle": "2024-03-24T15:12:42.593004Z",
     "shell.execute_reply": "2024-03-24T15:12:42.590791Z",
     "shell.execute_reply.started": "2024-03-24T15:06:02.086201Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type            | Params\n",
      "------------------------------------------\n",
      "0 | model | NormalizingFlow | 70.7 M\n",
      "1 | loss  | KL_with_S       | 0     \n",
      "------------------------------------------\n",
      "70.7 M    Trainable params\n",
      "0         Non-trainable params\n",
      "70.7 M    Total params\n",
      "282.641   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:  21%|██        | 54/256 [00:13<00:51,  3.92it/s, v_num=305, train_loss=-28.1] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    }
   ],
   "source": [
    "from Data import train_loader\n",
    "\n",
    "set_random_seed(42)\n",
    "\n",
    "nf=NormalizingFlow(latent=normal_dist,flows=configure_flows(16),conv_flows=configure_conv_flows(0,kernel_size=16),ort=True)\n",
    "pipeline=Pipeline(model=nf, criterion=KL_morse, optimizer_class=torch.optim.Adam, optimizer_kwargs={\"lr\": 0.0001,\"weight_decay\":0.0})\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=50,\n",
    "    logger=TensorBoardLogger(save_dir=f\"logs/nf\"),\n",
    "    num_sanity_val_steps=0,\n",
    "    log_every_n_steps=1,\n",
    "    accumulate_grad_batches=8\n",
    ")\n",
    "\n",
    "trainer.fit(model=pipeline, train_dataloaders=train_loader)\n",
    "torch.save(nf.state_dict(), \"model_weights1.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2315d7bd-3259-4b46-950d-64fbfd53aba1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-21T00:29:06.295137Z",
     "iopub.status.busy": "2024-03-21T00:29:06.294371Z",
     "iopub.status.idle": "2024-03-21T00:46:05.549715Z",
     "shell.execute_reply": "2024-03-21T00:46:05.548347Z",
     "shell.execute_reply.started": "2024-03-21T00:29:06.295089Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "2024-03-21 00:29:10.393767: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 00:29:11.639096: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-21 00:29:14.836232: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type            | Params\n",
      "------------------------------------------\n",
      "0 | model | NormalizingFlow | 15.5 M\n",
      "1 | loss  | KL_with_S       | 0     \n",
      "------------------------------------------\n",
      "15.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "15.5 M    Total params\n",
      "62.183    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 256/256 [00:50<00:00,  5.11it/s, v_num=273, train_loss=11.90]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 256/256 [00:50<00:00,  5.11it/s, v_num=273, train_loss=11.90]\n"
     ]
    }
   ],
   "source": [
    "from Data import train_loader\n",
    "\n",
    "set_random_seed(42)\n",
    "nf=NormalizingFlow(latent=normal_dist,flows=configure_flows(12),conv_flows=configure_conv_flows(0,kernel_size=16),ort=True)\n",
    "nf.load_state_dict(torch.load('model_weights1.pth'))\n",
    "pipeline=Pipeline(model=nf,criterion=KL_X4, optimizer_class=torch.optim.Adam,optimizer_kwargs={\"lr\": 0.00005,\"weight_decay\":0.0})\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=20,\n",
    "    logger=TensorBoardLogger(save_dir=f\"logs/nf\"),\n",
    "    num_sanity_val_steps=0,\n",
    "    log_every_n_steps=1,\n",
    "    enable_checkpointing=False,\n",
    "    accumulate_grad_batches=32\n",
    ")\n",
    "\n",
    "trainer.fit(model=pipeline, train_dataloaders=train_loader)\n",
    "torch.save(nf.state_dict(), \"model_weights3.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a808807a",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-24T15:14:05.745887614Z",
     "iopub.status.idle": "2024-03-24T15:14:05.748917542Z",
     "shell.execute_reply": "2024-03-24T15:14:05.745707886Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "Limits exceeded",
     "evalue": "Not enough units in project to continue executions. Please contact your project admin.\n",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "from Data import normal_dist\n",
    "import numpy as np\n",
    "from NFconstants import N_traj\n",
    "NF_trained=NormalizingFlow(latent=normal_dist,flows=configure_flows(16),conv_flows=configure_conv_flows(0,kernel_size=16),ort=True)\n",
    "NF_trained.load_state_dict(torch.load('model_weights1.pth'))\n",
    "NF_trained.eval()\n",
    "print(NF_trained.ort)\n",
    "trajs=NF_trained.sample(N_traj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6b3e8cac-67f4-45bd-82c0-f1d664b844fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T23:51:02.442810Z",
     "iopub.status.busy": "2024-03-23T23:51:02.442054Z",
     "iopub.status.idle": "2024-03-23T23:51:02.575716Z",
     "shell.execute_reply": "2024-03-23T23:51:02.574939Z",
     "shell.execute_reply.started": "2024-03-23T23:51:02.442765Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trajs=trajs.numpy()\n",
    "np.savetxt(\"NN RelMorse N=256 Beta=64 alpha=0.125 n_flows=16.txt\",trajs,delimiter=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "de878c22-3a61-4ff1-86d3-cd6f3da79a4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-21T23:15:02.661384Z",
     "iopub.status.busy": "2024-03-21T23:15:02.660505Z",
     "iopub.status.idle": "2024-03-21T23:15:02.870885Z",
     "shell.execute_reply": "2024-03-21T23:15:02.870046Z",
     "shell.execute_reply.started": "2024-03-21T23:15:02.661338Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "#trajs=np.genfromtxt(\"NN N=256 Beta=16 g=0.05 n_flows=12.txt\",delimiter=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a2bd7f45-900a-40c7-998d-c005f8b0db4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T23:51:07.624326Z",
     "iopub.status.busy": "2024-03-23T23:51:07.623671Z",
     "iopub.status.idle": "2024-03-23T23:51:07.656437Z",
     "shell.execute_reply": "2024-03-23T23:51:07.655595Z",
     "shell.execute_reply.started": "2024-03-23T23:51:07.624293Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trajs=(torch.tensor(trajs)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fe644a5e-8e4a-4536-bec1-78a391b60f97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T15:02:45.881536Z",
     "iopub.status.busy": "2024-03-24T15:02:45.880678Z",
     "iopub.status.idle": "2024-03-24T15:02:46.569088Z",
     "shell.execute_reply": "2024-03-24T15:02:46.567842Z",
     "shell.execute_reply.started": "2024-03-24T15:02:45.881502Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from NFandist import get_T\n",
    "def G(X,n_p=N_nod):\n",
    "    n_nod=(X.shape)[1]\n",
    "    T=torch.tensor(get_T(n_nod)).float()\n",
    "    G=np.zeros((n_p))\n",
    "    Y=X.clone()\n",
    "    Xt=torch.t(X)\n",
    "    for s in range(n_p):\n",
    "        G[s]=torch.trace(torch.matmul(Y,Xt))\n",
    "        Y=torch.matmul(Y,T)\n",
    "    return G/(N_traj*n_nod)\n",
    "g_nf=G(trajs)\n",
    "#g1=G(trajs[:,::2],8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "78c9ffdf-7d11-49a0-8304-3228e4cd69b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T21:35:19.661206Z",
     "iopub.status.busy": "2024-03-23T21:35:19.660748Z",
     "iopub.status.idle": "2024-03-23T21:35:19.705928Z",
     "shell.execute_reply": "2024-03-23T21:35:19.704956Z",
     "shell.execute_reply.started": "2024-03-23T21:35:19.661176Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from NFandist import calc_G\n",
    "from NFconstants import N_nod, N_traj, NG_points,Beta\n",
    "g_osc=calc_G(N_nod,Beta,N_nod)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d40ea38c-5c07-4349-9872-6f8026d990d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-17T00:34:29.314022Z",
     "iopub.status.busy": "2024-03-17T00:34:29.313173Z",
     "iopub.status.idle": "2024-03-17T00:34:29.332122Z",
     "shell.execute_reply": "2024-03-17T00:34:29.331342Z",
     "shell.execute_reply.started": "2024-03-17T00:34:29.313983Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "g_ur = [0.476546, 0.148654, 0.060357, 0.0232596, -0.00447499, -0.00224423, -0.00447499, 0.0232596, 0.060357, 0.148654]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "423d9be1-411c-4004-929e-ddd280cb3a77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-21T20:42:58.827532Z",
     "iopub.status.busy": "2024-03-21T20:42:58.826518Z",
     "iopub.status.idle": "2024-03-21T20:42:58.843655Z",
     "shell.execute_reply": "2024-03-21T20:42:58.842968Z",
     "shell.execute_reply.started": "2024-03-21T20:42:58.827485Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "g_ur = [0.555858, 0.497988, 0.446597, 0.401115, 0.360415, 0.324316, 0.29138, 0.261791, 0.235658, 0.211969, 0.190536, 0.171994, 0.155133, 0.140335, 0.126598, 0.114471, 0.103514, 0.0941716, 0.0852865, 0.0767528, 0.0691313, 0.0619047, 0.0550745, 0.0490998, 0.0443236, 0.0396256, 0.0358628, 0.0324961, 0.0302019, 0.0276177, 0.0251373, 0.0226234, 0.0203086, 0.0179717, 0.0164385, 0.0152739, 0.0143051, 0.0136778, 0.0127566, 0.0118486, 0.0111658, 0.0111462, 0.011026, 0.0110081, 0.0109681, 0.0106729, 0.0101027, 0.010377, 0.010866, 0.0114044, 0.0119873, 0.0114044, 0.010866, 0.010377, 0.0101027, 0.0106729, 0.0109681, 0.0110081, 0.011026, 0.0111462, 0.0111658, 0.0118486, 0.0127566, 0.0136778, 0.0143051, 0.0152739, 0.0164385, 0.0179717, 0.0203086, 0.0226234, 0.0251373, 0.0276177, 0.0302019, 0.0324961, 0.0358628, 0.0396256, 0.0443236, 0.0490998, 0.0550745, 0.0619047, 0.0691313, 0.0767528, 0.0852865, 0.0941716, 0.103514, 0.114471, 0.126598, 0.140335, 0.155133, 0.171994, 0.190536, 0.211969, 0.235658, 0.261791, 0.29138, 0.324316, 0.360415, 0.401115, 0.446597, 0.497988]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "761d4f40-3376-4f0e-9177-6ff5ff928fa4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-11T13:08:02.438822Z",
     "iopub.status.busy": "2024-03-11T13:08:02.437924Z",
     "iopub.status.idle": "2024-03-11T13:08:02.452208Z",
     "shell.execute_reply": "2024-03-11T13:08:02.451027Z",
     "shell.execute_reply.started": "2024-03-11T13:08:02.438776Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "g_rel = [0.389004, 0.174591, 0.0750764, 0.0320855, 0.0235634, 0.0204869, 0.0235634, 0.0320855, 0.0750764, 0.174591]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f0639e9e-3fa3-412f-8833-8af468af9fa8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-21T19:44:45.994058Z",
     "iopub.status.busy": "2024-03-21T19:44:45.993311Z",
     "iopub.status.idle": "2024-03-21T19:44:46.026964Z",
     "shell.execute_reply": "2024-03-21T19:44:46.026278Z",
     "shell.execute_reply.started": "2024-03-21T19:44:45.994017Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "g_rel = [0.392501, 0.361773, 0.333519, 0.307446, 0.283335, 0.261201, 0.240658, 0.221871, 0.204776, 0.188963, 0.174495, 0.161116, 0.148541, 0.136946, 0.126175, 0.116168, 0.106934, 0.0985733, 0.090693, 0.0836987, 0.0773237, 0.0713712, 0.0662134, 0.0611666, 0.0567049, 0.0525145, 0.0489322, 0.045775, 0.043085, 0.0407685, 0.0383386, 0.0365845, 0.0353032, 0.0339074, 0.0324167, 0.0308972, 0.0295226, 0.0285374, 0.0276133, 0.026899, 0.0265193, 0.0267518, 0.027023, 0.0272673, 0.0275789, 0.0277296, 0.0281657, 0.0286108, 0.0289897, 0.0292072, 0.0292838, 0.0292072, 0.0289897, 0.0286108, 0.0281657, 0.0277296, 0.0275789, 0.0272673, 0.027023, 0.0267518, 0.0265193, 0.026899, 0.0276133, 0.0285374, 0.0295226, 0.0308972, 0.0324167, 0.0339074, 0.0353032, 0.0365845, 0.0383386, 0.0407685, 0.043085, 0.045775, 0.0489322, 0.0525145, 0.0567049, 0.0611666, 0.0662134, 0.0713712, 0.0773237, 0.0836987, 0.090693, 0.0985733, 0.106934, 0.116168, 0.126175, 0.136946, 0.148541, 0.161116, 0.174495, 0.188963, 0.204776, 0.221871, 0.240658, 0.261201, 0.283335, 0.307446, 0.333519, 0.361773]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "65e2959c-aa9d-47a0-971a-68fd6575b32e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T13:22:56.600736Z",
     "iopub.status.busy": "2024-03-09T13:22:56.599626Z",
     "iopub.status.idle": "2024-03-09T13:22:56.630766Z",
     "shell.execute_reply": "2024-03-09T13:22:56.629607Z",
     "shell.execute_reply.started": "2024-03-09T13:22:56.600650Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "corr = [0.0049279, 0.00445719, 0.0040318, 0.00364688, 0.00329375, 0.00297512, 0.00268571, 0.00242197, 0.00217813, 0.00195686, 0.00176504, 0.001597, 0.0014406, 0.00130362, 0.00117932, 0.00107197, 0.000971531, 0.000873839, 0.000783014, 0.000698531, 0.000622945, 0.000554938, 0.000497423, 0.000446639, 0.000400234, 0.000360026, 0.000325092, 0.00028936, 0.000252744, 0.000222755, 0.00019756, 0.000178826, 0.000169581, 0.000165766, 0.000161208, 0.000158499, 0.000157808, 0.000156267, 0.000155463, 0.000151827, 0.000137475, 0.000124214, 0.000113485, 0.000104859, 9.63436e-05, 8.8317e-05, 8.17296e-05, 7.9884e-05, 7.83747e-05, 8.01024e-05, 8.44507e-05, 8.01024e-05, 7.83747e-05, 7.9884e-05, 8.17296e-05, 8.8317e-05, 9.63436e-05, 0.000104859, 0.000113485, 0.000124214, 0.000137475, 0.000151827, 0.000155463, 0.000156267, 0.000157808, 0.000158499, 0.000161208, 0.000165766, 0.000169581, 0.000178826, 0.00019756, 0.000222755, 0.000252744, 0.00028936, 0.000325092, 0.000360026, 0.000400234, 0.000446639, 0.000497423, 0.000554938, 0.000622945, 0.000698531, 0.000783014, 0.000873839, 0.000971531, 0.00107197, 0.00117932, 0.00130362, 0.0014406, 0.001597, 0.00176504, 0.00195686, 0.00217813, 0.00242197, 0.00268571, 0.00297512, 0.00329375, 0.00364688, 0.0040318, 0.00445719, 0.0049279]\n",
    "g_rel_001=(100*np.array(corr))[:-1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1cd1e02d-0324-466a-b37e-a60554908a29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-11T16:48:55.993064Z",
     "iopub.status.busy": "2024-03-11T16:48:55.992018Z",
     "iopub.status.idle": "2024-03-11T16:48:56.010951Z",
     "shell.execute_reply": "2024-03-11T16:48:56.009823Z",
     "shell.execute_reply.started": "2024-03-11T16:48:55.993012Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "corr = [0.0482165, 0.0437875, 0.0397512, 0.0361339, 0.0328051, 0.0297607, 0.0270138, 0.0244825, 0.0222039, 0.0201489, 0.0183026, 0.0166458, 0.0151002, 0.0137192, 0.012421, 0.0112716, 0.0102497, 0.00931179, 0.0084281, 0.00763501, 0.00697282, 0.00637519, 0.00579578, 0.00524782, 0.00469027, 0.00419239, 0.00376016, 0.00335117, 0.00299975, 0.00265075, 0.00236496, 0.00215769, 0.00196452, 0.00178665, 0.00162977, 0.00148276, 0.00135563, 0.00127519, 0.00120796, 0.00115448, 0.0011155, 0.00109623, 0.00112555, 0.00113097, 0.00108849, 0.00108302, 0.00112726, 0.00115736, 0.00118966, 0.00124266, 0.00121678, 0.00124266, 0.00118966, 0.00115736, 0.00112726, 0.00108302, 0.00108849, 0.00113097, 0.00112555, 0.00109623, 0.0011155, 0.00115448, 0.00120796, 0.00127519, 0.00135563, 0.00148276, 0.00162977, 0.00178665, 0.00196452, 0.00215769, 0.00236496, 0.00265075, 0.00299975, 0.00335117, 0.00376016, 0.00419239, 0.00469027, 0.00524782, 0.00579578, 0.00637519, 0.00697282, 0.00763501, 0.0084281, 0.00931179, 0.0102497, 0.0112716, 0.012421, 0.0137192, 0.0151002, 0.0166458, 0.0183026, 0.0201489, 0.0222039, 0.0244825, 0.0270138, 0.0297607, 0.0328051, 0.0361339, 0.0397512, 0.0437875, 0.0482165]\n",
    "g_rel_01=(10*np.array(corr))[:-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "34a5ead7-10a1-445f-abbd-4f8c2478ccd1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T15:02:50.096199Z",
     "iopub.status.busy": "2024-03-24T15:02:50.095261Z",
     "iopub.status.idle": "2024-03-24T15:02:50.450458Z",
     "shell.execute_reply": "2024-03-24T15:02:50.449352Z",
     "shell.execute_reply.started": "2024-03-24T15:02:50.096165Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23004960.768\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#import sys\n",
    "#sys.path.append('../')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from NFconstants import N_nod, N_traj, NG_points,Beta\n",
    "#from Value import G\n",
    "#import ensemble\n",
    "#from NFoscillator import basic_oscillator\n",
    "#from time import time\n",
    "#from NFandist import calc_G\n",
    "\n",
    "\"\"\"\n",
    "ens_nf=ensemble.ensemble.load(\"nf_ensemble.txt\",basic_oscillator)\n",
    "g_nf=np.vstack(ensemble.ensemble.Vaverage_and_sigma(ens_nf,G))\n",
    "g_nf=g_nf.transpose()[0]\n",
    "\"\"\"\n",
    "\n",
    "#g=g_osc\n",
    "print(g_nf[0])\n",
    "fig=plt.figure()\n",
    "#MCMC_list=np.arange(len(g))/len(g)\n",
    "NF_list=np.arange(len(g_nf))/len(g_nf)\n",
    "#plt.scatter(MCMC_list,g)\n",
    "plt.scatter(NF_list,g_nf)\n",
    "plt.legend([\"MCMC\",\"normalizing flow\"])\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c4f7df99-f8b8-42cc-88e7-41acb8257b39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T23:49:24.549697Z",
     "iopub.status.busy": "2024-03-23T23:49:24.548644Z",
     "iopub.status.idle": "2024-03-23T23:49:24.562458Z",
     "shell.execute_reply": "2024-03-23T23:49:24.561661Z",
     "shell.execute_reply.started": "2024-03-23T23:49:24.549635Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.996154541015625\n",
      "5.994833356201649\n"
     ]
    }
   ],
   "source": [
    "K = (1 - 2 * (g_nf[0]-g_nf[1]) / a) / (2 * a)\n",
    "print(K)\n",
    "V2=g_nf[0]/2\n",
    "print((3/2)*K+(1/2)*V2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5537b59a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T15:00:42.684537Z",
     "iopub.status.busy": "2024-03-24T15:00:42.683378Z",
     "iopub.status.idle": "2024-03-24T15:00:42.709602Z",
     "shell.execute_reply": "2024-03-24T15:00:42.708293Z",
     "shell.execute_reply.started": "2024-03-24T15:00:42.684487Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.0K\tlogs\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "! du -sh logs\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "96e1f7e3-4121-49e9-95f1-06ecbf041f59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T15:00:37.183186Z",
     "iopub.status.busy": "2024-03-24T15:00:37.182165Z",
     "iopub.status.idle": "2024-03-24T15:00:37.748425Z",
     "shell.execute_reply": "2024-03-24T15:00:37.746802Z",
     "shell.execute_reply.started": "2024-03-24T15:00:37.183148Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'logs/nf/lightning_logs/version_302': Directory not empty\n",
      "rm: cannot remove 'logs/nf/lightning_logs/version_303': Directory not empty\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Process exited with code 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-9b072bd96dfc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' rm -rf logs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/kernel/lib/python3.10/site-packages/ml_kernel/kernel.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(code)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_script_executor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mScriptExecutor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_output_error_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_script_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bash\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_init_message_handlers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/kernel/lib/python3.10/site-packages/ml_kernel/script_executor.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, lang, code)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mreturn_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_code\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Process exited with code %d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mreturn_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mException\u001b[0m: Process exited with code 1"
     ]
    }
   ],
   "source": [
    "! rm -rf logs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0937a257-cdff-4635-801c-dad1eb61f3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_flows(level_size,level_step=1):  # n_flows=8,...,12\n",
    "    flows=[]\n",
    "    n_levels=(N_latent-N_nod)//level_step\n",
    "    \n",
    "    if N_nod==N_latent:\n",
    "        level_step=0\n",
    "    \n",
    "    dim=N_latent//2\n",
    "    \n",
    "    for i in range(n_levels):\n",
    "        for k in range(level_size):\n",
    "            flows.append(AffineCouplingLayer(configure_theta(dim,dim),split=pair_SplitFunc,swap=k%2))\n",
    "        flows.append(nn.Linear(dim,dim-level_step//2))    \n",
    "        dim-=level_step//2    \n",
    "    \n",
    "    if dim!=N_nod//2:\n",
    "        print(\"smth wrong\")\n",
    "        \n",
    "    for k in range(level_size):\n",
    "        flows.append(AffineCouplingLayer(configure_theta(dim,dim),split=pair_SplitFunc,swap=k%2))\n",
    "    flows = nn.ModuleList(flows)\n",
    "    \n",
    "    return flows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67003bd9-b5df-4b89-bf8c-3fe1962ea74f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T22:17:57.203882Z",
     "iopub.status.busy": "2024-03-08T22:17:57.203532Z",
     "iopub.status.idle": "2024-03-08T22:18:00.912289Z",
     "shell.execute_reply": "2024-03-08T22:18:00.911495Z",
     "shell.execute_reply.started": "2024-03-08T22:17:57.203853Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "Normal(loc: torch.Size([100]), scale: torch.Size([100]))\n"
     ]
    }
   ],
   "source": [
    "print(\"start\")\n",
    "from Data import normal_dist\n",
    "\n",
    "def configure_theta():\n",
    "    theta=ThetaNetwork(\n",
    "                in_dim = N_nod//2,\n",
    "                out_dim = N_nod//2,\n",
    "                num_hidden = 16,  #2 to 6\n",
    "                hidden_dim = 2*N_nod , #100-1024\n",
    "                num_params = 2,\n",
    "                p_drop=0.4,\n",
    "    )\n",
    "    return theta\n",
    "\n",
    "def configure_flows(n_flows):  # n_flows=8,...,12\n",
    "    flows=[]\n",
    "    \n",
    "    flows.append(D(N_nod))\n",
    "    \n",
    "    for k in range(n_flows//4):\n",
    "        flows.append(AffineCouplingLayer(configure_theta(),split=pair_SplitFunc,swap=k%2))\n",
    "        flows.append(L1(N_nod))\n",
    "    \n",
    "    for k in range(3 * n_flows//4):\n",
    "        flows.append(AffineCouplingLayer(configure_theta(),split=pair_SplitFunc,swap=k%2))\n",
    "    \n",
    "    flows.append(D(N_nod))    \n",
    "    flows = nn.ModuleList(flows)\n",
    "    return flows \n",
    "\n",
    "def configure_conv_flows(n_conv,kernel_size=3):\n",
    "    conv_flows=[]\n",
    "    for i in range(n_conv):\n",
    "        conv_flows.append(AffineCouplingLayer(Conv_NN(N_nod//2,2,kernel_size),split=pair_SplitFunc,swap=i%2))\n",
    "    conv_flows = nn.ModuleList(conv_flows)\n",
    "    return conv_flows\n",
    "\n",
    "print(normal_dist)\n",
    "\n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f49475-3e4d-420b-b1fe-4cfd53099e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Data import normal_dist\n",
    "\n",
    "def configure_theta():\n",
    "    theta=ThetaNetwork(\n",
    "                in_dim = N_nod//2,\n",
    "                out_dim = N_nod//2,\n",
    "                num_hidden = 16,  #2 to 6\n",
    "                hidden_dim = 2 * N_nod , #100-1024\n",
    "                num_params = 2,\n",
    "                p_drop=0.0,\n",
    "    )\n",
    "    return theta\n",
    "\n",
    "def configure_flows(n_flows):  # n_flows=8,...,12\n",
    "    flows=[]\n",
    "    \n",
    "    flows.append(CubicCouplingLayer(configure_theta(),split=pair_SplitFunc,swap=0))\n",
    "    flows.append(CubicCouplingLayer(configure_theta(),split=pair_SplitFunc,swap=1))\n",
    "    \n",
    "    flows.append(D(N_nod))\n",
    "\n",
    "    for k in range(n_flows):\n",
    "        flows.append(AffineCouplingLayer(configure_theta(),split=pair_SplitFunc,swap=k%2))\n",
    "            \n",
    "    \n",
    "    flows = nn.ModuleList(flows)\n",
    "    return flows "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
