{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55d2823b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3978be52-6e34-4e0a-b401-c56031d17d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c93eb4f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4096, 4096])\n"
     ]
    }
   ],
   "source": [
    "from systems.Fields.scalar_field import Scalar_Field\n",
    "from systems.Fields.phi4 import Phi4\n",
    "from flows.NormalizingFlow import NormalizingFlow    \n",
    "from lattice import Lattice\n",
    "torch.set_default_dtype(torch.float32)\n",
    "#torch.set_float32_matmul_precision('high')\n",
    "\n",
    "def set_random_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "set_random_seed(42)\n",
    "\n",
    "\n",
    "L = 8\n",
    "latt = Lattice([L,L,L,L],[16,16,16,16],device=device)\n",
    "\n",
    "\n",
    "\n",
    "sf = Scalar_Field(latt,1)\n",
    "phi_4 = Phi4(latt,1,1/24)\n",
    "\n",
    "\n",
    "o=latt.ort_mat\n",
    "print(o.shape)\n",
    "\n",
    "#sf.set_J_local(0,[0,L//2])\n",
    "#phi_4.set_J_local(1,[0,L//2])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23f2495c-14bc-49b4-8614-69d77ce8ef65",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_dist = latt.normal_sampler()\n",
    "train_loader = latt.get_train_loader(epoch_size = 2**18,batch_size = 2 ** 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5401fb59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Pipeline(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        latent,\n",
    "        criterion,\n",
    "        optimizer_class=torch.optim.Adam,\n",
    "        optimizer_kwargs={\"lr\": 0.001,\"weight_decay\": 0}\n",
    "    ) -> None:\n",
    "        \n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "        self.loss = criterion.to(device)\n",
    "        self.latent = latent\n",
    "        self.optimizer_class = optimizer_class\n",
    "        self.optimizer_kwargs = optimizer_kwargs\n",
    "        \n",
    "    \"\"\"\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = self.optimizer_class(\n",
    "            self.model.parameters(), **self.optimizer_kwargs\n",
    "        )\n",
    "        return optimizer\n",
    "    \"\"\"\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = self.optimizer_class(self.model.parameters(), **self.optimizer_kwargs)\n",
    "        \n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer=optimizer,\n",
    "            min_lr=1e-5,\n",
    "            factor=0.99,\n",
    "            mode = \"min\",\n",
    "            patience = 2\n",
    "        )\n",
    "\n",
    "        lr_scheduler = {\n",
    "            \"scheduler\": scheduler,\n",
    "            \"interval\": \"epoch\",\n",
    "            \"monitor\": \"train_loss\",\n",
    "        }\n",
    "        return [optimizer], [lr_scheduler]\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        z = batch.to(device)\n",
    "        latent_log_prob = torch.sum(self.model.lattice.log_prob(z),-1)\n",
    "        x, log_abs_det = self.model.g(z)\n",
    "        loss = self.loss(x,log_abs_det)\n",
    "        ess = self.loss.ESS(latent_log_prob,log_abs_det)\n",
    "\n",
    "        \n",
    "        sch = self.lr_schedulers()\n",
    "        sch.step(loss)\n",
    "        self.log('train_loss', loss,prog_bar=True)\n",
    "        self.log('ess',ess)\n",
    "        self.log('mean_x',torch.mean(x))\n",
    "        self.log('lr',sch.get_last_lr()[0])\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        #print(\"---------------------------end epoch---------------------------------\")\n",
    "        pass\n",
    "    \n",
    "    def on_validation_end(self) -> None:\n",
    "        if not self.automatic_optimization:\n",
    "            # Save a checkpoint of the model\n",
    "            ckpt_path = os.path.join(self.trainer.log_dir, 'checkpoints', 'ckpt.pt')\n",
    "            self.trainer.save_checkpoint(ckpt_path, weights_only=True)\n",
    "        return super().on_validation_end()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa06713c",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_random_seed(42)\n",
    "nf = NormalizingFlow.config_and_init(n_blocks = 2,num_hidden = 6,hidden_dim = latt.total_nodes//2,lattice=latt,ort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03b1a0a0-68d8-4471-93f0-1971b8b5a916",
   "metadata": {},
   "outputs": [],
   "source": [
    "nf = NormalizingFlow.load_model(\"./weights/field.pth\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "546fbe93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(0.0014, device='cuda:0'), tensor(0.0006, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>))\n"
     ]
    }
   ],
   "source": [
    "z=next(iter(train_loader))\n",
    "print(nf.g_f_test(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "512f9a56-e420-4e02-b861-4a4dfb0d7cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "\n",
    "set_random_seed(42)\n",
    "\n",
    "\n",
    "pipeline = Pipeline(model = nf, \n",
    "                  latent = normal_dist ,\n",
    "                  criterion = sf.get_KL(), \n",
    "                  optimizer_class=torch.optim.Adam,\n",
    "                  optimizer_kwargs={\"lr\": 0.001,\"weight_decay\":1}).to(device)\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "        max_epochs = 100,\n",
    "        logger = TensorBoardLogger(save_dir=f\"./logs/field\"),\n",
    "        num_sanity_val_steps = 0,\n",
    "        log_every_n_steps = 1,\n",
    "        enable_checkpointing = False,\n",
    "        accumulate_grad_batches = 1)\n",
    "\n",
    "#trainer.fit(model=pipeline, train_dataloaders = train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b93bc0f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type            | Params | Mode \n",
      "--------------------------------------------------\n",
      "0 | model | NormalizingFlow | 302 M  | train\n",
      "1 | loss  | KL_with_S       | 0      | train\n",
      "--------------------------------------------------\n",
      "302 M     Trainable params\n",
      "0         Non-trainable params\n",
      "302 M     Total params\n",
      "1,209.336 Total estimated model params size (MB)\n",
      "235       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/home/seva/PIMC/PIMC/PIMC-py/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/16384 [00:00<?, ?it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seva/PIMC/PIMC/PIMC-py/.venv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:1340: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\n",
      "Consider using tensor.detach() first. (Triggered internally at /pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:835.)\n",
      "  current = float(metrics)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  16%|█▌        | 2653/16384 [06:35<34:05,  6.71it/s, v_num=27, train_loss=30.90]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seva/PIMC/PIMC/PIMC-py/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py:3707: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "try: \n",
    "    trainer.fit(model=pipeline, train_dataloaders = train_loader)\n",
    "except Exception:\n",
    "    nf.save(\"./weights/field.pth\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "34e09c8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NormalizingFlow(\n",
       "  (flows): ModuleList(\n",
       "    (0-7): 8 x AffineCouplingLayer(\n",
       "      (theta): ThetaNetwork(\n",
       "        (input): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (hidden): ModuleList(\n",
       "          (0-5): 6 x Sequential(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Dropout(p=0, inplace=False)\n",
       "            (2): LayerNorm((np.int64(512),), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (dims): Linear(in_features=512, out_features=256, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nf = NormalizingFlow.load_model(\"./weights/field.pth\").to(device)\n",
    "nf.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de77e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0047, device='cuda:0') tensor(0.0106, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "z = normal_dist.sample((1000,)).to(device)\n",
    "with torch.no_grad():\n",
    "    phi, _ = nf.g(z)\n",
    "err = torch.std(phi)    \n",
    "phi = torch.mean(phi,0)\n",
    "\n",
    "prop_x = sf.get_free_prop_x() \n",
    "phi_theor = -torch.matmul(prop_x,sf.J)\n",
    "print(torch.mean(phi-phi_theor),err/(1000 ** 0.5))\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43af8bc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "z = normal_dist.sample((100,)).to(device)\n",
    "with torch.no_grad():\n",
    "    phi, _ = nf.g(z)\n",
    "phi = torch.mean(phi,0)\n",
    "\n",
    "av = sf.lattice.get_time_averaging_mat()\n",
    "phi = torch.matmul(av,phi)\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(np.arange(sf.lattice.n_nodes[1]),-phi.cpu())\n",
    "plt.show()\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
