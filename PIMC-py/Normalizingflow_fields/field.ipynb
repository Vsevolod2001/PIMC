{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55d2823b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3978be52-6e34-4e0a-b401-c56031d17d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c93eb4f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from systems.Fields.scalar_field import Scalar_Field\n",
    "from systems.Fields.phi4 import Phi4\n",
    "from flows.NormalizingFlow import NormalizingFlow    \n",
    "from lattice import Lattice\n",
    "torch.set_default_dtype(torch.float32)\n",
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "def set_random_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "set_random_seed(42)\n",
    "\n",
    "\n",
    "L = 16\n",
    "latt = Lattice([L,L],[16,4],device=device)\n",
    "\n",
    "\n",
    "\n",
    "sf = Scalar_Field(latt,1)\n",
    "phi_4 = Phi4(latt,1,1/24)\n",
    "\n",
    "\n",
    "sf.set_J_local(1,[0,L//2])\n",
    "phi_4.set_J_local(1,[0,L//2])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23f2495c-14bc-49b4-8614-69d77ce8ef65",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_dist = latt.normal_sampler()\n",
    "train_loader = latt.get_train_loader(epoch_size = 2**18,batch_size = 2 ** 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5401fb59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Pipeline(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        latent,\n",
    "        criterion,\n",
    "        optimizer_class=torch.optim.Adam,\n",
    "        optimizer_kwargs={\"lr\": 0.001,\"weight_decay\": 0}\n",
    "    ) -> None:\n",
    "        \n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "        self.loss = criterion.to(device)\n",
    "        self.latent = latent\n",
    "        self.optimizer_class = optimizer_class\n",
    "        self.optimizer_kwargs = optimizer_kwargs\n",
    "        \n",
    "    \"\"\"\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = self.optimizer_class(\n",
    "            self.model.parameters(), **self.optimizer_kwargs\n",
    "        )\n",
    "        return optimizer\n",
    "    \"\"\"\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = self.optimizer_class(self.model.parameters(), **self.optimizer_kwargs)\n",
    "        \n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer=optimizer,\n",
    "            min_lr=1e-5,\n",
    "            factor=0.99,\n",
    "            mode = \"min\",\n",
    "            patience = 2\n",
    "        )\n",
    "\n",
    "        lr_scheduler = {\n",
    "            \"scheduler\": scheduler,\n",
    "            \"interval\": \"epoch\",\n",
    "            \"monitor\": \"train_loss\",\n",
    "        }\n",
    "        return [optimizer], [lr_scheduler]\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        z = batch.to(device)\n",
    "        latent_log_prob = torch.sum(self.model.lattice.log_prob(z),-1)\n",
    "        x, log_abs_det = self.model.g(z)\n",
    "        loss = self.loss(x,log_abs_det)\n",
    "        ess = self.loss.ESS(latent_log_prob,log_abs_det)\n",
    "\n",
    "        \n",
    "        sch = self.lr_schedulers()\n",
    "        sch.step(loss)\n",
    "        self.log('train_loss', loss,prog_bar=True)\n",
    "        self.log('ess',ess)\n",
    "        self.log('mean_x',torch.mean(x))\n",
    "        self.log('lr',sch.get_last_lr()[0])\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        #print(\"---------------------------end epoch---------------------------------\")\n",
    "        pass\n",
    "    \n",
    "    def on_validation_end(self) -> None:\n",
    "        if not self.automatic_optimization:\n",
    "            # Save a checkpoint of the model\n",
    "            ckpt_path = os.path.join(self.trainer.log_dir, 'checkpoints', 'ckpt.pt')\n",
    "            self.trainer.save_checkpoint(ckpt_path, weights_only=True)\n",
    "        return super().on_validation_end()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa06713c",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_random_seed(42)\n",
    "nf = NormalizingFlow.config_and_init(n_blocks = 4,num_hidden = 6,hidden_dim = 2 * latt.total_nodes,lattice=latt,ort=True)\n",
    "nf.save(\"./weights/field.pth\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03b1a0a0-68d8-4471-93f0-1971b8b5a916",
   "metadata": {},
   "outputs": [],
   "source": [
    "nf = NormalizingFlow.load_model(\"./weights/field.pth\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "512f9a56-e420-4e02-b861-4a4dfb0d7cbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nset_random_seed(42)\\n\\n\\npipeline = Pipeline(model = nf, \\n                  latent = normal_dist ,\\n                  criterion = phi_4.get_KL(), \\n                  optimizer_class=torch.optim.Adam,\\n                  optimizer_kwargs={\"lr\": 0.001,\"weight_decay\":0}).to(device)\\n\\ntrainer = pl.Trainer(\\n        max_epochs = 100,\\n        logger = TensorBoardLogger(save_dir=f\"./logs/field\"),\\n        num_sanity_val_steps = 0,\\n        log_every_n_steps = 1,\\n        enable_checkpointing = False,\\n        accumulate_grad_batches = 1)\\n\\n#trainer.fit(model=pipeline, train_dataloaders = train_loader)\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "set_random_seed(42)\n",
    "\n",
    "\n",
    "pipeline = Pipeline(model = nf, \n",
    "                  latent = normal_dist ,\n",
    "                  criterion = phi_4.get_KL(), \n",
    "                  optimizer_class=torch.optim.Adam,\n",
    "                  optimizer_kwargs={\"lr\": 0.001,\"weight_decay\":0}).to(device)\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "        max_epochs = 100,\n",
    "        logger = TensorBoardLogger(save_dir=f\"./logs/field\"),\n",
    "        num_sanity_val_steps = 0,\n",
    "        log_every_n_steps = 1,\n",
    "        enable_checkpointing = False,\n",
    "        accumulate_grad_batches = 1)\n",
    "\n",
    "#trainer.fit(model=pipeline, train_dataloaders = train_loader)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e625063",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type            | Params | Mode \n",
      "--------------------------------------------------\n",
      "0 | model | NormalizingFlow | 14.2 M | train\n",
      "1 | loss  | KL_with_S       | 0      | train\n",
      "--------------------------------------------------\n",
      "14.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "14.2 M    Total params\n",
      "56.943    Total estimated model params size (MB)\n",
      "235       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/home/seva/Рабочий стол/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49:   0%|          | 0/16 [00:00<?, ?it/s, v_num=2, train_loss=1.030]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Рабочий стол/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py:48\u001b[39m, in \u001b[36m_call_and_handle_interrupt\u001b[39m\u001b[34m(trainer, trainer_fn, *args, **kwargs)\u001b[39m\n\u001b[32m     47\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Рабочий стол/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:599\u001b[39m, in \u001b[36mTrainer._fit_impl\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[39m\n\u001b[32m    593\u001b[39m ckpt_path = \u001b[38;5;28mself\u001b[39m._checkpoint_connector._select_ckpt_path(\n\u001b[32m    594\u001b[39m     \u001b[38;5;28mself\u001b[39m.state.fn,\n\u001b[32m    595\u001b[39m     ckpt_path,\n\u001b[32m    596\u001b[39m     model_provided=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    597\u001b[39m     model_connected=\u001b[38;5;28mself\u001b[39m.lightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    598\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m599\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    601\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.stopped\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Рабочий стол/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:1012\u001b[39m, in \u001b[36mTrainer._run\u001b[39m\u001b[34m(self, model, ckpt_path)\u001b[39m\n\u001b[32m   1009\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1010\u001b[39m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[32m   1011\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1012\u001b[39m results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1014\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1015\u001b[39m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[32m   1016\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Рабочий стол/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:1056\u001b[39m, in \u001b[36mTrainer._run_stage\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1055\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.autograd.set_detect_anomaly(\u001b[38;5;28mself\u001b[39m._detect_anomaly):\n\u001b[32m-> \u001b[39m\u001b[32m1056\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1057\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Рабочий стол/.venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:216\u001b[39m, in \u001b[36m_FitLoop.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;28mself\u001b[39m.on_advance_start()\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28mself\u001b[39m.on_advance_end()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Рабочий стол/.venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:455\u001b[39m, in \u001b[36m_FitLoop.advance\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    454\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m455\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mepoch_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Рабочий стол/.venv/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py:150\u001b[39m, in \u001b[36m_TrainingEpochLoop.run\u001b[39m\u001b[34m(self, data_fetcher)\u001b[39m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m     \u001b[38;5;28mself\u001b[39m.on_advance_end(data_fetcher)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Рабочий стол/.venv/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py:282\u001b[39m, in \u001b[36m_TrainingEpochLoop.advance\u001b[39m\u001b[34m(self, data_fetcher)\u001b[39m\n\u001b[32m    281\u001b[39m dataloader_iter = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m282\u001b[39m batch, _, __ = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    283\u001b[39m \u001b[38;5;66;03m# TODO: we should instead use the batch_idx returned by the fetcher, however, that will require saving the\u001b[39;00m\n\u001b[32m    284\u001b[39m \u001b[38;5;66;03m# fetcher state so that the batch_idx is correct after restarting\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Рабочий стол/.venv/lib/python3.12/site-packages/pytorch_lightning/loops/fetchers.py:134\u001b[39m, in \u001b[36m_PrefetchDataFetcher.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.done:\n\u001b[32m    133\u001b[39m     \u001b[38;5;66;03m# this will run only when no pre-fetching was done.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m     batch = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__next__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    136\u001b[39m     \u001b[38;5;66;03m# the iterator is empty\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Рабочий стол/.venv/lib/python3.12/site-packages/pytorch_lightning/loops/fetchers.py:61\u001b[39m, in \u001b[36m_DataFetcher.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m     batch = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Рабочий стол/.venv/lib/python3.12/site-packages/pytorch_lightning/utilities/combined_loader.py:341\u001b[39m, in \u001b[36mCombinedLoader.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    340\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m341\u001b[39m out = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    342\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m._iterator, _Sequential):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Рабочий стол/.venv/lib/python3.12/site-packages/pytorch_lightning/utilities/combined_loader.py:78\u001b[39m, in \u001b[36m_MaxSizeCycle.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m     out[i] = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miterators\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Рабочий стол/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:733\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    732\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Рабочий стол/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:789\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    788\u001b[39m index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m789\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    790\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Рабочий стол/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PIMC/PIMC/PIMC-py/Normalizingflow_fields/Data.py:17\u001b[39m, in \u001b[36mDistribution_set.__getitem__\u001b[39m\u001b[34m(self, index)\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdistribution\u001b[49m\u001b[43m.\u001b[49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m].to(\u001b[38;5;28mself\u001b[39m.device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Рабочий стол/.venv/lib/python3.12/site-packages/torch/distributions/normal.py:74\u001b[39m, in \u001b[36mNormal.sample\u001b[39m\u001b[34m(self, sample_shape)\u001b[39m\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnormal\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexpand\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscale\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexpand\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m      9\u001b[39m pipeline = Pipeline(model = nf, \n\u001b[32m     10\u001b[39m               latent = normal_dist ,\n\u001b[32m     11\u001b[39m               criterion = phi_4.get_KL(), \n\u001b[32m     12\u001b[39m               optimizer_class=torch.optim.Adam,\n\u001b[32m     13\u001b[39m               optimizer_kwargs={\u001b[33m\"\u001b[39m\u001b[33mlr\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m0.001\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mweight_decay\u001b[39m\u001b[33m\"\u001b[39m:\u001b[32m0.5\u001b[39m}).to(device)\n\u001b[32m     15\u001b[39m trainer = pl.Trainer(\n\u001b[32m     16\u001b[39m     max_epochs = \u001b[32m50\u001b[39m,\n\u001b[32m     17\u001b[39m     logger = TensorBoardLogger(save_dir=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m./logs/field\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   (...)\u001b[39m\u001b[32m     20\u001b[39m     enable_checkpointing = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     21\u001b[39m     accumulate_grad_batches = \u001b[32m1\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpipeline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m nf.save(\u001b[33m\"\u001b[39m\u001b[33m./weights/field\u001b[39m\u001b[33m\"\u001b[39m+\u001b[38;5;28mstr\u001b[39m(G[i])+\u001b[33m\"\u001b[39m\u001b[33m.pth\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Рабочий стол/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:561\u001b[39m, in \u001b[36mTrainer.fit\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[39m\n\u001b[32m    559\u001b[39m \u001b[38;5;28mself\u001b[39m.training = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    560\u001b[39m \u001b[38;5;28mself\u001b[39m.should_stop = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m561\u001b[39m \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    562\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[32m    563\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Рабочий стол/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py:65\u001b[39m, in \u001b[36m_call_and_handle_interrupt\u001b[39m\u001b[34m(trainer, trainer_fn, *args, **kwargs)\u001b[39m\n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(launcher, _SubprocessScriptLauncher):\n\u001b[32m     64\u001b[39m         launcher.kill(_get_sigkill_signal())\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m     \u001b[43mexit\u001b[49m(\u001b[32m1\u001b[39m)\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[32m     68\u001b[39m     _interrupt(trainer, exception)\n",
      "\u001b[31mNameError\u001b[39m: name 'exit' is not defined"
     ]
    }
   ],
   "source": [
    "set_random_seed(42)\n",
    "G = np.array([1,2,4,8])\n",
    "\n",
    "for i in range(len(G)):\n",
    "     \n",
    "    phi_4 = Phi4(latt,1,G[i]/24)\n",
    "    phi_4.set_J_local(1,[0,L//2])\n",
    "\n",
    "    pipeline = Pipeline(model = nf, \n",
    "                  latent = normal_dist ,\n",
    "                  criterion = phi_4.get_KL(), \n",
    "                  optimizer_class=torch.optim.Adam,\n",
    "                  optimizer_kwargs={\"lr\": 0.001,\"weight_decay\":0.1}).to(device)\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs = 50,\n",
    "        logger = TensorBoardLogger(save_dir=f\"./logs/field\"),\n",
    "        num_sanity_val_steps = 0,\n",
    "        log_every_n_steps = 1,\n",
    "        enable_checkpointing = False,\n",
    "        accumulate_grad_batches = 1)\n",
    "    \n",
    "   \n",
    "    trainer.fit(model=pipeline, train_dataloaders = train_loader)\n",
    "    nf.save(\"./weights/field\"+str(G[i])+\".pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93bc0f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type            | Params | Mode \n",
      "--------------------------------------------------\n",
      "0 | model | NormalizingFlow | 14.2 M | train\n",
      "1 | loss  | KL_with_S       | 0      | train\n",
      "--------------------------------------------------\n",
      "14.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "14.2 M    Total params\n",
      "56.943    Total estimated model params size (MB)\n",
      "235       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52:  81%|████████▏ | 13/16 [05:51<01:21,  0.04it/s, v_num=61, train_loss=1.25e+3]\n",
      "Epoch 88:  81%|████████▏ | 13/16 [00:07<00:01,  1.63it/s, v_num=62, train_loss=1.910]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "try: \n",
    "    trainer.fit(model=pipeline, train_dataloaders = train_loader)\n",
    "except Exception:\n",
    "    nf.save(\"./weights/field.pth\")\n",
    "\"\"\"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "34e09c8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NormalizingFlow(\n",
       "  (flows): ModuleList(\n",
       "    (0-7): 8 x AffineCouplingLayer(\n",
       "      (theta): ThetaNetwork(\n",
       "        (input): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (hidden): ModuleList(\n",
       "          (0-5): 6 x Sequential(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Dropout(p=0, inplace=False)\n",
       "            (2): LayerNorm((np.int64(512),), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (dims): Linear(in_features=512, out_features=256, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nf = NormalizingFlow.load_model(\"./weights/field.pth\").to(device)\n",
    "nf.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de77e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0047, device='cuda:0') tensor(0.0106, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "z = normal_dist.sample((1000,)).to(device)\n",
    "with torch.no_grad():\n",
    "    phi, _ = nf.g(z)\n",
    "err = torch.std(phi)    \n",
    "phi = torch.mean(phi,0)\n",
    "\n",
    "prop_x = sf.get_free_prop_x() \n",
    "phi_theor = -torch.matmul(prop_x,sf.J)\n",
    "print(torch.mean(phi-phi_theor),err/(1000 ** 0.5))\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "43af8bc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "z = normal_dist.sample((100,)).to(device)\n",
    "with torch.no_grad():\n",
    "    phi, _ = nf.g(z)\n",
    "phi = torch.mean(phi,0)\n",
    "\n",
    "av = sf.lattice.get_time_averaging_mat()\n",
    "phi = torch.matmul(av,phi)\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(np.arange(sf.lattice.n_nodes[1]),-phi.cpu())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53069a0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0202, -0.1825,  0.0769,  0.0510, -0.1090, -0.0068,  0.4105,  0.4959,\n",
       "          0.2295, -0.0814, -0.2062, -0.3153,  0.0289,  0.5368, -0.0258,  0.2977,\n",
       "         -0.2273, -0.1041,  0.3749,  0.2349,  0.3209, -0.4064,  0.1815,  0.2269,\n",
       "          0.0437, -0.3166, -0.1353, -0.1645, -0.4408,  0.1646,  0.0084,  0.3763,\n",
       "          0.1502,  0.3443, -0.1137,  0.3276, -0.3484, -0.1079,  0.3991,  0.2041,\n",
       "         -0.1054, -0.1016, -0.2875,  0.2230,  0.0933,  0.4070,  0.6982,  0.1382,\n",
       "          0.0804, -0.1666, -0.2198, -0.0647,  0.1910, -0.3718,  0.6844,  0.0999,\n",
       "         -0.3933, -0.0402, -0.1242,  0.3569, -0.0986,  0.1322,  0.4264,  0.0957,\n",
       "         -0.0664,  0.6489, -0.0421, -0.7392, -0.2130, -0.3945,  0.1252, -0.0541,\n",
       "          0.1366,  0.7458, -0.1945, -0.1254,  0.3971,  0.7910,  0.1563, -0.1082,\n",
       "         -0.3481,  0.5663,  0.1759, -0.0637, -0.4013, -0.3575, -0.1164,  0.4406,\n",
       "         -0.1286,  0.1625, -0.0729,  0.0620,  0.1639,  0.2403, -0.0531, -0.0319,\n",
       "         -0.1675,  0.1164,  0.0021,  0.0074, -0.6346, -0.1807,  0.2446,  0.0886,\n",
       "         -0.2871,  0.5616,  0.0029, -0.1786,  0.3880, -0.2652, -0.8269,  0.0795,\n",
       "         -0.0772, -0.2583, -0.0556, -0.1158, -0.7378,  0.0719,  0.1745,  0.0506,\n",
       "         -0.1565,  0.1936, -0.4255, -0.0744,  0.2608,  0.2616, -0.5665,  0.3842,\n",
       "         -0.3705, -0.4011, -0.5250, -0.7451, -0.3072, -0.6112, -0.5696, -0.7351,\n",
       "         -0.5639, -0.1869, -0.8665, -0.2346, -0.5682, -0.4555, -0.1774,  0.0667,\n",
       "         -0.5936,  0.2175,  0.1879, -0.2155,  0.1177, -0.6910,  0.0102, -0.4609,\n",
       "         -0.4492, -0.0848, -0.5155, -0.4968, -0.2748,  0.2595, -0.1763, -0.2712,\n",
       "         -0.1480,  0.4176, -0.3759,  0.6981, -0.2917, -1.0424,  0.3700, -0.4208,\n",
       "         -0.4872,  0.0902, -0.0433, -0.4174,  0.0984,  0.3511,  0.2646, -0.1047,\n",
       "         -0.1053,  0.6594,  0.5573,  0.3286, -0.3057, -0.1287,  0.5538,  0.1261,\n",
       "          0.0491, -0.4233,  0.2418,  0.0640, -0.3607,  0.0030, -0.1531, -0.3682,\n",
       "          0.0903,  0.4893,  0.1599, -0.1321, -0.5742, -0.7147, -0.1797,  0.0316,\n",
       "         -0.2343, -0.2672, -0.2479,  0.1953,  0.1607, -0.1927, -0.1605, -0.2219,\n",
       "         -0.0406,  0.2523,  0.1803, -0.3290, -0.1473, -0.1484, -0.0272,  0.4397,\n",
       "         -0.0158, -0.5745,  0.2342,  0.2576,  0.2377,  0.5479,  0.2822, -0.0103,\n",
       "          0.1728,  0.0429, -0.2526, -0.1015, -0.4142, -0.3308, -0.1808, -0.1027,\n",
       "          0.4039,  0.0200, -0.2145,  0.1107,  0.1525,  0.4193,  0.0999,  0.3255,\n",
       "          0.3414, -0.4161,  0.3050,  0.0186,  0.3629,  0.3472,  0.3932, -0.2056,\n",
       "         -0.0163,  0.3084,  0.2914, -0.3212, -0.1048,  0.1188,  0.1420,  0.4376]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from samplers.Langevin import Langevin\n",
    "from samplers.NN_Metropolis import NN_Metropolis\n",
    "\n",
    "for i in range(len(G)):\n",
    "    x = normal_dist.sample((1,)).to(device)\n",
    "\n",
    "    N_samp=1000\n",
    "    Lang = Langevin(phi_4,1,val = \"none\",eps = 0.001,N_sweep = 100,log_per = 1000,filename = \"./trajs_and_corr/1.txt\",open_mode = \"w\")\n",
    "    nn_M = NN_Metropolis(phi_4,N_samp,nf,Lang,log_per = 1000,filename=\"trajs_and_corr/localJ\"+str(G[i])+\".txt\",stat_filename=\"./trajs_and_corr/stat\"+str(G[i])+\".txt\")\n",
    "    nn_M.run(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e5ab85e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 256])\n",
      "torch.float32\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "phi = np.genfromtxt(\"trajs_and_corr/0.txt\",delimiter=\" \")\n",
    "phi = torch.tensor(phi).to(device).to(torch.float32)\n",
    "print(phi.shape)\n",
    "\n",
    "\n",
    "phi = torch.mean(phi,0)\n",
    "\n",
    "av = sf.lattice.get_time_averaging_mat()\n",
    "print(phi.dtype)\n",
    "phi = torch.matmul(av,phi)\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(np.arange(sf.lattice.n_nodes[1]),-phi.cpu())\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd9cc21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
