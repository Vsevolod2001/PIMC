{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578eee8c-a957-41c0-ba48-d15420da1f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "J_arr = np.arange(0,2.1,0.4)\n",
    "lambda_arr= np.arange(0,0.5,0.04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69181af3-d4b8-41f6-a887-4849c75c4d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_random_seed(42)\n",
    "for i in range(6,len(lambda_arr)):\n",
    "    \n",
    "    phi_4 = Phi4(N_nod,Beta,Space_dim,Mass,L_nod,R,0,lambda_arr[i])\n",
    "    pipeline = Pipeline(model=rg, \n",
    "                  latent = normal_dist ,\n",
    "                  criterion = phi_4.get_KL(), \n",
    "                  optimizer_class=torch.optim.Adam,\n",
    "                  optimizer_kwargs={\"lr\": 0.001,\"weight_decay\":0.0})\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs = 10,\n",
    "        logger = TensorBoardLogger(save_dir=f\"./logs/field_phi4_lambda\"),\n",
    "        num_sanity_val_steps = 0,\n",
    "        log_every_n_steps = 1,\n",
    "        enable_checkpointing = False,\n",
    "        accumulate_grad_batches = 1)\n",
    "\n",
    "    trainer.fit(model=pipeline, train_dataloaders=train_loader)\n",
    "    rg.save(\"./weights_phi4_lambda/model_weights_phi4_lambda\"+str(lambda_arr[i])+\".pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c68bb72-bbf1-4b33-b693-50b064a465a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim_dict1={8:256}\n",
    "n_flows_dict1={8:4}\n",
    "num_hidden_dict1={8:4}\n",
    "set_random_seed(42)\n",
    "rg = RGflows.configure_RG_model(RGmasks,n_flows_dict1,num_hidden_dict1,hidden_dim_dict1,grids_no_grad=0,p_drop=0.0,sys_dim = scalar.dim, O_latt = O_latt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561029e2-809b-46a3-bd49-b194ec577608",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(14):\n",
    "    \n",
    "    phi_4 = Phi4(N_nod,Beta,Space_dim,Mass,L_nod,R,0,0.48)\n",
    "    pipeline = Pipeline(model=rg, \n",
    "                  latent = normal_dist ,\n",
    "                  criterion = phi_4.get_KL(), \n",
    "                  optimizer_class=torch.optim.Adam,\n",
    "                  optimizer_kwargs={\"lr\": 0.001,\"weight_decay\":0.0})\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs = 15,\n",
    "        logger = TensorBoardLogger(save_dir=f\"./logs/field_phi4_numberaff\"),\n",
    "        num_sanity_val_steps = 0,\n",
    "        log_every_n_steps = 1,\n",
    "        enable_checkpointing = False,\n",
    "        accumulate_grad_batches = 1)\n",
    "    rg.append_aff(256,6,2)\n",
    "    trainer.fit(model=pipeline, train_dataloaders=train_loader)\n",
    "    rg.save(\"./weights_phi4_number_aff/model_weights_phi4 \"+str(4+2*i)+\".pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05d79f6-617b-4e40-84af-b9a823a9aa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_random_seed(42)\n",
    "for i in range(len(J_arr)):\n",
    "    \n",
    "    phi4.set_J_global(J_arr[i])\n",
    "    pipeline = Pipeline(model=rg, \n",
    "                  latent = normal_dist ,\n",
    "                  criterion = phi4.get_KL(), \n",
    "                  optimizer_class=torch.optim.Adam,\n",
    "                  optimizer_kwargs={\"lr\": 0.001,\"weight_decay\":0.0})\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs = 10,\n",
    "        logger = TensorBoardLogger(save_dir=f\"./logs/field_phi4_J_global\"),\n",
    "        num_sanity_val_steps = 0,\n",
    "        log_every_n_steps = 1,\n",
    "        enable_checkpointing = False,\n",
    "        accumulate_grad_batches = 1)\n",
    "\n",
    "    trainer.fit(model=pipeline, train_dataloaders=train_loader)\n",
    "    rg.save(\"./weights/field/phi4_J/phi_4_J\"+str(J_arr[i])+\".pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e97994-b137-48ca-92b7-9fccdbecc5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_random_seed(42)\n",
    "phi4.set_J_local(1,4)\n",
    "phi4.mass2 = 0.0625\n",
    "for i in range(len(beta_arr)):\n",
    "    \n",
    "    phi4.beta = beta_arr[i]\n",
    "    pipeline = Pipeline(model = rg, \n",
    "                  latent = normal_dist ,\n",
    "                  criterion = phi4.get_KL(), \n",
    "                  optimizer_class=torch.optim.Adam,\n",
    "                  optimizer_kwargs={\"lr\": 0.001,\"weight_decay\":0.0})\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs = 15,\n",
    "        logger = TensorBoardLogger(save_dir=f\"./logs/field_phi4_beta\"),\n",
    "        num_sanity_val_steps = 0,\n",
    "        log_every_n_steps = 1,\n",
    "        enable_checkpointing = False,\n",
    "        accumulate_grad_batches = 1)\n",
    "\n",
    "    trainer.fit(model=pipeline, train_dataloaders=train_loader)\n",
    "    rg.save(\"./weights/field/phi4_beta_jloc/phi4_beta_jloc\"+str(beta_arr[i])+\".pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2685abed",
   "metadata": {},
   "outputs": [],
   "source": [
    "J_arr=np.array([0,0.2,0.5,0.7,1.0,1.2,1.4,1.6,1.8,2.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7f3d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_random_seed(42)\n",
    "J_arr=np.array([0,0.2,0.5,0.7,1.0,1.2,1.4,1.6,1.8,2.0])\n",
    "\n",
    "for i in range(len(J_arr)):\n",
    "     \n",
    "    phi_4 = Phi4(latt,1,1/24)\n",
    "    phi_4.set_J_global(torch.tensor(J_arr[i]))\n",
    "\n",
    "    pipeline = Pipeline(model = nf, \n",
    "                  latent = normal_dist ,\n",
    "                  criterion = phi_4.get_KL(), \n",
    "                  optimizer_class=torch.optim.Adam,\n",
    "                  optimizer_kwargs={\"lr\": 0.001,\"weight_decay\":0.1}).to(device)\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs = 10,\n",
    "        logger = TensorBoardLogger(save_dir=f\"./logs/field\"),\n",
    "        num_sanity_val_steps = 0,\n",
    "        log_every_n_steps = 1,\n",
    "        enable_checkpointing = False,\n",
    "        accumulate_grad_batches = 1)\n",
    "    \n",
    "   \n",
    "    trainer.fit(model=pipeline, train_dataloaders = train_loader)\n",
    "    nf.save(\"./weights/field_glob\"+str(J_arr[i])+\".pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6441fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from samplers.Langevin import Langevin\n",
    "from samplers.NN_Metropolis import NN_Metropolis\n",
    "\n",
    "for i in range(len(J_arr)):\n",
    "    x = normal_dist.sample((1,)).to(device)\n",
    "     \n",
    "\n",
    "    nf = NormalizingFlow.load_model(\"./weights/field_glob\"+str(J_arr[i])+\".pth\").to(device)\n",
    "    nf.eval()\n",
    "\n",
    "\n",
    "    phi_4 = Phi4(latt,1,1/24)\n",
    "    phi_4.set_J_global(torch.tensor(J_arr[i]))\n",
    "\n",
    "    N_samp=1000\n",
    "    Lang = Langevin(phi_4,1,val = \"none\",eps = 0.001,N_sweep = 100,log_per = 1000,filename = \"./trajs_and_corr/1.txt\",open_mode = \"w\")\n",
    "    nn_M = NN_Metropolis(phi_4,N_samp,nf,Lang,log_per = 1000,filename=\"trajs_and_corr/globalJ\"+str(J_arr[i])+\".txt\",stat_filename=\"./trajs_and_corr/stat_global\"+str(J_arr[i])+\".txt\")\n",
    "    nn_M.run(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49bd6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "G=np.array([1,2,4,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac29b557",
   "metadata": {},
   "outputs": [],
   "source": [
    "from samplers.Langevin import Langevin\n",
    "from samplers.NN_Metropolis import NN_Metropolis\n",
    "\n",
    "G=np.array([1,2,4,8])\n",
    "for i in range(len(G)):\n",
    "    x = normal_dist.sample((1,)).to(device)\n",
    "     \n",
    "\n",
    "    nf = NormalizingFlow.load_model(\"./weights/field\"+str(G[i])+\".pth\").to(device)\n",
    "    nf.eval()\n",
    "\n",
    "\n",
    "    phi_4 = Phi4(latt,1,G[i]/24)\n",
    "    phi_4.set_J_local(1,[0,L//2])\n",
    "\n",
    "\n",
    "    N_samp=1000\n",
    "    Lang = Langevin(phi_4,1,val = \"none\",eps = 0.001,N_sweep = 100,log_per = 1000,filename = \"./trajs_and_corr/1.txt\",open_mode = \"w\")\n",
    "    nn_M = NN_Metropolis(phi_4,N_samp,nf,Lang,log_per = 1000,filename=\"trajs_and_corr/localJ\"+str(G[i])+\".txt\",stat_filename=\"./trajs_and_corr/stat\"+str(G[i])+\".txt\")\n",
    "    nn_M.run(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d4aee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for i in range(4):\n",
    "    \n",
    "    filename=\"trajs_and_corr/localJ\"+str(G[i])+\".txt\"\n",
    "    \n",
    "    phi = np.genfromtxt(filename,delimiter=\" \")\n",
    "    phi = torch.tensor(phi).to(device).to(torch.float32)\n",
    "\n",
    "    err = torch.std(phi,0)/(1000**0.5)\n",
    "    phi = torch.mean(phi,0)\n",
    "\n",
    "    av = sf.lattice.get_time_averaging_mat()\n",
    "    phi = torch.matmul(av,phi)\n",
    "    err = torch.matmul(av,err)\n",
    "\n",
    "\n",
    "    x = latt.steps[1]*np.arange(latt.n_nodes[1])\n",
    "    plt.scatter(x,-phi.cpu())\n",
    "    plt.errorbar(x,-phi.cpu(),err.cpu(),linestyle=\"none\")\n",
    "plt.xlabel(\"x\",fontsize=17)\n",
    "plt.ylabel(r\"$|\\langle \\phi \\rangle|$\",fontsize=17)    \n",
    "plt.legend([r\"$\\lambda=1$\",r\"$\\lambda=2$\",r\"$\\lambda=4$\",r\"$\\lambda=8$\"])\n",
    "plt.title(r\"$J=\\delta(x-2)$\",fontsize=17)\n",
    "plt.grid(True)   \n",
    "plt.savefig(\"./localJ1.pdf\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf8cbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_exp = len(J_arr)\n",
    "mean = np.zeros(n_exp)\n",
    "err = np.zeros(n_exp)\n",
    "for i in range(n_exp):\n",
    "    \n",
    "    filename=\"trajs_and_corr/globalJ\"+str(J_arr[i])+\".txt\"\n",
    "    \n",
    "    phi = np.genfromtxt(filename,delimiter=\" \")\n",
    "    phi = torch.tensor(phi).to(device).to(torch.float32)\n",
    "    \n",
    "    err[i] = torch.std(phi)/((1000 * 256)**0.5)\n",
    "    mean[i] = torch.mean(phi)\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(J_arr,-mean)\n",
    "plt.errorbar(J_arr,-mean,err)\n",
    "plt.plot(J_arr,J_arr)\n",
    "plt.xlabel(\"J\",fontsize=17)\n",
    "plt.ylabel(r\"$|\\langle \\phi \\rangle|$\",fontsize=17)    \n",
    "plt.legend([r\"$\\lambda=1$\",r\"$\\lambda=0$\"])\n",
    "#plt.title(r\"\",fontsize=17)\n",
    "plt.grid(True)   \n",
    "plt.savefig(\"./globalJ.pdf\") \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
