{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c367363",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-24T16:44:28.821474960Z",
     "iopub.status.idle": "2024-01-24T16:44:28.824855025Z",
     "shell.execute_reply": "2024-01-24T16:44:28.821419169Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Callable, List, Tuple\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.distributions.distribution import Distribution\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5baefebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "\n",
    "class Linear_CL(nn.Linear):\n",
    "    def __init__(self,n):\n",
    "        super().__init__(n,n,bias=False)\n",
    "        self.n=n\n",
    "        \n",
    "    def log_abs_det(self):\n",
    "        return torch.log(torch.abs(torch.det(self.weight)))\n",
    "    \n",
    "    def g(self,z):\n",
    "        return self.forward(z), (self.log_abs_det())*torch.ones((z.shape[0]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffdb9efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "\n",
    "class L1(nn.Linear):\n",
    "    def __init__(self,n):\n",
    "        super().__init__(n*(n-1)//2,1,bias=False)\n",
    "        self.n=n\n",
    "        self.mask2d=torch.zeros((n*(n-1) // 2),dtype=int)\n",
    "        for i in range(1,n):\n",
    "            for j in range(i):\n",
    "                self.mask2d[i*(i-1)//2+j]=i*n+j\n",
    "        self.d_ind=[(n+1)*k for k in range(n)]\n",
    "        self.ones=torch.ones((n))\n",
    "    \n",
    "    def anti_flatten(self):\n",
    "        n=self.n\n",
    "        L=torch.zeros((n**2)).to(device)\n",
    "        L[self.mask2d]=self.weight.to(device)\n",
    "        L[self.d_ind]=self.ones\n",
    "        L=torch.reshape(L,(n,n)).to(device)\n",
    "        return L        \n",
    "            \n",
    "    def log_abs_det(self):\n",
    "        return 0\n",
    "    \n",
    "    def forward(self,x):\n",
    "        Lwt=torch.t(self.anti_flatten())\n",
    "        return torch.matmul(x,Lwt)\n",
    "    \n",
    "    def g(self,z):\n",
    "        return self.forward(z), torch.zeros((z.shape[0]))\n",
    "        \n",
    "    def adj(self,mat):\n",
    "        Lw=self.anti_flatten()\n",
    "        Lwt=torch.t(Lw)\n",
    "        D=torch.matmul(Lwt,torch.matmul(mat,Lw))\n",
    "        return D\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02681dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "\n",
    "class D(nn.Linear):\n",
    "    def __init__(self,n):\n",
    "        super().__init__(n,1,bias=False)\n",
    "        self.n=n\n",
    "        self.d_ind=[(n+1)*k for k in range(n)]\n",
    "    \n",
    "    def anti_flatten(self):\n",
    "        n=self.n\n",
    "        D=torch.zeros((n**2)).to(device)\n",
    "        D[self.d_ind]=self.weight.to(device)\n",
    "        D=torch.reshape(D,(n,n)).to(device)\n",
    "        return D        \n",
    "            \n",
    "    def log_abs_det(self):\n",
    "        ABS=torch.abs(self.weight)\n",
    "        l=torch.log(ABS)\n",
    "        lad=torch.sum(l)\n",
    "        return lad\n",
    "    \n",
    "    def forward(self,x):\n",
    "        D=self.anti_flatten()\n",
    "        return torch.matmul(x,D)\n",
    "    \n",
    "    def g(self,z):\n",
    "        lad=self.log_abs_det()\n",
    "        return self.forward(z), lad * torch.ones((z.shape[0]))\n",
    "        \n",
    "    def adj(self,mat):\n",
    "        Lw=self.anti_flatten()\n",
    "        Lwt=torch.t(Lw)\n",
    "        D=torch.matmul(Lwt,torch.matmul(mat,Lw))\n",
    "        return D\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de40e85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "m=L1(10)\n",
    "#print(m.anti_flatten())\n",
    "d=D(10)\n",
    "#print(d.anti_flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0c95929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0746, -0.0933,  0.0117, -0.1131,  0.1047, -0.0332,  0.0792, -0.2627,\n",
      "          0.0493,  0.0783],\n",
      "        [ 0.0750, -0.0875,  0.0006, -0.0833,  0.0055, -0.1197,  0.0851, -0.2436,\n",
      "          0.0204,  0.1890],\n",
      "        [ 0.0323, -0.1165,  0.0767, -0.2221,  0.0609, -0.1830,  0.0783, -0.0787,\n",
      "          0.0010,  0.0179],\n",
      "        [ 0.0320, -0.1088,  0.0016, -0.2157,  0.0841, -0.1873,  0.0332, -0.1772,\n",
      "          0.0155,  0.0217],\n",
      "        [ 0.1233, -0.1639,  0.1090, -0.0819,  0.1413, -0.1988,  0.0267, -0.1159,\n",
      "          0.0077,  0.1147],\n",
      "        [ 0.1110, -0.1642,  0.0098, -0.1949,  0.0147, -0.0869,  0.0376, -0.2151,\n",
      "          0.1059,  0.2148],\n",
      "        [ 0.1238, -0.0825,  0.0203, -0.0175,  0.1279, -0.0307,  0.0835, -0.2521,\n",
      "          0.0237,  0.2739],\n",
      "        [ 0.0247, -0.1978,  0.1533, -0.1773,  0.0748, -0.1591,  0.0668, -0.1809,\n",
      "          0.0332,  0.0917],\n",
      "        [ 0.0189, -0.0234,  0.0584, -0.1419,  0.0888, -0.0806,  0.0044, -0.1699,\n",
      "          0.0192,  0.0369],\n",
      "        [ 0.1305, -0.0232,  0.0787, -0.0581,  0.0615, -0.0066,  0.0372, -0.2853,\n",
      "          0.0852,  0.0447]], grad_fn=<MmBackward0>) tensor([-16.7755, -16.7755, -16.7755, -16.7755, -16.7755, -16.7755, -16.7755,\n",
      "        -16.7755, -16.7755, -16.7755], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z=torch.rand((10,10))\n",
    "x, lad= m.g(z)\n",
    "x, lad= d.g(z)\n",
    "print(x, lad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7bb50635",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T16:57:44.641553Z",
     "iopub.status.busy": "2024-01-21T16:57:44.640468Z",
     "iopub.status.idle": "2024-01-21T16:57:44.663958Z",
     "shell.execute_reply": "2024-01-21T16:57:44.662825Z",
     "shell.execute_reply.started": "2024-01-21T16:57:44.641502Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "\n",
    "class L(nn.Linear):\n",
    "    def __init__(self,n):\n",
    "        super().__init__(n*(n+1)//2,1,bias=False)\n",
    "        self.n=n\n",
    "        self.diag_mask=torch.tensor([ (k+1) * (k+2) // 2 - 1 for k in range(n)])\n",
    "        self.mask2d=torch.zeros((n*(n+1) // 2),dtype=int)\n",
    "        for i in range(n):\n",
    "            for j in range(i+1):\n",
    "                self.mask2d[i*(i+1)//2+j]=i*n+j\n",
    "    \n",
    "    def anti_flatten(self):\n",
    "        n=self.n\n",
    "        L=torch.zeros((n**2)).to(device)\n",
    "        L[self.mask2d]=self.weight.to(device) \n",
    "        L=torch.reshape(L,(n,n)).to(device)\n",
    "        return L        \n",
    "            \n",
    "    def log_abs_det(self):\n",
    "        diag=self.weight[0][self.diag_mask]\n",
    "        la=torch.log(torch.abs(diag))\n",
    "        lad=torch.sum(la)\n",
    "        return lad\n",
    "    \n",
    "    def forward(self,x):\n",
    "        Lwt=torch.t(self.anti_flatten())\n",
    "        return torch.matmul(x,Lwt)\n",
    "        \n",
    "    def adj(self,mat):\n",
    "        Lw=self.anti_flatten()\n",
    "        Lwt=torch.t(Lw)\n",
    "        D=torch.matmul(Lwt,torch.matmul(mat,Lw))\n",
    "        return D\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4177d0f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "from NFandist import get_O, get_A\n",
    "from NFconstants import N_nod, Beta\n",
    "O=(torch.tensor(get_O(N_nod)).float()).to(device)\n",
    "Ot=torch.t(O)\n",
    "print(Ot.requires_grad)\n",
    "\n",
    "A=(torch.tensor(get_A(N_nod,Beta)).float()).to(device)\n",
    "I=(torch.eye(N_nod)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a112bc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormalizingFlow(nn.Module):\n",
    "    \n",
    "    def __init__(self, latent: Distribution, flows: List[nn.Module], conv_flows = [], ort=False):\n",
    "        super().__init__()\n",
    "        self.latent = latent\n",
    "        self.flows = flows\n",
    "        self.ort = ort\n",
    "        self.conv_flows = conv_flows\n",
    "\n",
    "    def latent_sample(self, num_samples: int = 1) -> torch.Tensor:\n",
    "        z=self.latent.sample((num_samples,))\n",
    "        return z        \n",
    "\n",
    "    def sample(self, num_samples: int = 1) -> torch.Tensor:\n",
    "        \"\"\"Sample a new observation x by sampling z from\n",
    "        the latent distribution and pass through g.\"\"\"\n",
    "        z=(self.latent_sample(num_samples))\n",
    "        with torch.no_grad():\n",
    "            x, _ = self.g(z)\n",
    "        return x \n",
    "    \n",
    "\n",
    "    def g(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        \n",
    "        #x, sum_log_abs_det = z, torch.ones(z.size(0)).to(z.device)\n",
    "        x, sum_log_abs_det = z, torch.zeros(z.size(0)).to(z.device)\n",
    "        for flow in reversed(self.flows):\n",
    "            x, log_abs_det = flow.g(x)\n",
    "            sum_log_abs_det += log_abs_det\n",
    "        \n",
    "        if self.ort:\n",
    "            x=torch.matmul(x,Ot.to(x.device))\n",
    "        \n",
    "        #x=x*a    \n",
    "        \n",
    "        for flow in reversed(self.conv_flows):\n",
    "            x, log_abs_det = flow.g(x)\n",
    "            sum_log_abs_det += log_abs_det\n",
    "        return x, sum_log_abs_det\n",
    "    \n",
    "        \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.flows)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "857f6d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_flows():  # n_flows=8,...,12\n",
    "    flows=[]\n",
    "    \n",
    "    #flows.append(Linear_CL(N_nod))\n",
    "    flows.append(D(N_nod))\n",
    "    flows.append(L1(N_nod))\n",
    "\n",
    "    \n",
    "    flows = nn.ModuleList(flows)\n",
    "    return flows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ab3fa53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T16:57:45.696455Z",
     "iopub.status.busy": "2024-01-21T16:57:45.695166Z",
     "iopub.status.idle": "2024-01-21T16:57:46.086456Z",
     "shell.execute_reply": "2024-01-21T16:57:46.085371Z",
     "shell.execute_reply.started": "2024-01-21T16:57:45.696400Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from NFconstants import N_nod, Beta , N_traj\n",
    "from NFandist import get_A, get_C\n",
    "A=(torch.tensor(get_A(N_nod,Beta)).float()).to(device)\n",
    "I=(torch.eye(N_nod)).to(device)\n",
    "def set_random_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b66a3749",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T16:57:46.453500Z",
     "iopub.status.busy": "2024-01-21T16:57:46.452562Z",
     "iopub.status.idle": "2024-01-21T16:57:46.467139Z",
     "shell.execute_reply": "2024-01-21T16:57:46.466118Z",
     "shell.execute_reply.started": "2024-01-21T16:57:46.453455Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Cheatloss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Cheatloss, self).__init__()\n",
    "\n",
    "    def forward(self, model,lad):\n",
    "        A_D=model.adj(A)\n",
    "        loss=0.5*torch.trace(A_D)-lad\n",
    "        return loss\n",
    "CL=Cheatloss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d85bbd7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T16:57:48.022398Z",
     "iopub.status.busy": "2024-01-21T16:57:48.021387Z",
     "iopub.status.idle": "2024-01-21T16:57:48.038714Z",
     "shell.execute_reply": "2024-01-21T16:57:48.037452Z",
     "shell.execute_reply.started": "2024-01-21T16:57:48.022345Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Pipeline(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        criterion,\n",
    "        optimizer_class=torch.optim.Adam,\n",
    "        optimizer_kwargs={\"lr\": 0.001,\"weight_decay\": 0.01}\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.loss = criterion\n",
    "        self.optimizer_class = optimizer_class\n",
    "        self.optimizer_kwargs = optimizer_kwargs\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = self.optimizer_class(\n",
    "            self.model.parameters(), **self.optimizer_kwargs\n",
    "        )\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        z = batch\n",
    "        x, log_abs_det = model.g(z)\n",
    "        loss = self.loss(x,log_abs_det)\n",
    "        self.log('train_loss', loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "07d32ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from NFoscillator import Oscillator\n",
    "from NFconstants import N_nod, Beta\n",
    "osc=Oscillator(N_nod,Beta)\n",
    "KL_osc=osc.get_KL()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b5b0325",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T16:57:49.272063Z",
     "iopub.status.busy": "2024-01-21T16:57:49.270976Z",
     "iopub.status.idle": "2024-01-21T17:15:05.447242Z",
     "shell.execute_reply": "2024-01-21T17:15:05.445798Z",
     "shell.execute_reply.started": "2024-01-21T16:57:49.272013Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name  | Type            | Params\n",
      "------------------------------------------\n",
      "0 | model | NormalizingFlow | 8.3 K \n",
      "1 | loss  | KL_with_S       | 0     \n",
      "------------------------------------------\n",
      "8.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "8.3 K     Total params\n",
      "0.033     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e41baa9a95f4774bdc4fe4d763cc707",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                      | 0/? [00:00<â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1000` reached.\n"
     ]
    }
   ],
   "source": [
    "from Data import normal_dist\n",
    "from Data import train_loader\n",
    "\n",
    "set_random_seed(42)\n",
    "model=NormalizingFlow(latent=normal_dist,flows=configure_flows(),ort=False)\n",
    "pipeline=Pipeline(model=model,criterion=KL_osc, optimizer_class=torch.optim.Adam,\n",
    "        optimizer_kwargs={\"lr\": 0.0001, \"weight_decay\": 0.01})\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=1000,\n",
    "    logger=TensorBoardLogger(save_dir=f\"logs/nf\"),\n",
    "    num_sanity_val_steps=0,\n",
    "    accumulate_grad_batches=8\n",
    ")\n",
    "\n",
    "trainer.fit(model=pipeline, train_dataloaders=train_loader)\n",
    "torch.save(model.state_dict(), \"model_weights.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "836f35aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T17:15:05.450939Z",
     "iopub.status.busy": "2024-01-21T17:15:05.450137Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for simple_nf:\n\tMissing key(s) in state_dict: \"layer.weight\". \n\tUnexpected key(s) in state_dict: \"weight\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-56-11624d6ca6fe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msimple_nf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mL_layer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#model=L_layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"L_layer_weights.pth\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m pipeline=Pipeline(model=model,criterion=KL_osc, optimizer_class=torch.optim.Adam,\n\u001b[0;32m      6\u001b[0m         optimizer_kwargs={\"lr\": 0.001,\"weight_decay\": 0})\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[1;34m(self, state_dict, strict)\u001b[0m\n\u001b[0;32m   1481\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1482\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[1;32m-> 1483\u001b[1;33m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[0;32m   1484\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1485\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for simple_nf:\n\tMissing key(s) in state_dict: \"layer.weight\". \n\tUnexpected key(s) in state_dict: \"weight\". "
     ]
    }
   ],
   "source": [
    "model=Linear_CL(N_nod)\n",
    "#model=L_layer\n",
    "model.load_state_dict(torch.load(\"L_layer_weights.pth\"))\n",
    "pipeline=Pipeline(model=model,criterion=KL_osc, optimizer_class=torch.optim.Adam,\n",
    "        optimizer_kwargs={\"lr\": 0.001,\"weight_decay\": 0})\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=2000,\n",
    "    logger=TensorBoardLogger(save_dir=f\"logs/nf\"),\n",
    "    num_sanity_val_steps=0,\n",
    ")\n",
    "\n",
    "trainer.fit(model=pipeline, train_dataloaders=train_loader)\n",
    "torch.save(model.state_dict(), \"L_layer_weights.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a4f67ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Data import normal_dist\n",
    "import numpy as np\n",
    "from NFconstants import N_traj\n",
    "model_trained=NormalizingFlow(latent=normal_dist,flows=configure_flows(),ort=False)\n",
    "model_trained.load_state_dict(torch.load('model_weights.pth'))\n",
    "model_trained.eval()\n",
    "#print(NF_trained.ort)\n",
    "trajs=model_trained.sample(N_traj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f837ce60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from NFandist import get_T\n",
    "T=torch.tensor(get_T(N_nod)).float()\n",
    "def G(X,n_p=N_nod):\n",
    "    G=np.zeros((n_p))\n",
    "    Y=X.clone()\n",
    "    Xt=torch.t(X)\n",
    "    for s in range(n_p):\n",
    "        G[s]=torch.trace(torch.matmul(Y,Xt))\n",
    "        Y=torch.matmul(Y,T)\n",
    "    return G/(N_traj*N_nod)\n",
    "g_nf=G(trajs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "817d4670",
   "metadata": {},
   "outputs": [],
   "source": [
    "from NFandist import calc_G\n",
    "from NFconstants import N_nod, N_traj, NG_points,Beta\n",
    "g_osc=calc_G(N_nod,Beta,N_nod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "775f8d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#import sys\n",
    "#sys.path.append('../')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from NFconstants import N_nod, N_traj, NG_points,Beta\n",
    "#from Value import G\n",
    "#import ensemble\n",
    "#from NFoscillator import basic_oscillator\n",
    "#from time import time\n",
    "#from NFandist import calc_G\n",
    "\n",
    "\"\"\"\n",
    "ens_nf=ensemble.ensemble.load(\"nf_ensemble.txt\",basic_oscillator)\n",
    "g_nf=np.vstack(ensemble.ensemble.Vaverage_and_sigma(ens_nf,G))\n",
    "g_nf=g_nf.transpose()[0]\n",
    "\"\"\"\n",
    "\n",
    "g=g_osc\n",
    "print(len(g))\n",
    "fig=plt.figure()\n",
    "MCMC_list=np.arange(len(g))/len(g)\n",
    "NF_list=np.arange(len(g_nf))/len(g_nf)\n",
    "plt.scatter(MCMC_list,g)\n",
    "plt.scatter(NF_list,g_nf)\n",
    "plt.legend([\"MCMC\",\"normalizing flow\"])\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ad5b7542",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T14:46:43.974083Z",
     "iopub.status.busy": "2024-01-21T14:46:43.972858Z",
     "iopub.status.idle": "2024-01-21T14:46:44.081082Z",
     "shell.execute_reply": "2024-01-21T14:46:44.080032Z",
     "shell.execute_reply.started": "2024-01-21T14:46:43.974037Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 9.7450e-01,  6.8725e-03,  1.6029e-03,  ...,  2.9996e-02,\n",
      "          1.2987e-02, -1.0077e-02],\n",
      "        [ 6.8728e-03,  1.0180e+00, -1.9002e-02,  ...,  4.0149e-04,\n",
      "         -1.8119e-02,  1.3663e-03],\n",
      "        [ 1.6030e-03, -1.9002e-02,  9.8187e-01,  ...,  1.0302e-02,\n",
      "         -7.3258e-03,  9.5749e-03],\n",
      "        ...,\n",
      "        [ 2.9996e-02,  4.0149e-04,  1.0302e-02,  ...,  9.7388e-01,\n",
      "         -4.3421e-03, -1.0112e-02],\n",
      "        [ 1.2987e-02, -1.8119e-02, -7.3258e-03,  ..., -4.3421e-03,\n",
      "          1.0155e+00, -2.4950e-02],\n",
      "        [-1.0077e-02,  1.3663e-03,  9.5749e-03,  ..., -1.0112e-02,\n",
      "         -2.4950e-02,  1.0105e+00]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "L_layer=L(N_nod)\n",
    "L_layer.load_state_dict(torch.load(\"L_layer_weights.pth\"))\n",
    "print(L_layer.adj(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ca4c84d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.0000e+00,  5.8752e-08, -1.3914e-08,  ...,  2.2872e-08,\n",
      "          2.5498e-07,  0.0000e+00],\n",
      "        [ 4.0992e-08,  1.0000e+00, -2.7618e-08,  ...,  2.2800e-08,\n",
      "         -2.4269e-08,  2.8902e-08],\n",
      "        [-5.8108e-10, -9.3866e-08,  1.0000e+00,  ...,  4.4837e-09,\n",
      "         -4.7684e-07, -5.5179e-08],\n",
      "        ...,\n",
      "        [-1.2623e-09,  5.3057e-09, -3.6523e-10,  ...,  1.0000e+00,\n",
      "         -3.5937e-09,  1.9324e-08],\n",
      "        [-7.7986e-10, -1.9018e-10,  1.1782e-10,  ...,  5.4074e-10,\n",
      "          1.0000e+00, -2.6425e-09],\n",
      "        [ 7.4506e-09, -1.3039e-08, -2.9977e-09,  ..., -1.6764e-08,\n",
      "         -5.8208e-09,  1.0000e+00]])\n",
      "tensor([[ 2.0000e-01, -7.7642e-09, -1.9571e-09,  ..., -1.1199e-07,\n",
      "         -3.6891e-07,  0.0000e+00],\n",
      "        [-6.7893e-10,  2.7885e-01, -2.3201e-08,  ...,  2.8581e-08,\n",
      "          3.0639e-09,  3.8130e-08],\n",
      "        [-4.9183e-10, -5.3233e-09,  2.7885e-01,  ..., -8.5684e-10,\n",
      "         -9.5367e-07, -5.2030e-07],\n",
      "        ...,\n",
      "        [ 3.9386e-09, -8.6246e-11, -2.1778e-09,  ...,  2.0121e+01,\n",
      "         -7.6323e-08, -8.9375e-08],\n",
      "        [ 9.0515e-10,  3.1814e-11, -8.4611e-11,  ..., -3.0659e-08,\n",
      "          2.0121e+01, -1.7668e-07],\n",
      "        [ 7.4506e-09, -3.8650e-08, -2.2585e-08,  ...,  1.1921e-07,\n",
      "          7.4506e-09,  2.0200e+01]])\n",
      "tensor(2.4544e-06)\n"
     ]
    }
   ],
   "source": [
    "C=(torch.tensor(get_C(N_nod,beta)).float()).to(device)\n",
    "Ct=torch.t(C)\n",
    "A_e=torch.matmul(Ct,torch.matmul(A,C))\n",
    "print(A_e)\n",
    "A_D=torch.matmul(Ot,torch.matmul(A,O))\n",
    "print(A_D)\n",
    "print(torch.linalg.matrix_norm(A_e-I))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e94e763",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
