{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbee9da4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-26T17:21:26.272583Z",
     "iopub.status.busy": "2024-02-26T17:21:26.271801Z",
     "iopub.status.idle": "2024-02-26T17:21:26.285391Z",
     "shell.execute_reply": "2024-02-26T17:21:26.284633Z",
     "shell.execute_reply.started": "2024-02-26T17:21:26.272539Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Callable, List, Tuple\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.distributions.distribution import Distribution\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c93eb4f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-26T17:21:27.176269Z",
     "iopub.status.busy": "2024-02-26T17:21:27.175362Z",
     "iopub.status.idle": "2024-02-26T17:21:27.193962Z",
     "shell.execute_reply": "2024-02-26T17:21:27.193081Z",
     "shell.execute_reply.started": "2024-02-26T17:21:27.176225Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "from NFconstants import N_nod, beta\n",
    "from NFandist import get_O\n",
    "from NFandist import get_diag\n",
    "\n",
    "def set_random_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "O=(torch.tensor(get_O(N_nod)).float()).to(device)\n",
    "Ot=(torch.t(O)).to(device)\n",
    "print(Ot.requires_grad)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b66bc606",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-26T17:21:28.165583Z",
     "iopub.status.busy": "2024-02-26T17:21:28.164691Z",
     "iopub.status.idle": "2024-02-26T17:21:28.186588Z",
     "shell.execute_reply": "2024-02-26T17:21:28.185820Z",
     "shell.execute_reply.started": "2024-02-26T17:21:28.165539Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AffineCouplingLayer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        theta: nn.Module,\n",
    "        split: Callable[[torch.Tensor], Tuple[torch.Tensor, torch.Tensor]],\n",
    "        swap: int\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.theta = theta\n",
    "        self.split = split\n",
    "        self.swap=swap\n",
    "\n",
    "    def g(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"g : z -> x. The inverse of f.\"\"\"\n",
    "        z1, z2 = self.split(z,self.swap)\n",
    "        t, s = self.theta(z1)\n",
    "        x1, x2 = z1, (z2 - t) * torch.exp(-s)\n",
    "        log_det = -s.sum(-1) \n",
    "        return torch.cat((x2, x1), dim=-1), log_det\n",
    "    \n",
    "    def f(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"f : x -> z. The inverse of g.\"\"\"\n",
    "        x2, x1 = self.split(x,self.swap)\n",
    "        t, s = self.theta(x1)\n",
    "        z1, z2 = x1, x2 * torch.exp(s) + t \n",
    "        log_det = s.sum(-1) \n",
    "        return torch.cat((z1, z2), dim=-1), log_det"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f17f095c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-26T17:21:29.357254Z",
     "iopub.status.busy": "2024-02-26T17:21:29.356322Z",
     "iopub.status.idle": "2024-02-26T17:21:29.376754Z",
     "shell.execute_reply": "2024-02-26T17:21:29.375998Z",
     "shell.execute_reply.started": "2024-02-26T17:21:29.357193Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    def g_steps(self, z: torch.Tensor) -> List[torch.Tensor]:\\n        Maps latent variable z to observation x\\n        and stores intermediate results.\\n        \\n        xs = [z]\\n        for flow in reversed(self.flows):\\n            xs.append(flow.g(xs[-1]))\\n        return xs\\n\\n    \\n    def latent_log_prob(self, z: torch.Tensor) -> torch.Tensor:\\n        llp=self.latent.log_prob(z)\\n        sum_llp= torch.sum(llp,axis=-1)\\n        return sum_llp\\n \\n    \\n    def f(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:  #forward\\n        Maps observation x to latent variable z.\\n        Additionally, computes the log determinant\\n        of the Jacobian for this transformation.\\n        Inveres of g.\\n        \\n        z, sum_log_abs_det = x, torch.ones(x.size(0)).to(x.device)\\n        for flow in self.flows:\\n            z, log_abs_det = flow.f(z)\\n            sum_log_abs_det += log_abs_det\\n\\n        return z, sum_log_abs_det\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NormalizingFlow(nn.Module):\n",
    "    \n",
    "    def __init__(self, latent: Distribution, flows: List[nn.Module], ort=False):\n",
    "        super().__init__()\n",
    "        self.latent = latent\n",
    "        self.flows = flows\n",
    "        self.ort=ort\n",
    "\n",
    "        \n",
    "    def latent_sample(self, num_samples: int = 1) -> torch.Tensor:\n",
    "        z=self.latent.sample((num_samples,))\n",
    "        return z        \n",
    "\n",
    "    def sample(self, num_samples: int = 1) -> torch.Tensor:\n",
    "        \"\"\"Sample a new observation x by sampling z from\n",
    "        the latent distribution and pass through g.\"\"\"\n",
    "        z=(self.latent_sample(num_samples))\n",
    "        with torch.no_grad():\n",
    "            x, _ = self.g(z)\n",
    "        return x \n",
    "    \n",
    "\n",
    "    def g(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        x, sum_log_abs_det = z, torch.ones(z.size(0)).to(z.device)\n",
    "        for flow in reversed(self.flows):\n",
    "            x, log_abs_det = flow.g(x)\n",
    "            sum_log_abs_det += log_abs_det\n",
    "        \n",
    "        if self.ort:\n",
    "            x=torch.matmul(x,Ot.to(x.device))\n",
    "        return x, sum_log_abs_det\n",
    "    \n",
    "        \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.flows)\n",
    "    \n",
    " \n",
    "\"\"\"\n",
    "    def g_steps(self, z: torch.Tensor) -> List[torch.Tensor]:\n",
    "        Maps latent variable z to observation x\n",
    "        and stores intermediate results.\n",
    "        \n",
    "        xs = [z]\n",
    "        for flow in reversed(self.flows):\n",
    "            xs.append(flow.g(xs[-1]))\n",
    "        return xs\n",
    "\n",
    "    \n",
    "    def latent_log_prob(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        llp=self.latent.log_prob(z)\n",
    "        sum_llp= torch.sum(llp,axis=-1)\n",
    "        return sum_llp\n",
    " \n",
    "    \n",
    "    def f(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:  #forward\n",
    "        Maps observation x to latent variable z.\n",
    "        Additionally, computes the log determinant\n",
    "        of the Jacobian for this transformation.\n",
    "        Inveres of g.\n",
    "        \n",
    "        z, sum_log_abs_det = x, torch.ones(x.size(0)).to(x.device)\n",
    "        for flow in self.flows:\n",
    "            z, log_abs_det = flow.f(z)\n",
    "            sum_log_abs_det += log_abs_det\n",
    "\n",
    "        return z, sum_log_abs_det\n",
    "\"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b1ec3b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-26T17:21:30.428386Z",
     "iopub.status.busy": "2024-02-26T17:21:30.427254Z",
     "iopub.status.idle": "2024-02-26T17:21:30.449211Z",
     "shell.execute_reply": "2024-02-26T17:21:30.448479Z",
     "shell.execute_reply.started": "2024-02-26T17:21:30.428335Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ThetaNetwork(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_dim: int,\n",
    "        out_dim: int,\n",
    "        num_hidden: int,\n",
    "        hidden_dim: int,\n",
    "        num_params: int,\n",
    "        p_drop: float,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.input = nn.Linear(in_dim, hidden_dim)\n",
    "        self.hidden = nn.ModuleList(\n",
    "            [nn.Sequential(\n",
    "                nn.Linear(hidden_dim, hidden_dim),\n",
    "                nn.Dropout(p=p_drop),\n",
    "                nn.LayerNorm(hidden_dim)\n",
    "            ) for _ in range(num_hidden)]\n",
    "        )\n",
    "\n",
    "        self.num_params = num_params\n",
    "        self.out_dim = out_dim\n",
    "        self.dims = nn.Linear(hidden_dim, out_dim * num_params)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = F.leaky_relu(self.input(x))\n",
    "        for h in self.hidden:\n",
    "            x = F.leaky_relu(h(x))\n",
    "\n",
    "        batch_params = self.dims(x).reshape(x.size(0), self.out_dim, -1) \n",
    "        params = batch_params.chunk(self.num_params, dim=-1) \n",
    "        return [p.squeeze(-1) for p in params]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc7f0bed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-26T17:21:31.421268Z",
     "iopub.status.busy": "2024-02-26T17:21:31.420326Z",
     "iopub.status.idle": "2024-02-26T17:21:31.444214Z",
     "shell.execute_reply": "2024-02-26T17:21:31.443450Z",
     "shell.execute_reply.started": "2024-02-26T17:21:31.421219Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def SplitFunc(x: torch.Tensor,swap: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    if swap==0:\n",
    "        return x[:,::2], x[:,1::2]\n",
    "    else: \n",
    "        return x[:,1::2], x[:,::2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f71825a-6aed-44d3-8d61-b49b3c9cff11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-26T17:21:32.495725Z",
     "iopub.status.busy": "2024-02-26T17:21:32.494862Z",
     "iopub.status.idle": "2024-02-26T17:21:32.569173Z",
     "shell.execute_reply": "2024-02-26T17:21:32.568490Z",
     "shell.execute_reply.started": "2024-02-26T17:21:32.495662Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "I=torch.arange(N_nod)\n",
    "i0=I[::4]\n",
    "i1=I[1::4]\n",
    "i2=I[2::4]\n",
    "i3=I[3::4]\n",
    "mask1=torch.cat((i0,i1))\n",
    "mask2=torch.cat((i2,i3))\n",
    "\n",
    "def pair_SplitFunc(x: torch.Tensor,swap: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    if swap==0:\n",
    "        return x[:,mask1], x[:,mask2]\n",
    "    else: \n",
    "        return x[:,mask2], x[:,mask1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9586f025",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-26T17:21:33.761843Z",
     "iopub.status.busy": "2024-02-26T17:21:33.760914Z",
     "iopub.status.idle": "2024-02-26T17:21:34.536457Z",
     "shell.execute_reply": "2024-02-26T17:21:34.535476Z",
     "shell.execute_reply.started": "2024-02-26T17:21:33.761798Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "Normal(loc: torch.Size([32]), scale: torch.Size([32]))\n"
     ]
    }
   ],
   "source": [
    "print(\"start\")\n",
    "from Data import normal_dist\n",
    "\n",
    "def configure_theta():\n",
    "    theta=ThetaNetwork(\n",
    "                in_dim = N_nod//2,\n",
    "                out_dim = N_nod//2,\n",
    "                num_hidden = 12,  #2 to 6\n",
    "                hidden_dim =10*N_nod , #100-1024\n",
    "                num_params = 2,\n",
    "                p_drop=0.0,\n",
    "    )\n",
    "    return theta\n",
    "\n",
    "def configure_flows(n_flows):  # n_flows=8,...,12\n",
    "    flows=[]\n",
    "    for i in range(n_flows):\n",
    "        flows.append(AffineCouplingLayer(configure_theta(),split=pair_SplitFunc,swap=i%2))\n",
    "    flows = nn.ModuleList(flows)\n",
    "    return flows \n",
    "\n",
    "print(normal_dist)\n",
    "\n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5401fb59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-26T17:21:35.747091Z",
     "iopub.status.busy": "2024-02-26T17:21:35.746363Z",
     "iopub.status.idle": "2024-02-26T17:21:35.760794Z",
     "shell.execute_reply": "2024-02-26T17:21:35.759941Z",
     "shell.execute_reply.started": "2024-02-26T17:21:35.747047Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Pipeline(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        criterion,\n",
    "        optimizer_class=torch.optim.Adam,\n",
    "        optimizer_kwargs={\"lr\": 0.001,\"weight_decay\": 0}\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.loss = criterion\n",
    "        self.optimizer_class = optimizer_class\n",
    "        self.optimizer_kwargs = optimizer_kwargs\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = self.optimizer_class(\n",
    "            self.model.parameters(), **self.optimizer_kwargs\n",
    "        )\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        z = batch\n",
    "        x, log_abs_det = self.model.g(z)\n",
    "        loss = self.loss(x,log_abs_det)\n",
    "        self.log('train_loss', loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        #print(\"---------------------------end epoch---------------------------------\")\n",
    "        pass\n",
    "    \n",
    "    def on_validation_end(self) -> None:\n",
    "        if not self.automatic_optimization:\n",
    "            # Save a checkpoint of the model\n",
    "            ckpt_path = os.path.join(self.trainer.log_dir, 'checkpoints', 'ckpt.pt')\n",
    "            self.trainer.save_checkpoint(ckpt_path, weights_only=True)\n",
    "        return super().on_validation_end()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558e4bef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-26T17:44:49.845361Z",
     "iopub.status.busy": "2024-02-26T17:44:49.844671Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type            | Params\n",
      "------------------------------------------\n",
      "0 | model | NormalizingFlow | 40.2 M\n",
      "1 | loss  | KL_with_S       | 0     \n",
      "------------------------------------------\n",
      "40.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "40.2 M    Total params\n",
      "160.772   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40a3634d06664520a77123e3affb7033",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from LOSS import KL_osc\n",
    "from LOSS import KL_1rel\n",
    "from LOSS import KL_ur\n",
    "from Data import train_loader\n",
    "\n",
    "set_random_seed(42)\n",
    "\n",
    "nf=NormalizingFlow(latent=normal_dist,flows=configure_flows(32),ort=True)\n",
    "pipeline=Pipeline(model=nf, criterion=KL_ur, optimizer_class=torch.optim.Adam, optimizer_kwargs={\"lr\": 0.001})\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=20,\n",
    "    logger=TensorBoardLogger(save_dir=f\"logs/nf\"),\n",
    "    num_sanity_val_steps=0,\n",
    "    log_every_n_steps=1,\n",
    "    accumulate_grad_batches=64\n",
    ")\n",
    "\n",
    "trainer.fit(model=pipeline, train_dataloaders=train_loader)\n",
    "torch.save(nf.state_dict(), \"model_weights1.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bf52257c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T21:30:28.460761Z",
     "iopub.status.busy": "2024-02-24T21:30:28.460276Z",
     "iopub.status.idle": "2024-02-24T21:59:44.899613Z",
     "shell.execute_reply": "2024-02-24T21:59:44.898075Z",
     "shell.execute_reply.started": "2024-02-24T21:30:28.460721Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type            | Params\n",
      "------------------------------------------\n",
      "0 | model | NormalizingFlow | 30.1 M\n",
      "1 | loss  | KL_with_S       | 0     \n",
      "------------------------------------------\n",
      "30.1 M    Trainable params\n",
      "0         Non-trainable params\n",
      "30.1 M    Total params\n",
      "120.579   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "905e90fa7bf5495997815431c2bf7c73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    }
   ],
   "source": [
    "from LOSS import KL_ur\n",
    "from Data import train_loader\n",
    "nf=NormalizingFlow(latent=normal_dist,flows=configure_flows(24),ort=True)\n",
    "nf.load_state_dict(torch.load('model_weights1.pth'))\n",
    "pipeline=Pipeline(model=nf,criterion=KL_ur,optimizer_class=torch.optim.Adam,optimizer_kwargs={\"lr\": 0.00001})\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=10,\n",
    "    logger=TensorBoardLogger(save_dir=f\"logs/nf\"),\n",
    "    num_sanity_val_steps=0,\n",
    "    log_every_n_steps=10,\n",
    "    enable_checkpointing=False,\n",
    "    accumulate_grad_batches=32\n",
    ")\n",
    "\n",
    "trainer.fit(model=pipeline, train_dataloaders=train_loader)\n",
    "torch.save(nf.state_dict(), \"model_weights3.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a808807a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-26T17:43:55.721262Z",
     "iopub.status.busy": "2024-02-26T17:43:55.720446Z",
     "iopub.status.idle": "2024-02-26T17:43:56.992578Z",
     "shell.execute_reply": "2024-02-26T17:43:56.991830Z",
     "shell.execute_reply.started": "2024-02-26T17:43:55.721211Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "from Data import normal_dist\n",
    "import numpy as np\n",
    "from NFconstants import N_traj\n",
    "NF_trained=NormalizingFlow(latent=normal_dist,flows=configure_flows(32),ort=True)\n",
    "NF_trained.load_state_dict(torch.load('model_weights1.pth'))\n",
    "NF_trained.eval()\n",
    "print(NF_trained.ort)\n",
    "trajs=NF_trained.sample(N_traj)\n",
    "#trajs=trajs.numpy()\n",
    "#np.savetxt(\"nf_ensemble.txt\",trajs,delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe644a5e-8e4a-4536-bec1-78a391b60f97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-26T17:43:56.994815Z",
     "iopub.status.busy": "2024-02-26T17:43:56.993786Z",
     "iopub.status.idle": "2024-02-26T17:43:57.028619Z",
     "shell.execute_reply": "2024-02-26T17:43:57.027832Z",
     "shell.execute_reply.started": "2024-02-26T17:43:56.994778Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from NFandist import get_T\n",
    "T=torch.tensor(get_T(N_nod)).float()\n",
    "def G(X,n_p=N_nod):\n",
    "    G=np.zeros((n_p))\n",
    "    Y=X.clone()\n",
    "    Xt=torch.t(X)\n",
    "    for s in range(n_p):\n",
    "        G[s]=torch.trace(torch.matmul(Y,Xt))\n",
    "        Y=torch.matmul(Y,T)\n",
    "    return G/(N_traj*N_nod)\n",
    "g_nf=G(trajs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dfd21f71-aa9f-47e5-b343-d862dffb5100",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-10T23:19:37.890549Z",
     "iopub.status.busy": "2024-02-10T23:19:37.889616Z",
     "iopub.status.idle": "2024-02-10T23:19:37.903942Z",
     "shell.execute_reply": "2024-02-10T23:19:37.902962Z",
     "shell.execute_reply.started": "2024-02-10T23:19:37.890513Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "g = [0.555858, 0.497988, 0.446597, 0.401115, 0.360415, 0.324316, 0.29138, 0.261791, 0.235658, 0.211969, 0.190536, 0.171994, 0.155133, 0.140335, 0.126598, 0.114471, 0.103514, 0.0941716, 0.0852865, 0.0767528, 0.0691313, 0.0619047, 0.0550745, 0.0490998, 0.0443236, 0.0396256, 0.0358628, 0.0324961, 0.0302019, 0.0276177, 0.0251373, 0.0226234, 0.0203086, 0.0179717, 0.0164385, 0.0152739, 0.0143051, 0.0136778, 0.0127566, 0.0118486, 0.0111658, 0.0111462, 0.011026, 0.0110081, 0.0109681, 0.0106729, 0.0101027, 0.010377, 0.010866, 0.0114044, 0.0119873, 0.0114044, 0.010866, 0.010377, 0.0101027, 0.0106729, 0.0109681, 0.0110081, 0.011026, 0.0111462, 0.0111658, 0.0118486, 0.0127566, 0.0136778, 0.0143051, 0.0152739, 0.0164385, 0.0179717, 0.0203086, 0.0226234, 0.0251373, 0.0276177, 0.0302019, 0.0324961, 0.0358628, 0.0396256, 0.0443236, 0.0490998, 0.0550745, 0.0619047, 0.0691313, 0.0767528, 0.0852865, 0.0941716, 0.103514, 0.114471, 0.126598, 0.140335, 0.155133, 0.171994, 0.190536, 0.211969, 0.235658, 0.261791, 0.29138, 0.324316, 0.360415, 0.401115, 0.446597, 0.497988, 0.555858]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d40ea38c-5c07-4349-9872-6f8026d990d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-26T17:43:58.218286Z",
     "iopub.status.busy": "2024-02-26T17:43:58.217499Z",
     "iopub.status.idle": "2024-02-26T17:43:58.231347Z",
     "shell.execute_reply": "2024-02-26T17:43:58.230551Z",
     "shell.execute_reply.started": "2024-02-26T17:43:58.218240Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "g = [0.476546, 0.148654, 0.060357, 0.0232596, -0.00447499, -0.00224423, -0.00447499, 0.0232596, 0.060357, 0.148654, 0.476546]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "761d4f40-3376-4f0e-9177-6ff5ff928fa4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-15T23:22:09.444907Z",
     "iopub.status.busy": "2024-02-15T23:22:09.441761Z",
     "iopub.status.idle": "2024-02-15T23:22:09.456020Z",
     "shell.execute_reply": "2024-02-15T23:22:09.455366Z",
     "shell.execute_reply.started": "2024-02-15T23:22:09.444871Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "g_rel = [0.389004, 0.174591, 0.0750764, 0.0320855, 0.0235634, 0.0204869, 0.0235634, 0.0320855, 0.0750764, 0.174591, 0.389004]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "93da659e-23a1-4fdf-8dd8-13329188bb4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-11T17:58:54.231943Z",
     "iopub.status.busy": "2024-02-11T17:58:54.230952Z",
     "iopub.status.idle": "2024-02-11T17:58:54.245097Z",
     "shell.execute_reply": "2024-02-11T17:58:54.243765Z",
     "shell.execute_reply.started": "2024-02-11T17:58:54.231883Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "corr_abs = [5.57554, 4.28447, 3.3921, 2.84037, 2.53217, 2.44156, 2.53217, 2.84037, 3.3921, 4.28447]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34a5ead7-10a1-445f-abbd-4f8c2478ccd1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-26T17:43:59.824582Z",
     "iopub.status.busy": "2024-02-26T17:43:59.824056Z",
     "iopub.status.idle": "2024-02-26T17:44:00.184204Z",
     "shell.execute_reply": "2024-02-26T17:44:00.183450Z",
     "shell.execute_reply.started": "2024-02-26T17:43:59.824542Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#import sys\n",
    "#sys.path.append('../')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from NFconstants import N_nod, N_traj, NG_points,beta\n",
    "#from Value import G\n",
    "#import ensemble\n",
    "#from NFoscillator import basic_oscillator\n",
    "#from time import time\n",
    "#from NFandist import calc_G\n",
    "\n",
    "\"\"\"\n",
    "ens_nf=ensemble.ensemble.load(\"nf_ensemble.txt\",basic_oscillator)\n",
    "g_nf=np.vstack(ensemble.ensemble.Vaverage_and_sigma(ens_nf,G))\n",
    "g_nf=g_nf.transpose()[0]\n",
    "\"\"\"\n",
    "\n",
    "g=g[:-1]\n",
    "print(len(g))\n",
    "\n",
    "fig=plt.figure()\n",
    "MCMC_list=np.arange(len(g))/len(g)\n",
    "NF_list=np.arange(len(g_nf))/len(g_nf)\n",
    "plt.scatter(MCMC_list,g)\n",
    "plt.scatter(NF_list,g_nf)\n",
    "plt.legend([\"MCMC\",\"normalizing flow\"])\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5537b59a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
