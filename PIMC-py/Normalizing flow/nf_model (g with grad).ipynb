{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from typing import Callable, List, Tuple\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.distributions.distribution import Distribution\n",
    "from pytorch_lightning.loggers import TensorBoardLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_random_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AffineCouplingLayer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        theta: nn.Module,\n",
    "        split: Callable[[torch.Tensor], Tuple[torch.Tensor, torch.Tensor]],\n",
    "        swap: int\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.theta = theta\n",
    "        self.split = split\n",
    "        self.swap=swap\n",
    "\n",
    "    def f(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"f : x -> z. The inverse of g.\"\"\"\n",
    "        x2, x1 = self.split(x,self.swap)\n",
    "        t, s = self.theta(x1)\n",
    "        z1, z2 = x1, x2 * torch.exp(s) + t \n",
    "        log_det = s.sum(-1) \n",
    "        return torch.cat((z1, z2), dim=-1), log_det\n",
    "\n",
    "    def g(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"g : z -> x. The inverse of f.\"\"\"\n",
    "        z1, z2 = self.split(z,self.swap)\n",
    "        t, s = self.theta(z1)\n",
    "        x1, x2 = z1, (z2 - t) * torch.exp(-s)\n",
    "        log_det = -s.sum(-1) \n",
    "        return torch.cat((x2, x1), dim=-1), log_det"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NormalizingFlow(nn.Module):\n",
    "    def __init__(self, latent: Distribution, flows: List[nn.Module]):\n",
    "        super().__init__()\n",
    "        self.latent = latent\n",
    "        self.flows = flows\n",
    "\n",
    "    def latent_log_prob(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        llp=self.latent.log_prob(z)\n",
    "        sum_llp= torch.sum(llp,axis=-1)\n",
    "        return sum_llp\n",
    "\n",
    "    def latent_sample(self, num_samples: int = 1) -> torch.Tensor:\n",
    "        z=self.latent.sample((num_samples,))\n",
    "        return z                  \n",
    "\n",
    "    def sample(self, num_samples: int = 1) -> torch.Tensor:\n",
    "        \"\"\"Sample a new observation x by sampling z from\n",
    "        the latent distribution and pass through g.\"\"\"\n",
    "        z=self.latent_sample(num_samples)\n",
    "        with torch.no_grad():\n",
    "            x, _ = self.g(z)\n",
    "        return x \n",
    "    \n",
    "\n",
    "    def f(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:  #forward\n",
    "        \"\"\"Maps observation x to latent variable z.\n",
    "        Additionally, computes the log determinant\n",
    "        of the Jacobian for this transformation.\n",
    "        Inveres of g.\"\"\"\n",
    "        z, sum_log_abs_det = x, torch.ones(x.size(0)).to(x.device)\n",
    "        for flow in self.flows:\n",
    "            z, log_abs_det = flow.f(z)\n",
    "            sum_log_abs_det += log_abs_det\n",
    "\n",
    "        return z, sum_log_abs_det\n",
    "\n",
    "    def g(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        x, sum_log_abs_det = z, torch.ones(z.size(0)).to(z.device)\n",
    "        for flow in reversed(self.flows):\n",
    "            x, log_abs_det = flow.g(x)\n",
    "            sum_log_abs_det += log_abs_det\n",
    "        return x, sum_log_abs_det\n",
    "    \n",
    "\n",
    "    def g_steps(self, z: torch.Tensor) -> List[torch.Tensor]:\n",
    "        \"\"\"Maps latent variable z to observation x\n",
    "        and stores intermediate results.\"\"\"\n",
    "        xs = [z]\n",
    "        for flow in reversed(self.flows):\n",
    "            xs.append(flow.g(xs[-1]))\n",
    "        return xs\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.flows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ThetaNetwork(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_dim: int,\n",
    "        out_dim: int,\n",
    "        num_hidden: int,\n",
    "        hidden_dim: int,\n",
    "        num_params: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.input = nn.Linear(in_dim, hidden_dim)\n",
    "        self.hidden = nn.ModuleList(\n",
    "            [nn.Linear(hidden_dim, hidden_dim) for _ in range(num_hidden)]\n",
    "        )\n",
    "\n",
    "        self.num_params = num_params\n",
    "        self.out_dim = out_dim\n",
    "        self.dims = nn.Linear(hidden_dim, out_dim * num_params)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = F.leaky_relu(self.input(x))\n",
    "        for h in self.hidden:\n",
    "            x = F.leaky_relu(h(x))\n",
    "\n",
    "        batch_params = self.dims(x).reshape(x.size(0), self.out_dim, -1) \n",
    "        params = batch_params.chunk(self.num_params, dim=-1) #???\n",
    "        return [p.squeeze(-1) for p in params]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SplitFunc(x: torch.Tensor,swap: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    if swap==0:\n",
    "        return x[:,::2], x[:,1::2]\n",
    "    else: \n",
    "        return x[:,1::2], x[:,::2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal(loc: torch.Size([10]), scale: torch.Size([10]))\n"
     ]
    }
   ],
   "source": [
    "from NFconstants import N_nod\n",
    "from Data import normal_dist\n",
    "def configure_theta():\n",
    "    theta=ThetaNetwork(\n",
    "                in_dim = N_nod//2,\n",
    "                out_dim = N_nod//2,\n",
    "                num_hidden = 4,  #2 to 6\n",
    "                hidden_dim =100 , #100-1024\n",
    "                num_params = 2)\n",
    "    return theta\n",
    "def configure_flows(n_flows):  # n_flows=8,...,12\n",
    "    flows=[]\n",
    "    for i in range(n_flows):\n",
    "        flows.append(AffineCouplingLayer(configure_theta(),split=SplitFunc,swap=i%2))\n",
    "    flows = nn.ModuleList(flows)\n",
    "    return flows \n",
    "print(normal_dist)\n",
    "\n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Pipeline(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        criterion,\n",
    "        optimizer_class=torch.optim.Adam,\n",
    "        optimizer_kwargs={\"lr\": 0.0001,\"weight_decay\": 0},\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.loss = criterion\n",
    "        self.optimizer_class = optimizer_class\n",
    "        self.optimizer_kwargs = optimizer_kwargs\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = self.optimizer_class(\n",
    "            self.model.parameters(), **self.optimizer_kwargs\n",
    "        )\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        z = batch\n",
    "        x, log_abs_det = self.model.g(z)\n",
    "        loss = self.loss(x,log_abs_det)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        #print(\"---------------------------end epoch---------------------------------\")\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name  | Type            | Params\n",
      "------------------------------------------\n",
      "0 | model | NormalizingFlow | 336 K \n",
      "1 | loss  | KL_with_S       | 0     \n",
      "------------------------------------------\n",
      "336 K     Trainable params\n",
      "0         Non-trainable params\n",
      "336 K     Total params\n",
      "1.344     Total estimated model params size (MB)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:133: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  f\"The dataloader, {name}, does not have many workers which may be a bottleneck.\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dd7c5f1c79141868ed5d5c91b3ea61b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from LOSS import KL_osc\n",
    "from Data import train_loader\n",
    "\n",
    "set_random_seed(42)\n",
    "nf=NormalizingFlow(latent=normal_dist,flows=configure_flows(8))\n",
    "pipeline=Pipeline(model=nf,criterion=KL_osc)\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=10,\n",
    "    logger=TensorBoardLogger(save_dir=f\"logs/nf\"),\n",
    "    num_sanity_val_steps=0,\n",
    ")\n",
    "\n",
    "trainer.fit(model=pipeline, train_dataloaders=train_loader)\n",
    "torch.save(nf.state_dict(), \"model_weights1.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Data import normal_dist\n",
    "import numpy as np\n",
    "from NFconstants import N_traj\n",
    "NF_trained=NormalizingFlow(latent=normal_dist,flows=configure_flows(8))\n",
    "NF_trained.load_state_dict(torch.load('model_weights1.pth'))\n",
    "NF_trained.eval()\n",
    "trajs=NF_trained.sample(N_traj)\n",
    "trajs=trajs.numpy()\n",
    "np.savetxt(\"nf_ensemble.txt\",trajs,delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSOEuIhIghbuISIAU7iIiAfr/VY0F9oUnc6YAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x22b03ff13c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from NFconstants import N_nod,N_traj, NG_points\n",
    "from Value import G\n",
    "import ensemble\n",
    "from NFoscillator import basic_oscillator\n",
    "from time import time\n",
    "\n",
    "\n",
    "\n",
    "ens_nf=ensemble.ensemble.load(\"nf_ensemble.txt\",basic_oscillator)\n",
    "V_nf=np.vstack(ensemble.ensemble.Vaverage_and_sigma(ens_nf,G))\n",
    "V_nft=V_nf.transpose()\n",
    "\n",
    "ens=ensemble.ensemble.load(\"ensemble.txt\",basic_oscillator)\n",
    "V=np.vstack(ensemble.ensemble.Vaverage_and_sigma(ens,G))\n",
    "Vt=V.transpose()\n",
    "\n",
    "\n",
    "fig=plt.figure()\n",
    "plt.scatter(list(range(NG_points)),Vt[0])\n",
    "plt.scatter(list(range(NG_points)),V_nft[0])\n",
    "plt.legend([\"analytical\",\"normalizing flow\"])\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "_repr_pretty_() takes 1 positional argument but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    691\u001b[0m                 \u001b[0mtype_pprinters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype_printers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    692\u001b[0m                 deferred_pprinters=self.deferred_printers)\n\u001b[1;32m--> 693\u001b[1;33m             \u001b[0mprinter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpretty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    694\u001b[0m             \u001b[0mprinter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\lib\\pretty.py\u001b[0m in \u001b[0;36mpretty\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    377\u001b[0m                             \u001b[0mmeth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_repr_pretty_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmeth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 379\u001b[1;33m                                 \u001b[1;32mreturn\u001b[0m \u001b[0mmeth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    380\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0m_default_pprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: _repr_pretty_() takes 1 positional argument but 3 were given"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_repr_pretty_() takes 1 positional argument but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    691\u001b[0m                 \u001b[0mtype_pprinters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype_printers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    692\u001b[0m                 deferred_pprinters=self.deferred_printers)\n\u001b[1;32m--> 693\u001b[1;33m             \u001b[0mprinter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpretty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    694\u001b[0m             \u001b[0mprinter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\lib\\pretty.py\u001b[0m in \u001b[0;36mpretty\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    377\u001b[0m                             \u001b[0mmeth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_repr_pretty_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmeth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 379\u001b[1;33m                                 \u001b[1;32mreturn\u001b[0m \u001b[0mmeth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    380\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0m_default_pprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: _repr_pretty_() takes 1 positional argument but 3 were given"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-bdd640fb06671ad1\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-bdd640fb06671ad1\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir=logs/nf --port=6007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
