{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c703223",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-27T09:58:54.775023Z",
     "iopub.status.idle": "2024-01-27T09:58:54.775736Z",
     "shell.execute_reply": "2024-01-27T09:58:54.775428Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9b04ee1-89c6-48ea-9245-e25d7952e401",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-27T09:59:04.234139Z",
     "iopub.status.busy": "2024-01-27T09:59:04.233427Z",
     "iopub.status.idle": "2024-01-27T09:59:08.209422Z",
     "shell.execute_reply": "2024-01-27T09:59:08.208242Z",
     "shell.execute_reply.started": "2024-01-27T09:59:04.234092Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Callable, List, Tuple\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.distributions.distribution import Distribution\n",
    "from pytorch_lightning.loggers import TensorBoardLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f3ed970",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-27T09:59:08.211653Z",
     "iopub.status.busy": "2024-01-27T09:59:08.210916Z",
     "iopub.status.idle": "2024-01-27T09:59:08.230448Z",
     "shell.execute_reply": "2024-01-27T09:59:08.229129Z",
     "shell.execute_reply.started": "2024-01-27T09:59:08.211607Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_random_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2783b9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-27T09:59:11.339627Z",
     "iopub.status.busy": "2024-01-27T09:59:11.338672Z",
     "iopub.status.idle": "2024-01-27T09:59:11.357067Z",
     "shell.execute_reply": "2024-01-27T09:59:11.355931Z",
     "shell.execute_reply.started": "2024-01-27T09:59:11.339577Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AffineCouplingLayer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        theta: nn.Module,\n",
    "        split: Callable[[torch.Tensor], Tuple[torch.Tensor, torch.Tensor]],\n",
    "        swap: int\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.theta = theta\n",
    "        self.split = split\n",
    "        self.swap=swap\n",
    "\n",
    "    def f(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"f : x -> z. The inverse of g.\"\"\"\n",
    "        x2, x1 = self.split(x,self.swap)\n",
    "        t, s = self.theta(x1)\n",
    "        z1, z2 = x1, x2 * torch.exp(s) + t \n",
    "        log_det = s.sum(-1) \n",
    "        return torch.cat((z1, z2), dim=-1), log_det\n",
    "\n",
    "    def g(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"g : z -> x. The inverse of f.\"\"\"\n",
    "        z1, z2 = self.split(z,self.swap)\n",
    "        t, s = self.theta(z1)\n",
    "        x1, x2 = z1, (z2 - t) * torch.exp(-s)\n",
    "        log_det = -s.sum(-1) \n",
    "        return torch.cat((x2, x1), dim=-1), log_det"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8fdcfff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-27T09:59:12.129110Z",
     "iopub.status.busy": "2024-01-27T09:59:12.128036Z",
     "iopub.status.idle": "2024-01-27T09:59:12.154299Z",
     "shell.execute_reply": "2024-01-27T09:59:12.153163Z",
     "shell.execute_reply.started": "2024-01-27T09:59:12.129061Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NormalizingFlow(nn.Module):\n",
    "    def __init__(self, latent: Distribution, flows: List[nn.Module]):\n",
    "        super().__init__()\n",
    "        self.latent = latent\n",
    "        self.flows = flows\n",
    "\n",
    "    def latent_log_prob(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        llp=self.latent.log_prob(z)\n",
    "        sum_llp= torch.sum(llp,axis=-1)\n",
    "        return sum_llp\n",
    "\n",
    "    def latent_sample(self, num_samples: int = 1) -> torch.Tensor:\n",
    "        z=self.latent.sample((num_samples,))\n",
    "        return z                  \n",
    "\n",
    "    def sample(self, num_samples: int = 1) -> torch.Tensor:\n",
    "        \"\"\"Sample a new observation x by sampling z from\n",
    "        the latent distribution and pass through g.\"\"\"\n",
    "        z=self.latent_sample(num_samples)\n",
    "        with torch.no_grad():\n",
    "            x, _ = self.g(z)\n",
    "        return x \n",
    "    \n",
    "\n",
    "    def f(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:  #forward\n",
    "        \"\"\"Maps observation x to latent variable z.\n",
    "        Additionally, computes the log determinant\n",
    "        of the Jacobian for this transformation.\n",
    "        Inveres of g.\"\"\"\n",
    "        z, sum_log_abs_det = x, torch.ones(x.size(0)).to(x.device)\n",
    "        for flow in self.flows:\n",
    "            z, log_abs_det = flow.f(z)\n",
    "            sum_log_abs_det += log_abs_det\n",
    "\n",
    "        return z, sum_log_abs_det\n",
    "\n",
    "    def g(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        x, sum_log_abs_det = z, torch.ones(z.size(0)).to(z.device)\n",
    "        for flow in reversed(self.flows):\n",
    "            x, log_abs_det = flow.g(x)\n",
    "            sum_log_abs_det += log_abs_det\n",
    "        return x, sum_log_abs_det\n",
    "    \n",
    "\n",
    "    def g_steps(self, z: torch.Tensor) -> List[torch.Tensor]:\n",
    "        \"\"\"Maps latent variable z to observation x\n",
    "        and stores intermediate results.\"\"\"\n",
    "        xs = [z]\n",
    "        for flow in reversed(self.flows):\n",
    "            xs.append(flow.g(xs[-1]))\n",
    "        return xs\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.flows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be2cc397",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-27T09:59:13.631098Z",
     "iopub.status.busy": "2024-01-27T09:59:13.630190Z",
     "iopub.status.idle": "2024-01-27T09:59:13.648222Z",
     "shell.execute_reply": "2024-01-27T09:59:13.647203Z",
     "shell.execute_reply.started": "2024-01-27T09:59:13.631063Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ThetaNetwork(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_dim: int,\n",
    "        out_dim: int,\n",
    "        num_hidden: int,\n",
    "        hidden_dim: int,\n",
    "        num_params: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.input = nn.Linear(in_dim, hidden_dim)\n",
    "        self.hidden = nn.ModuleList(\n",
    "            [nn.Sequential(\n",
    "                nn.Linear(hidden_dim, hidden_dim),\n",
    "                nn.LayerNorm(hidden_dim)\n",
    "            ) for _ in range(num_hidden)]\n",
    "        )\n",
    "\n",
    "        self.num_params = num_params\n",
    "        self.out_dim = out_dim\n",
    "        self.dims = nn.Linear(hidden_dim, out_dim * num_params)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = F.leaky_relu(self.input(x))\n",
    "        for h in self.hidden:\n",
    "            x = F.leaky_relu(h(x))\n",
    "\n",
    "        batch_params = self.dims(x).reshape(x.size(0), self.out_dim, -1) \n",
    "        params = batch_params.chunk(self.num_params, dim=-1) #???\n",
    "        return [p.squeeze(-1) for p in params]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4b7b342",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-27T09:59:15.266167Z",
     "iopub.status.busy": "2024-01-27T09:59:15.265229Z",
     "iopub.status.idle": "2024-01-27T09:59:15.296340Z",
     "shell.execute_reply": "2024-01-27T09:59:15.295350Z",
     "shell.execute_reply.started": "2024-01-27T09:59:15.266128Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def SplitFunc(x: torch.Tensor,swap: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    if swap==0:\n",
    "        return x[:,::2], x[:,1::2]\n",
    "    else: \n",
    "        return x[:,1::2], x[:,::2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b73e3b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-27T09:59:23.415630Z",
     "iopub.status.busy": "2024-01-27T09:59:23.414662Z",
     "iopub.status.idle": "2024-01-27T09:59:23.439036Z",
     "shell.execute_reply": "2024-01-27T09:59:23.437879Z",
     "shell.execute_reply.started": "2024-01-27T09:59:23.415595Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal(loc: torch.Size([100]), scale: torch.Size([100]))\n"
     ]
    }
   ],
   "source": [
    "from NFconstants import N_nod\n",
    "from Data import normal_dist\n",
    "def configure_theta():\n",
    "    theta=ThetaNetwork(\n",
    "                in_dim = N_nod//2,\n",
    "                out_dim = N_nod//2,\n",
    "                num_hidden = 4,  #2 to 6\n",
    "                hidden_dim =100 , #100-1024\n",
    "                num_params = 2)\n",
    "    return theta\n",
    "def configure_flows(n_flows):  # n_flows=8,...,12\n",
    "    flows=[]\n",
    "    for i in range(n_flows):\n",
    "        flows.append(AffineCouplingLayer(configure_theta(),split=SplitFunc,swap=i%2))\n",
    "    flows = nn.ModuleList(flows)\n",
    "    return flows \n",
    "print(normal_dist)\n",
    "\n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e16a7827",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-27T09:59:26.082102Z",
     "iopub.status.busy": "2024-01-27T09:59:26.081052Z",
     "iopub.status.idle": "2024-01-27T09:59:26.099762Z",
     "shell.execute_reply": "2024-01-27T09:59:26.098639Z",
     "shell.execute_reply.started": "2024-01-27T09:59:26.082055Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Pipeline(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        criterion,\n",
    "        optimizer_class=torch.optim.Adam,\n",
    "        optimizer_kwargs={\"lr\": 0.001,\"weight_decay\": 0.01}\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.loss = criterion\n",
    "        self.optimizer_class = optimizer_class\n",
    "        self.optimizer_kwargs = optimizer_kwargs\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = self.optimizer_class(\n",
    "            self.model.parameters(), **self.optimizer_kwargs\n",
    "        )\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        z = batch\n",
    "        x, log_abs_det = self.model.g(z)\n",
    "        loss = self.loss(x,log_abs_det)\n",
    "        self.log('train_loss', loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        #print(\"---------------------------end epoch---------------------------------\")\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f008de91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-26T15:53:39.108724Z",
     "iopub.status.busy": "2024-01-26T15:53:39.107712Z",
     "iopub.status.idle": "2024-01-26T16:22:51.577354Z",
     "shell.execute_reply": "2024-01-26T16:22:51.575832Z",
     "shell.execute_reply.started": "2024-01-26T15:53:39.108684Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type            | Params\n",
      "------------------------------------------\n",
      "0 | model | NormalizingFlow | 902 K \n",
      "1 | loss  | KL_with_S       | 0     \n",
      "------------------------------------------\n",
      "902 K     Trainable params\n",
      "0         Non-trainable params\n",
      "902 K     Total params\n",
      "3.610     Total estimated model params size (MB)\n",
      "/home/jupyter/.local/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:293: The number of training batches (4) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2358eed58ee2416dbb68513152584c4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2000` reached.\n"
     ]
    }
   ],
   "source": [
    "from LOSS import KL_osc\n",
    "from Data import train_loader\n",
    "\n",
    "set_random_seed(42)\n",
    "nf=NormalizingFlow(latent=normal_dist,flows=configure_flows(16))\n",
    "pipeline=Pipeline(model=nf,criterion=KL_osc)\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=2000,\n",
    "    logger=TensorBoardLogger(save_dir=f\"logs/nf\"),\n",
    "    num_sanity_val_steps=0,\n",
    ")\n",
    "\n",
    "trainer.fit(model=pipeline, train_dataloaders=train_loader)\n",
    "torch.save(nf.state_dict(), \"model_weights1.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "56d81165-4a52-4345-b7a3-49cbd73e6f36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-27T10:58:10.503726Z",
     "iopub.status.busy": "2024-01-27T10:58:10.502662Z",
     "iopub.status.idle": "2024-01-27T11:31:05.247708Z",
     "shell.execute_reply": "2024-01-27T11:31:05.246171Z",
     "shell.execute_reply.started": "2024-01-27T10:58:10.503675Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type            | Params\n",
      "------------------------------------------\n",
      "0 | model | NormalizingFlow | 902 K \n",
      "1 | loss  | KL_with_S       | 0     \n",
      "------------------------------------------\n",
      "902 K     Trainable params\n",
      "0         Non-trainable params\n",
      "902 K     Total params\n",
      "3.610     Total estimated model params size (MB)\n",
      "/home/jupyter/.local/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:293: The number of training batches (4) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2a24bffadc644b09445467a982091a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1000` reached.\n"
     ]
    }
   ],
   "source": [
    "from LOSS import KL_osc\n",
    "from Data import train_loader\n",
    "nf=NormalizingFlow(latent=normal_dist,flows=configure_flows(16))\n",
    "nf.load_state_dict(torch.load('model_weights2.pth'))\n",
    "pipeline=Pipeline(model=nf,criterion=KL_osc,optimizer_kwargs={\"lr\": 0.00001,\"weight_decay\": 0})\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=1000,\n",
    "    logger=TensorBoardLogger(save_dir=f\"logs/nf\"),\n",
    "    num_sanity_val_steps=0,\n",
    ")\n",
    "\n",
    "trainer.fit(model=pipeline, train_dataloaders=train_loader)\n",
    "torch.save(nf.state_dict(), \"model_weights2.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a759d671",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-27T11:31:14.193107Z",
     "iopub.status.busy": "2024-01-27T11:31:14.192080Z",
     "iopub.status.idle": "2024-01-27T11:31:14.432372Z",
     "shell.execute_reply": "2024-01-27T11:31:14.431209Z",
     "shell.execute_reply.started": "2024-01-27T11:31:14.193065Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from Data import normal_dist\n",
    "import numpy as np\n",
    "from NFconstants import N_traj\n",
    "NF_trained=NormalizingFlow(latent=normal_dist,flows=configure_flows(16))\n",
    "NF_trained.load_state_dict(torch.load('model_weights2.pth'))\n",
    "NF_trained.eval()\n",
    "trajs=NF_trained.sample(N_traj)\n",
    "trajs=trajs.numpy()\n",
    "np.savetxt(\"nf_ensemble.txt\",trajs,delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e492e201",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-27T11:35:38.278082Z",
     "iopub.status.busy": "2024-01-27T11:35:38.277122Z",
     "iopub.status.idle": "2024-01-27T11:35:46.735951Z",
     "shell.execute_reply": "2024-01-27T11:35:46.734880Z",
     "shell.execute_reply.started": "2024-01-27T11:35:38.278041Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0004250635861453578\n",
      "-0.000287228243845028\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from NFconstants import N_nod, N_traj, NG_points,beta,a\n",
    "from Value import G\n",
    "import ensemble\n",
    "from NFoscillator import basic_oscillator\n",
    "from time import time\n",
    "from NFandist import calc_G\n",
    "\n",
    "\n",
    "ens_nf=ensemble.ensemble.load(\"nf_ensemble.txt\",basic_oscillator)\n",
    "\n",
    "g_nf=np.vstack(ensemble.ensemble.Vaverage_and_sigma(ens_nf,G))\n",
    "g_nf=g_nf.transpose()[0]\n",
    "\n",
    "g=calc_G(N_nod,beta,N_nod)\n",
    "\n",
    "fig=plt.figure()\n",
    "plt.scatter(list(range(NG_points)),g)\n",
    "plt.scatter(list(range(NG_points)),g_nf)\n",
    "#print(g_nf[0])\n",
    "#print(1/(2 * a)*(1-2*(g_nf[0]-g_nf[1])/a))\n",
    "print(g_nf[0]-g[0])\n",
    "print(g_nf[1]-g[1])\n",
    "plt.legend([\"analytical\",\"normalizing flow\"])\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "198fcfae",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "_repr_pretty_() takes 1 positional argument but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    691\u001b[0m                 \u001b[0mtype_pprinters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype_printers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    692\u001b[0m                 deferred_pprinters=self.deferred_printers)\n\u001b[1;32m--> 693\u001b[1;33m             \u001b[0mprinter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpretty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    694\u001b[0m             \u001b[0mprinter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\lib\\pretty.py\u001b[0m in \u001b[0;36mpretty\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    377\u001b[0m                             \u001b[0mmeth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_repr_pretty_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmeth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 379\u001b[1;33m                                 \u001b[1;32mreturn\u001b[0m \u001b[0mmeth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    380\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0m_default_pprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: _repr_pretty_() takes 1 positional argument but 3 were given"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_repr_pretty_() takes 1 positional argument but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    691\u001b[0m                 \u001b[0mtype_pprinters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype_printers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    692\u001b[0m                 deferred_pprinters=self.deferred_printers)\n\u001b[1;32m--> 693\u001b[1;33m             \u001b[0mprinter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpretty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    694\u001b[0m             \u001b[0mprinter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\lib\\pretty.py\u001b[0m in \u001b[0;36mpretty\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    377\u001b[0m                             \u001b[0mmeth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_repr_pretty_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmeth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 379\u001b[1;33m                                 \u001b[1;32mreturn\u001b[0m \u001b[0mmeth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    380\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0m_default_pprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: _repr_pretty_() takes 1 positional argument but 3 were given"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-bdd640fb06671ad1\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-bdd640fb06671ad1\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir=logs/nf --port=6007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4cc3d0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
