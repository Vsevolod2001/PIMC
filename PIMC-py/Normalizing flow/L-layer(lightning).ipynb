{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112f3bf4-1631-430c-b467-8b1dd7161f6d",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-24T16:44:28.821474960Z",
     "iopub.status.idle": "2024-01-24T16:44:28.824855025Z",
     "shell.execute_reply": "2024-01-24T16:44:28.821419169Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "Limits exceeded",
     "evalue": "Not enough units in project to continue executions. Please contact your project admin.\n",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "from typing import Callable, List, Tuple\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.distributions.distribution import Distribution\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c80bf496-81d4-4ed2-9151-a8023765d768",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T16:57:44.641553Z",
     "iopub.status.busy": "2024-01-21T16:57:44.640468Z",
     "iopub.status.idle": "2024-01-21T16:57:44.663958Z",
     "shell.execute_reply": "2024-01-21T16:57:44.662825Z",
     "shell.execute_reply.started": "2024-01-21T16:57:44.641502Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "\n",
    "class L(nn.Linear):\n",
    "    def __init__(self,n):\n",
    "        super().__init__(n*(n+1)//2,1,bias=False)\n",
    "        self.n=n\n",
    "        self.diag_mask=torch.tensor([ (k+1) * (k+2) // 2 - 1 for k in range(n)])\n",
    "        self.mask2d=torch.zeros((n*(n+1) // 2),dtype=int)\n",
    "        for i in range(n):\n",
    "            for j in range(i+1):\n",
    "                self.mask2d[i*(i+1)//2+j]=i*n+j\n",
    "    \n",
    "    def anti_flatten(self):\n",
    "        n=self.n\n",
    "        L=torch.zeros((n**2)).to(device)\n",
    "        L[self.mask2d]=self.weight.to(device) \n",
    "        L=torch.reshape(L,(n,n)).to(device)\n",
    "        return L        \n",
    "            \n",
    "    def log_abs_det(self):\n",
    "        diag=self.weight[0][self.diag_mask]\n",
    "        la=torch.log(torch.abs(diag))\n",
    "        lad=torch.sum(la)\n",
    "        return lad\n",
    "    \n",
    "    def forward(self,x):\n",
    "        Lwt=torch.t(self.anti_flatten())\n",
    "        return torch.matmul(x,Lwt)\n",
    "        \n",
    "    def adj(self,mat):\n",
    "        Lw=self.anti_flatten()\n",
    "        Lwt=torch.t(Lw)\n",
    "        D=torch.matmul(Lwt,torch.matmul(mat,Lw))\n",
    "        return D\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fabe536f-5c4f-44b0-865c-d1d4f6962016",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T16:57:45.696455Z",
     "iopub.status.busy": "2024-01-21T16:57:45.695166Z",
     "iopub.status.idle": "2024-01-21T16:57:46.086456Z",
     "shell.execute_reply": "2024-01-21T16:57:46.085371Z",
     "shell.execute_reply.started": "2024-01-21T16:57:45.696400Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from NFconstants import N_nod, beta , N_traj\n",
    "from NFandist import get_A, get_C\n",
    "A=(torch.tensor(get_A(N_nod,beta)).float()).to(device)\n",
    "def set_random_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "def A_I(model):\n",
    "    with torch.no_grad():\n",
    "        A_D=model.adj(A)\n",
    "        I=(torch.eye(N_nod)).to(device)\n",
    "    return torch.linalg.matrix_norm(A_D-I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f5652ef-d577-4587-8823-b3e854cde0c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T16:57:46.453500Z",
     "iopub.status.busy": "2024-01-21T16:57:46.452562Z",
     "iopub.status.idle": "2024-01-21T16:57:46.467139Z",
     "shell.execute_reply": "2024-01-21T16:57:46.466118Z",
     "shell.execute_reply.started": "2024-01-21T16:57:46.453455Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Cheatloss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Cheatloss, self).__init__()\n",
    "\n",
    "    def forward(self, model,lad):\n",
    "        A_D=model.adj(A)\n",
    "        loss=0.5*torch.trace(A_D)-lad\n",
    "        return loss\n",
    "CL=Cheatloss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5ae26be-6ce2-4b2c-a8d1-f285b7ea61aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T16:57:48.022398Z",
     "iopub.status.busy": "2024-01-21T16:57:48.021387Z",
     "iopub.status.idle": "2024-01-21T16:57:48.038714Z",
     "shell.execute_reply": "2024-01-21T16:57:48.037452Z",
     "shell.execute_reply.started": "2024-01-21T16:57:48.022345Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Pipeline(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        criterion,\n",
    "        optimizer_class=torch.optim.Adam,\n",
    "        optimizer_kwargs={\"lr\": 0.001,\"weight_decay\": 0.01}\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.loss = criterion\n",
    "        self.optimizer_class = optimizer_class\n",
    "        self.optimizer_kwargs = optimizer_kwargs\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = self.optimizer_class(\n",
    "            self.model.parameters(), **self.optimizer_kwargs\n",
    "        )\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        z = batch\n",
    "        x, log_abs_det = self.model(z), self.model.log_abs_det()\n",
    "        #log_abs_det=self.model.log_abs_det()\n",
    "        loss = self.loss(x,log_abs_det)\n",
    "        self.log('train_loss', loss, prog_bar=True)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        metric=A_I(self.model)\n",
    "        self.log(\"metric\",metric, prog_bar=True)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88a6e203-5c97-4d0d-afdc-2da798efc8a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T16:57:49.272063Z",
     "iopub.status.busy": "2024-01-21T16:57:49.270976Z",
     "iopub.status.idle": "2024-01-21T17:15:05.447242Z",
     "shell.execute_reply": "2024-01-21T17:15:05.445798Z",
     "shell.execute_reply.started": "2024-01-21T16:57:49.272013Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "2024-01-21 16:57:53.937626: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-21 16:57:55.309223: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type      | Params\n",
      "------------------------------------\n",
      "0 | model | L         | 5.0 K \n",
      "1 | loss  | KL_with_S | 0     \n",
      "------------------------------------\n",
      "5.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.0 K     Total params\n",
      "0.020     Total estimated model params size (MB)\n",
      "/home/jupyter/.local/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:293: The number of training batches (4) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0505e07e69e04cbb902248b22a6b02cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    }
   ],
   "source": [
    "from LOSS import KL_osc\n",
    "from Data import train_loader\n",
    "\n",
    "set_random_seed(42)\n",
    "L_layer=L(N_nod)\n",
    "pipeline=Pipeline(model=L_layer,criterion=KL_osc, optimizer_class=torch.optim.Adam,\n",
    "        optimizer_kwargs={\"lr\": 0.001, \"weight_decay\": 0.01})\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=1000,\n",
    "    logger=TensorBoardLogger(save_dir=f\"logs/nf\"),\n",
    "    num_sanity_val_steps=0,\n",
    ")\n",
    "\n",
    "trainer.fit(model=pipeline, train_dataloaders=train_loader)\n",
    "torch.save(L_layer.state_dict(), \"L_layer_weights.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97b4fe0-3eae-4375-b3c0-447d15fce267",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T17:15:05.450939Z",
     "iopub.status.busy": "2024-01-21T17:15:05.450137Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "L_layer=L(N_nod)\n",
    "L_layer.load_state_dict(torch.load(\"L_layer_weights.pth\"))\n",
    "pipeline=Pipeline(model=L_layer,criterion=KL_osc, optimizer_class=torch.optim.LBFGS,\n",
    "        optimizer_kwargs={\"lr\": 0.00001})\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=200,\n",
    "    logger=TensorBoardLogger(save_dir=f\"logs/nf\"),\n",
    "    num_sanity_val_steps=0,\n",
    ")\n",
    "\n",
    "trainer.fit(model=pipeline, train_dataloaders=train_loader)\n",
    "torch.save(L_layer.state_dict(), \"L_layer_weights.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77bf0750-567a-4fc6-bc72-260650ff1c7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T14:46:43.974083Z",
     "iopub.status.busy": "2024-01-21T14:46:43.972858Z",
     "iopub.status.idle": "2024-01-21T14:46:44.081082Z",
     "shell.execute_reply": "2024-01-21T14:46:44.080032Z",
     "shell.execute_reply.started": "2024-01-21T14:46:43.974037Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 9.4951e-01,  8.6635e-03, -7.5204e-03,  ...,  2.5913e-03,\n",
      "          1.9455e-03,  1.1769e-03],\n",
      "        [ 8.6637e-03,  9.9896e-01,  1.1440e-03,  ..., -1.1417e-08,\n",
      "         -8.2279e-09, -2.6673e-09],\n",
      "        [-7.5205e-03,  1.1440e-03,  9.9896e-01,  ...,  1.3134e-09,\n",
      "          2.8978e-10,  4.2857e-11],\n",
      "        ...,\n",
      "        [ 2.5912e-03, -1.1418e-08,  1.3115e-09,  ...,  1.0000e+00,\n",
      "         -1.6694e-08,  4.6356e-08],\n",
      "        [ 1.9452e-03, -8.2257e-09,  2.8788e-10,  ...,  2.7856e-08,\n",
      "          1.0000e+00,  3.0513e-08],\n",
      "        [ 1.1774e-03, -2.6683e-09,  4.3626e-11,  ...,  1.8042e-09,\n",
      "         -3.1326e-08,  1.0000e+00]], device='cuda:0', grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "L_layer=L(N_nod)\n",
    "L_layer.load_state_dict(torch.load(\"L_layer_weights.pth\"))\n",
    "print(L_layer.adj(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221b4bbf-25e7-4c2f-9a81-c0d892dfb961",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
