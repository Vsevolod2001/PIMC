{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbee9da4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T12:33:21.453682Z",
     "iopub.status.busy": "2024-03-09T12:33:21.452714Z",
     "iopub.status.idle": "2024-03-09T12:33:21.467989Z",
     "shell.execute_reply": "2024-03-09T12:33:21.466546Z",
     "shell.execute_reply.started": "2024-03-09T12:33:21.453639Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Callable, List, Tuple\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.distributions.distribution import Distribution\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c93eb4f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T12:33:21.471464Z",
     "iopub.status.busy": "2024-03-09T12:33:21.470394Z",
     "iopub.status.idle": "2024-03-09T12:33:22.061323Z",
     "shell.execute_reply": "2024-03-09T12:33:22.060216Z",
     "shell.execute_reply.started": "2024-03-09T12:33:21.471418Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "from NFconstants import N_nod, beta, N_latent, a\n",
    "from NFandist import get_O\n",
    "from NFandist import get_diag\n",
    "\n",
    "def set_random_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "O=(torch.tensor(get_O(N_nod)).float()).to(device)\n",
    "Ot=(torch.t(O)).to(device)\n",
    "print(Ot.requires_grad)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b66bc606",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T12:33:23.419527Z",
     "iopub.status.busy": "2024-03-09T12:33:23.418525Z",
     "iopub.status.idle": "2024-03-09T12:33:23.440209Z",
     "shell.execute_reply": "2024-03-09T12:33:23.439088Z",
     "shell.execute_reply.started": "2024-03-09T12:33:23.419489Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AffineCouplingLayer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        theta: nn.Module,\n",
    "        split: Callable[[torch.Tensor], Tuple[torch.Tensor, torch.Tensor]],\n",
    "        swap: int\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.theta = theta\n",
    "        self.split = split\n",
    "        self.swap=swap\n",
    "\n",
    "    def g(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"g : z -> x. The inverse of f.\"\"\"\n",
    "        z1, z2 = self.split(z,self.swap)\n",
    "        t, s = self.theta(z1)\n",
    "        x1, x2 = z1, z2 * torch.exp(s) + t\n",
    "        log_det = s.sum(-1) \n",
    "        return torch.cat((x2, x1), dim=-1), log_det\n",
    "    \n",
    "    def f(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"f : x -> z. The inverse of g.\"\"\"\n",
    "        x2, x1 = self.split(x,self.swap)\n",
    "        t, s = self.theta(x1)\n",
    "        z1, z2 = x1, x2 * torch.exp(s) + t \n",
    "        log_det = s.sum(-1) \n",
    "        return torch.cat((z1, z2), dim=-1), log_det"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "37fb9fdb-6230-4682-9350-ee9a9b953361",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T12:59:46.386895Z",
     "iopub.status.busy": "2024-03-09T12:59:46.386076Z",
     "iopub.status.idle": "2024-03-09T12:59:46.410722Z",
     "shell.execute_reply": "2024-03-09T12:59:46.409586Z",
     "shell.execute_reply.started": "2024-03-09T12:59:46.386835Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CubicCouplingLayer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        theta: nn.Module,\n",
    "        split: Callable[[torch.Tensor], Tuple[torch.Tensor, torch.Tensor]],\n",
    "        swap: int\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.theta = theta\n",
    "        self.split = split\n",
    "        self.swap=swap\n",
    "\n",
    "    def g(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        z1, z2 = self.split(z,self.swap)\n",
    "        t, s = self.theta(z1)\n",
    "        x1 = z1 \n",
    "        x2 = z2 + torch.exp(s-2) * (z2) ** 3 + t\n",
    "        log_det = (torch.log(1+3 * torch.exp(s-2) * (z2) ** 2)).sum(-1) \n",
    "        return torch.cat((x2, x1), dim=-1), log_det\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e523fea8-aa47-41d8-bf1c-b9d75570111d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T12:59:47.260985Z",
     "iopub.status.busy": "2024-03-09T12:59:47.259966Z",
     "iopub.status.idle": "2024-03-09T12:59:47.279836Z",
     "shell.execute_reply": "2024-03-09T12:59:47.278727Z",
     "shell.execute_reply.started": "2024-03-09T12:59:47.260951Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class D(nn.Linear):\n",
    "    def __init__(self,n):\n",
    "        super().__init__(n,1,bias=False)\n",
    "        self.n=n\n",
    "        self.d_ind=[(n+1)*k for k in range(n)]\n",
    "    \n",
    "    def anti_flatten(self):\n",
    "        n=self.n\n",
    "        D=torch.zeros((n**2)).to(device)\n",
    "        D[self.d_ind]=self.weight.to(device)\n",
    "        D=torch.reshape(D,(n,n)).to(device)\n",
    "        return D        \n",
    "            \n",
    "    def log_abs_det(self):\n",
    "        ABS=torch.abs(self.weight)\n",
    "        l=torch.log(ABS)\n",
    "        lad=torch.sum(l)\n",
    "        return lad\n",
    "    \n",
    "    def forward(self,x):\n",
    "        D=(self.anti_flatten()).to(x.device)\n",
    "        return torch.matmul(x,D)\n",
    "    \n",
    "    def g(self,z):\n",
    "        lad=self.log_abs_det()\n",
    "        return self.forward(z),  lad * torch.ones((z.shape[0])).to(z.device)\n",
    "        \n",
    "    def adj(self,mat):\n",
    "        Lw=self.anti_flatten()\n",
    "        Lwt=torch.t(Lw)\n",
    "        D=torch.matmul(Lwt,torch.matmul(mat,Lw))\n",
    "        return D\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5755c2b0-a7b7-41b3-b027-f2110fea12a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T12:59:47.787585Z",
     "iopub.status.busy": "2024-03-09T12:59:47.786538Z",
     "iopub.status.idle": "2024-03-09T12:59:47.804784Z",
     "shell.execute_reply": "2024-03-09T12:59:47.803647Z",
     "shell.execute_reply.started": "2024-03-09T12:59:47.787518Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class L1(nn.Linear):\n",
    "    def __init__(self,n):\n",
    "        super().__init__(n*(n-1)//2,1,bias=False)\n",
    "        self.n=n\n",
    "        self.mask2d=torch.zeros((n*(n-1) // 2),dtype=int)\n",
    "        for i in range(1,n):\n",
    "            for j in range(i):\n",
    "                self.mask2d[i*(i-1)//2+j]=i*n+j\n",
    "        self.d_ind=[(n+1)*k for k in range(n)]\n",
    "        self.ones=torch.ones((n)).to(device)\n",
    "    \n",
    "    def anti_flatten(self):\n",
    "        n=self.n\n",
    "        L=torch.zeros((n**2)).to(device)\n",
    "        L[self.mask2d]=self.weight.to(device)\n",
    "        L[self.d_ind]=self.ones\n",
    "        L=torch.reshape(L,(n,n)).to(device)\n",
    "        return L        \n",
    "            \n",
    "    def log_abs_det(self):\n",
    "        return 0\n",
    "    \n",
    "    def forward(self,x):\n",
    "        Lwt=torch.t(self.anti_flatten()).to(x.device)\n",
    "        return torch.matmul(x,Lwt)\n",
    "    \n",
    "    def g(self,z):\n",
    "        return self.forward(z), torch.zeros((z.shape[0])).to(z.device)\n",
    "        \n",
    "    def adj(self,mat):\n",
    "        Lw=self.anti_flatten()\n",
    "        Lwt=torch.t(Lw)\n",
    "        D=torch.matmul(Lwt,torch.matmul(mat,Lw))\n",
    "        return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f17f095c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T12:59:48.352712Z",
     "iopub.status.busy": "2024-03-09T12:59:48.351673Z",
     "iopub.status.idle": "2024-03-09T12:59:48.374414Z",
     "shell.execute_reply": "2024-03-09T12:59:48.373432Z",
     "shell.execute_reply.started": "2024-03-09T12:59:48.352662Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    def g_steps(self, z: torch.Tensor) -> List[torch.Tensor]:\\n        Maps latent variable z to observation x\\n        and stores intermediate results.\\n        \\n        xs = [z]\\n        for flow in reversed(self.flows):\\n            xs.append(flow.g(xs[-1]))\\n        return xs\\n\\n    \\n    def latent_log_prob(self, z: torch.Tensor) -> torch.Tensor:\\n        llp=self.latent.log_prob(z)\\n        sum_llp= torch.sum(llp,axis=-1)\\n        return sum_llp\\n \\n    \\n    def f(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:  #forward\\n        Maps observation x to latent variable z.\\n        Additionally, computes the log determinant\\n        of the Jacobian for this transformation.\\n        Inveres of g.\\n        \\n        z, sum_log_abs_det = x, torch.ones(x.size(0)).to(x.device)\\n        for flow in self.flows:\\n            z, log_abs_det = flow.f(z)\\n            sum_log_abs_det += log_abs_det\\n\\n        return z, sum_log_abs_det\\n'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NormalizingFlow(nn.Module):\n",
    "    \n",
    "    def __init__(self, latent: Distribution, flows: List[nn.Module], conv_flows = [], ort=False):\n",
    "        super().__init__()\n",
    "        self.latent = latent\n",
    "        self.flows = flows\n",
    "        self.ort = ort\n",
    "        self.conv_flows = conv_flows\n",
    "\n",
    "    def latent_sample(self, num_samples: int = 1) -> torch.Tensor:\n",
    "        z=self.latent.sample((num_samples,))\n",
    "        return z        \n",
    "\n",
    "    def sample(self, num_samples: int = 1) -> torch.Tensor:\n",
    "        \"\"\"Sample a new observation x by sampling z from\n",
    "        the latent distribution and pass through g.\"\"\"\n",
    "        z=(self.latent_sample(num_samples))\n",
    "        with torch.no_grad():\n",
    "            x, _ = self.g(z)\n",
    "        return x \n",
    "    \n",
    "\n",
    "    def g(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        \n",
    "        x, sum_log_abs_det = z, torch.ones(z.size(0)).to(z.device)\n",
    "        for flow in reversed(self.flows):\n",
    "            x, log_abs_det = flow.g(x)\n",
    "            sum_log_abs_det += log_abs_det\n",
    "        \n",
    "        if self.ort:\n",
    "            x=torch.matmul(x,Ot.to(x.device))\n",
    "        \n",
    "        #x=x*a    \n",
    "        \n",
    "        for flow in reversed(self.conv_flows):\n",
    "            x, log_abs_det = flow.g(x)\n",
    "            sum_log_abs_det += log_abs_det\n",
    "        return x, sum_log_abs_det\n",
    "    \n",
    "        \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.flows)\n",
    "    \n",
    " \n",
    "\"\"\"\n",
    "    def g_steps(self, z: torch.Tensor) -> List[torch.Tensor]:\n",
    "        Maps latent variable z to observation x\n",
    "        and stores intermediate results.\n",
    "        \n",
    "        xs = [z]\n",
    "        for flow in reversed(self.flows):\n",
    "            xs.append(flow.g(xs[-1]))\n",
    "        return xs\n",
    "\n",
    "    \n",
    "    def latent_log_prob(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        llp=self.latent.log_prob(z)\n",
    "        sum_llp= torch.sum(llp,axis=-1)\n",
    "        return sum_llp\n",
    " \n",
    "    \n",
    "    def f(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:  #forward\n",
    "        Maps observation x to latent variable z.\n",
    "        Additionally, computes the log determinant\n",
    "        of the Jacobian for this transformation.\n",
    "        Inveres of g.\n",
    "        \n",
    "        z, sum_log_abs_det = x, torch.ones(x.size(0)).to(x.device)\n",
    "        for flow in self.flows:\n",
    "            z, log_abs_det = flow.f(z)\n",
    "            sum_log_abs_det += log_abs_det\n",
    "\n",
    "        return z, sum_log_abs_det\n",
    "\"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8b1ec3b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T12:59:48.802285Z",
     "iopub.status.busy": "2024-03-09T12:59:48.801179Z",
     "iopub.status.idle": "2024-03-09T12:59:48.821493Z",
     "shell.execute_reply": "2024-03-09T12:59:48.820283Z",
     "shell.execute_reply.started": "2024-03-09T12:59:48.802236Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ThetaNetwork(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_dim: int,\n",
    "        out_dim: int,\n",
    "        num_hidden: int,\n",
    "        hidden_dim: int,\n",
    "        num_params: int,\n",
    "        p_drop: float,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.input = nn.Linear(in_dim, hidden_dim)\n",
    "        self.hidden = nn.ModuleList(\n",
    "            [nn.Sequential(\n",
    "                nn.Linear(hidden_dim, hidden_dim),\n",
    "                nn.Dropout(p=p_drop),\n",
    "                nn.LayerNorm(hidden_dim)\n",
    "            ) for _ in range(num_hidden)]\n",
    "        )\n",
    "\n",
    "        self.num_params = num_params\n",
    "        self.out_dim = out_dim\n",
    "        self.dims = nn.Linear(hidden_dim, out_dim * num_params)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = F.leaky_relu(self.input(x),negative_slope=0.01)\n",
    "        for h in self.hidden:\n",
    "            x = F.leaky_relu(h(x),negative_slope=0.01)\n",
    "\n",
    "        batch_params = self.dims(x).reshape(x.size(0), self.out_dim, -1) \n",
    "        params = batch_params.chunk(self.num_params, dim=-1) \n",
    "        return [p.squeeze(-1) for p in params]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6162dd77-ae0a-4461-bc79-a8bb12341f19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T12:59:49.398793Z",
     "iopub.status.busy": "2024-03-09T12:59:49.397976Z",
     "iopub.status.idle": "2024-03-09T12:59:49.420330Z",
     "shell.execute_reply": "2024-03-09T12:59:49.419254Z",
     "shell.execute_reply.started": "2024-03-09T12:59:49.398753Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Conv_NN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        out_dim,\n",
    "        num_params,\n",
    "        kernel_size=3\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.layers = torch.nn.Sequential(\n",
    "        nn.Conv1d(in_channels=1, out_channels=2, kernel_size=kernel_size,padding=\"same\"), \n",
    "        nn.LeakyReLU(),\n",
    "        nn.LayerNorm(out_dim),    \n",
    "        nn.Conv1d(in_channels=2, out_channels=4, kernel_size=kernel_size,padding=\"same\"), \n",
    "        nn.LeakyReLU(),\n",
    "        nn.LayerNorm(out_dim),    \n",
    "        nn.Conv1d(in_channels=4, out_channels=8, kernel_size=kernel_size,padding=\"same\"),\n",
    "        nn.LeakyReLU(),\n",
    "        nn.LayerNorm(out_dim),\n",
    "        nn.Conv1d(in_channels=8, out_channels=16, kernel_size=kernel_size,padding=\"same\"),\n",
    "        nn.LeakyReLU(),\n",
    "        nn.LayerNorm(out_dim),\n",
    "        nn.Conv1d(in_channels=16, out_channels=20, kernel_size=kernel_size,padding=\"same\"),\n",
    "        nn.LeakyReLU(),\n",
    "        nn.LayerNorm(out_dim),\n",
    "        nn.Conv1d(in_channels=20, out_channels=16, kernel_size=kernel_size,padding=\"same\"),\n",
    "        nn.LeakyReLU(),\n",
    "        nn.LayerNorm(out_dim),\n",
    "        nn.Conv1d(in_channels=16, out_channels=4, kernel_size=kernel_size,padding=\"same\"),\n",
    "        nn.LeakyReLU(),\n",
    "        nn.LayerNorm(out_dim),        \n",
    "        nn.Conv1d(in_channels=4, out_channels=1, kernel_size=kernel_size,padding=\"same\"),\n",
    "        nn.LeakyReLU(),    \n",
    "        )\n",
    "        self.num_params = num_params\n",
    "        self.out_dim = out_dim\n",
    "        self.dims = nn.Linear(out_dim, out_dim * num_params)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x=x.unsqueeze(1)\n",
    "        x=self.layers(x)\n",
    "        x=x.squeeze(1)\n",
    "        batch_params = self.dims(x).reshape(x.size(0),self.out_dim , -1) \n",
    "        params = batch_params.chunk(self.num_params, dim=-1) \n",
    "        return [p.squeeze(-1) for p in params]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "dc7f0bed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T12:59:49.988209Z",
     "iopub.status.busy": "2024-03-09T12:59:49.987384Z",
     "iopub.status.idle": "2024-03-09T12:59:50.003440Z",
     "shell.execute_reply": "2024-03-09T12:59:50.002308Z",
     "shell.execute_reply.started": "2024-03-09T12:59:49.988177Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def SplitFunc(x: torch.Tensor,swap: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    if swap==0:\n",
    "        return x[:,::2], x[:,1::2]\n",
    "    else: \n",
    "        return x[:,1::2], x[:,::2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7f71825a-6aed-44d3-8d61-b49b3c9cff11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T12:59:50.532602Z",
     "iopub.status.busy": "2024-03-09T12:59:50.530967Z",
     "iopub.status.idle": "2024-03-09T12:59:50.559820Z",
     "shell.execute_reply": "2024-03-09T12:59:50.558490Z",
     "shell.execute_reply.started": "2024-03-09T12:59:50.532531Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "I=torch.arange(N_nod)\n",
    "i0=I[::4]\n",
    "i1=I[1::4]\n",
    "i2=I[2::4]\n",
    "i3=I[3::4]\n",
    "mask1=torch.cat((i0,i1))\n",
    "mask2=torch.cat((i2,i3))\n",
    "\n",
    "def pair_SplitFunc(x: torch.Tensor,swap: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    if swap==0:\n",
    "        return x[:,mask1], x[:,mask2]\n",
    "    else: \n",
    "        return x[:,mask2], x[:,mask1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "9586f025",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T18:49:51.664962Z",
     "iopub.status.busy": "2024-03-09T18:49:51.663826Z",
     "iopub.status.idle": "2024-03-09T18:49:51.688047Z",
     "shell.execute_reply": "2024-03-09T18:49:51.686859Z",
     "shell.execute_reply.started": "2024-03-09T18:49:51.664861Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "Normal(loc: torch.Size([100]), scale: torch.Size([100]))\n"
     ]
    }
   ],
   "source": [
    "print(\"start\")\n",
    "from Data import normal_dist\n",
    "\n",
    "def configure_theta():\n",
    "    theta=ThetaNetwork(\n",
    "                in_dim = N_nod//2,\n",
    "                out_dim = N_nod//2,\n",
    "                num_hidden = 12,  #2 to 6\n",
    "                hidden_dim = 2 * N_nod , #100-1024\n",
    "                num_params = 2,\n",
    "                p_drop=0.1,\n",
    "    )\n",
    "    return theta\n",
    "\n",
    "def configure_flows(n_flows):  # n_flows=8,...,12\n",
    "    flows=[]\n",
    "    \"\"\"\n",
    "    flows.append(D(N_nod))\n",
    "    \n",
    "    for k in range(n_flows//2):\n",
    "        flows.append(AffineCouplingLayer(configure_theta(),split=pair_SplitFunc,swap=k%2))\n",
    "        flows.append(L1(N_nod))\n",
    "    \n",
    "    #flows.append(CubicCouplingLayer(configure_theta(),split=pair_SplitFunc,swap=0))\n",
    "    #flows.append(CubicCouplingLayer(configure_theta(),split=pair_SplitFunc,swap=1))\n",
    "    \n",
    "    for k in range(n_flows//2):\n",
    "        flows.append(AffineCouplingLayer(configure_theta(),split=pair_SplitFunc,swap=k%2))\n",
    "    \n",
    "    flows.append(CubicCouplingLayer(configure_theta(),split=pair_SplitFunc,swap=0))\n",
    "    flows.append(CubicCouplingLayer(configure_theta(),split=pair_SplitFunc,swap=1))\n",
    "    \n",
    "    flows.append(CubicCouplingLayer(configure_theta(),split=pair_SplitFunc,swap=0))\n",
    "    flows.append(CubicCouplingLayer(configure_theta(),split=pair_SplitFunc,swap=1))\n",
    "    \n",
    "    flows.append(CubicCouplingLayer(configure_theta(),split=pair_SplitFunc,swap=0))\n",
    "    flows.append(CubicCouplingLayer(configure_theta(),split=pair_SplitFunc,swap=1))\n",
    "    \"\"\"\n",
    "    flows.append(D(N_nod))    \n",
    "    flows = nn.ModuleList(flows)\n",
    "    return flows \n",
    "\n",
    "def configure_conv_flows(n_conv,kernel_size=3):\n",
    "    conv_flows=[]\n",
    "    for i in range(n_conv):\n",
    "        conv_flows.append(AffineCouplingLayer(Conv_NN(N_nod//2,2,kernel_size),split=pair_SplitFunc,swap=i%2))\n",
    "    conv_flows = nn.ModuleList(conv_flows)\n",
    "    return conv_flows\n",
    "\n",
    "print(normal_dist)\n",
    "\n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "5401fb59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T18:49:54.046479Z",
     "iopub.status.busy": "2024-03-09T18:49:54.045493Z",
     "iopub.status.idle": "2024-03-09T18:49:54.062974Z",
     "shell.execute_reply": "2024-03-09T18:49:54.061641Z",
     "shell.execute_reply.started": "2024-03-09T18:49:54.046429Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Pipeline(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        criterion,\n",
    "        optimizer_class=torch.optim.Adam,\n",
    "        optimizer_kwargs={\"lr\": 0.001,\"weight_decay\": 0}\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.loss = criterion\n",
    "        self.optimizer_class = optimizer_class\n",
    "        self.optimizer_kwargs = optimizer_kwargs\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = self.optimizer_class(\n",
    "            self.model.parameters(), **self.optimizer_kwargs\n",
    "        )\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        z = batch\n",
    "        x, log_abs_det = self.model.g(z)\n",
    "        loss = self.loss(x,log_abs_det)\n",
    "        self.log('train_loss', loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        #print(\"---------------------------end epoch---------------------------------\")\n",
    "        pass\n",
    "    \n",
    "    def on_validation_end(self) -> None:\n",
    "        if not self.automatic_optimization:\n",
    "            # Save a checkpoint of the model\n",
    "            ckpt_path = os.path.join(self.trainer.log_dir, 'checkpoints', 'ckpt.pt')\n",
    "            self.trainer.save_checkpoint(ckpt_path, weights_only=True)\n",
    "        return super().on_validation_end()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "3857c540-6428-46f4-ac0a-31aa76f83ad2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T18:49:55.275453Z",
     "iopub.status.busy": "2024-03-09T18:49:55.274454Z",
     "iopub.status.idle": "2024-03-09T18:49:55.293299Z",
     "shell.execute_reply": "2024-03-09T18:49:55.292240Z",
     "shell.execute_reply.started": "2024-03-09T18:49:55.275413Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from NFoscillator import Oscillator\n",
    "from NFrel_oscillator import Rel_Oscillator\n",
    "from NFur_oscillator import Ur_Oscillator\n",
    "KL_osc=Oscillator.make_KL(Oscillator)\n",
    "KL_rel001=Rel_Oscillator.make_KL(Rel_Oscillator,sigma=0.01)\n",
    "KL_rel01=Rel_Oscillator.make_KL(Rel_Oscillator,sigma=0.1)\n",
    "KL_rel1=Rel_Oscillator.make_KL(Rel_Oscillator,sigma=1)\n",
    "KL_ur=Ur_Oscillator.make_KL(Ur_Oscillator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "558e4bef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T18:50:45.365477Z",
     "iopub.status.busy": "2024-03-09T18:50:45.364395Z",
     "iopub.status.idle": "2024-03-09T18:58:33.619108Z",
     "shell.execute_reply": "2024-03-09T18:58:33.617537Z",
     "shell.execute_reply.started": "2024-03-09T18:50:45.365434Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kernel/lib/python3.10/site-packages/wurlitzer.py:209: RuntimeWarning: Failed to set pipe buffer size\n",
      "  warnings.warn(\"Failed to set pipe buffer size\", RuntimeWarning)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type            | Params\n",
      "------------------------------------------\n",
      "0 | model | NormalizingFlow | 100   \n",
      "1 | loss  | KL_with_S       | 0     \n",
      "------------------------------------------\n",
      "100       Trainable params\n",
      "0         Non-trainable params\n",
      "100       Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05d6c25cd8eb4791992f8ba4a84f52ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    }
   ],
   "source": [
    "from Data import train_loader\n",
    "\n",
    "set_random_seed(42)\n",
    "\n",
    "nf=NormalizingFlow(latent=normal_dist,flows=configure_flows(24),conv_flows=configure_conv_flows(0,kernel_size=8),ort=True)\n",
    "pipeline=Pipeline(model=nf, criterion=KL_ur, optimizer_class=torch.optim.Adam, optimizer_kwargs={\"lr\": 0.001,\"weight_decay\":0.0})\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=50,\n",
    "    logger=TensorBoardLogger(save_dir=f\"logs/nf\"),\n",
    "    num_sanity_val_steps=0,\n",
    "    log_every_n_steps=1,\n",
    "    accumulate_grad_batches=4\n",
    ")\n",
    "\n",
    "trainer.fit(model=pipeline, train_dataloaders=train_loader)\n",
    "torch.save(nf.state_dict(), \"model_weights1.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0c2a7174-bbe4-47a4-a6dc-5b9fc9f320c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T21:00:26.769258Z",
     "iopub.status.busy": "2024-03-08T21:00:26.768545Z",
     "iopub.status.idle": "2024-03-08T21:00:26.779634Z",
     "shell.execute_reply": "2024-03-08T21:00:26.778866Z",
     "shell.execute_reply.started": "2024-03-08T21:00:26.769211Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.997873416618259\n"
     ]
    }
   ],
   "source": [
    "from NFandist import calc_Z\n",
    "import numpy as np\n",
    "print(-np.log(calc_Z(N_nod,beta)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "bf52257c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T13:33:13.461828Z",
     "iopub.status.busy": "2024-03-09T13:33:13.461058Z",
     "iopub.status.idle": "2024-03-09T13:33:15.246455Z",
     "shell.execute_reply": "2024-03-09T13:33:15.242197Z",
     "shell.execute_reply.started": "2024-03-09T13:33:13.461787Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for NormalizingFlow:\n\tMissing key(s) in state_dict: \"flows.14.weight\", \"flows.16.weight\", \"flows.18.weight\", \"flows.20.weight\", \"flows.22.weight\", \"flows.23.theta.input.weight\", \"flows.23.theta.input.bias\", \"flows.23.theta.hidden.0.0.weight\", \"flows.23.theta.hidden.0.0.bias\", \"flows.23.theta.hidden.0.2.weight\", \"flows.23.theta.hidden.0.2.bias\", \"flows.23.theta.hidden.1.0.weight\", \"flows.23.theta.hidden.1.0.bias\", \"flows.23.theta.hidden.1.2.weight\", \"flows.23.theta.hidden.1.2.bias\", \"flows.23.theta.hidden.2.0.weight\", \"flows.23.theta.hidden.2.0.bias\", \"flows.23.theta.hidden.2.2.weight\", \"flows.23.theta.hidden.2.2.bias\", \"flows.23.theta.hidden.3.0.weight\", \"flows.23.theta.hidden.3.0.bias\", \"flows.23.theta.hidden.3.2.weight\", \"flows.23.theta.hidden.3.2.bias\", \"flows.23.theta.hidden.4.0.weight\", \"flows.23.theta.hidden.4.0.bias\", \"flows.23.theta.hidden.4.2.weight\", \"flows.23.theta.hidden.4.2.bias\", \"flows.23.theta.hidden.5.0.weight\", \"flows.23.theta.hidden.5.0.bias\", \"flows.23.theta.hidden.5.2.weight\", \"flows.23.theta.hidden.5.2.bias\", \"flows.23.theta.hidden.6.0.weight\", \"flows.23.theta.hidden.6.0.bias\", \"flows.23.theta.hidden.6.2.weight\", \"flows.23.theta.hidden.6.2.bias\", \"flows.23.theta.hidden.7.0.weight\", \"flows.23.theta.hidden.7.0.bias\", \"flows.23.theta.hidden.7.2.weight\", \"flows.23.theta.hidden.7.2.bias\", \"flows.23.theta.hidden.8.0.weight\", \"flows.23.theta.hidden.8.0.bias\", \"flows.23.theta.hidden.8.2.weight\", \"flows.23.theta.hidden.8.2.bias\", \"flows.23.theta.hidden.9.0.weight\", \"flows.23.theta.hidden.9.0.bias\", \"flows.23.theta.hidden.9.2.weight\", \"flows.23.theta.hidden.9.2.bias\", \"flows.23.theta.hidden.10.0.weight\", \"flows.23.theta.hidden.10.0.bias\", \"flows.23.theta.hidden.10.2.weight\", \"flows.23.theta.hidden.10.2.bias\", \"flows.23.theta.hidden.11.0.weight\", \"flows.23.theta.hidden.11.0.bias\", \"flows.23.theta.hidden.11.2.weight\", \"flows.23.theta.hidden.11.2.bias\", \"flows.23.theta.dims.weight\", \"flows.23.theta.dims.bias\", \"flows.24.weight\", \"flows.25.theta.input.weight\", \"flows.25.theta.input.bias\", \"flows.25.theta.hidden.0.0.weight\", \"flows.25.theta.hidden.0.0.bias\", \"flows.25.theta.hidden.0.2.weight\", \"flows.25.theta.hidden.0.2.bias\", \"flows.25.theta.hidden.1.0.weight\", \"flows.25.theta.hidden.1.0.bias\", \"flows.25.theta.hidden.1.2.weight\", \"flows.25.theta.hidden.1.2.bias\", \"flows.25.theta.hidden.2.0.weight\", \"flows.25.theta.hidden.2.0.bias\", \"flows.25.theta.hidden.2.2.weight\", \"flows.25.theta.hidden.2.2.bias\", \"flows.25.theta.hidden.3.0.weight\", \"flows.25.theta.hidden.3.0.bias\", \"flows.25.theta.hidden.3.2.weight\", \"flows.25.theta.hidden.3.2.bias\", \"flows.25.theta.hidden.4.0.weight\", \"flows.25.theta.hidden.4.0.bias\", \"flows.25.theta.hidden.4.2.weight\", \"flows.25.theta.hidden.4.2.bias\", \"flows.25.theta.hidden.5.0.weight\", \"flows.25.theta.hidden.5.0.bias\", \"flows.25.theta.hidden.5.2.weight\", \"flows.25.theta.hidden.5.2.bias\", \"flows.25.theta.hidden.6.0.weight\", \"flows.25.theta.hidden.6.0.bias\", \"flows.25.theta.hidden.6.2.weight\", \"flows.25.theta.hidden.6.2.bias\", \"flows.25.theta.hidden.7.0.weight\", \"flows.25.theta.hidden.7.0.bias\", \"flows.25.theta.hidden.7.2.weight\", \"flows.25.theta.hidden.7.2.bias\", \"flows.25.theta.hidden.8.0.weight\", \"flows.25.theta.hidden.8.0.bias\", \"flows.25.theta.hidden.8.2.weight\", \"flows.25.theta.hidden.8.2.bias\", \"flows.25.theta.hidden.9.0.weight\", \"flows.25.theta.hidden.9.0.bias\", \"flows.25.theta.hidden.9.2.weight\", \"flows.25.theta.hidden.9.2.bias\", \"flows.25.theta.hidden.10.0.weight\", \"flows.25.theta.hidden.10.0.bias\", \"flows.25.theta.hidden.10.2.weight\", \"flows.25.theta.hidden.10.2.bias\", \"flows.25.theta.hidden.11.0.weight\", \"flows.25.theta.hidden.11.0.bias\", \"flows.25.theta.hidden.11.2.weight\", \"flows.25.theta.hidden.11.2.bias\", \"flows.25.theta.dims.weight\", \"flows.25.theta.dims.bias\", \"flows.26.theta.input.weight\", \"flows.26.theta.input.bias\", \"flows.26.theta.hidden.0.0.weight\", \"flows.26.theta.hidden.0.0.bias\", \"flows.26.theta.hidden.0.2.weight\", \"flows.26.theta.hidden.0.2.bias\", \"flows.26.theta.hidden.1.0.weight\", \"flows.26.theta.hidden.1.0.bias\", \"flows.26.theta.hidden.1.2.weight\", \"flows.26.theta.hidden.1.2.bias\", \"flows.26.theta.hidden.2.0.weight\", \"flows.26.theta.hidden.2.0.bias\", \"flows.26.theta.hidden.2.2.weight\", \"flows.26.theta.hidden.2.2.bias\", \"flows.26.theta.hidden.3.0.weight\", \"flows.26.theta.hidden.3.0.bias\", \"flows.26.theta.hidden.3.2.weight\", \"flows.26.theta.hidden.3.2.bias\", \"flows.26.theta.hidden.4.0.weight\", \"flows.26.theta.hidden.4.0.bias\", \"flows.26.theta.hidden.4.2.weight\", \"flows.26.theta.hidden.4.2.bias\", \"flows.26.theta.hidden.5.0.weight\", \"flows.26.theta.hidden.5.0.bias\", \"flows.26.theta.hidden.5.2.weight\", \"flows.26.theta.hidden.5.2.bias\", \"flows.26.theta.hidden.6.0.weight\", \"flows.26.theta.hidden.6.0.bias\", \"flows.26.theta.hidden.6.2.weight\", \"flows.26.theta.hidden.6.2.bias\", \"flows.26.theta.hidden.7.0.weight\", \"flows.26.theta.hidden.7.0.bias\", \"flows.26.theta.hidden.7.2.weight\", \"flows.26.theta.hidden.7.2.bias\", \"flows.26.theta.hidden.8.0.weight\", \"flows.26.theta.hidden.8.0.bias\", \"flows.26.theta.hidden.8.2.weight\", \"flows.26.theta.hidden.8.2.bias\", \"flows.26.theta.hidden.9.0.weight\", \"flows.26.theta.hidden.9.0.bias\", \"flows.26.theta.hidden.9.2.weight\", \"flows.26.theta.hidden.9.2.bias\", \"flows.26.theta.hidden.10.0.weight\", \"flows.26.theta.hidden.10.0.bias\", \"flows.26.theta.hidden.10.2.weight\", \"flows.26.theta.hidden.10.2.bias\", \"flows.26.theta.hidden.11.0.weight\", \"flows.26.theta.hidden.11.0.bias\", \"flows.26.theta.hidden.11.2.weight\", \"flows.26.theta.hidden.11.2.bias\", \"flows.26.theta.dims.weight\", \"flows.26.theta.dims.bias\", \"flows.27.theta.input.weight\", \"flows.27.theta.input.bias\", \"flows.27.theta.hidden.0.0.weight\", \"flows.27.theta.hidden.0.0.bias\", \"flows.27.theta.hidden.0.2.weight\", \"flows.27.theta.hidden.0.2.bias\", \"flows.27.theta.hidden.1.0.weight\", \"flows.27.theta.hidden.1.0.bias\", \"flows.27.theta.hidden.1.2.weight\", \"flows.27.theta.hidden.1.2.bias\", \"flows.27.theta.hidden.2.0.weight\", \"flows.27.theta.hidden.2.0.bias\", \"flows.27.theta.hidden.2.2.weight\", \"flows.27.theta.hidden.2.2.bias\", \"flows.27.theta.hidden.3.0.weight\", \"flows.27.theta.hidden.3.0.bias\", \"flows.27.theta.hidden.3.2.weight\", \"flows.27.theta.hidden.3.2.bias\", \"flows.27.theta.hidden.4.0.weight\", \"flows.27.theta.hidden.4.0.bias\", \"flows.27.theta.hidden.4.2.weight\", \"flows.27.theta.hidden.4.2.bias\", \"flows.27.theta.hidden.5.0.weight\", \"flows.27.theta.hidden.5.0.bias\", \"flows.27.theta.hidden.5.2.weight\", \"flows.27.theta.hidden.5.2.bias\", \"flows.27.theta.hidden.6.0.weight\", \"flows.27.theta.hidden.6.0.bias\", \"flows.27.theta.hidden.6.2.weight\", \"flows.27.theta.hidden.6.2.bias\", \"flows.27.theta.hidden.7.0.weight\", \"flows.27.theta.hidden.7.0.bias\", \"flows.27.theta.hidden.7.2.weight\", \"flows.27.theta.hidden.7.2.bias\", \"flows.27.theta.hidden.8.0.weight\", \"flows.27.theta.hidden.8.0.bias\", \"flows.27.theta.hidden.8.2.weight\", \"flows.27.theta.hidden.8.2.bias\", \"flows.27.theta.hidden.9.0.weight\", \"flows.27.theta.hidden.9.0.bias\", \"flows.27.theta.hidden.9.2.weight\", \"flows.27.theta.hidden.9.2.bias\", \"flows.27.theta.hidden.10.0.weight\", \"flows.27.theta.hidden.10.0.bias\", \"flows.27.theta.hidden.10.2.weight\", \"flows.27.theta.hidden.10.2.bias\", \"flows.27.theta.hidden.11.0.weight\", \"flows.27.theta.hidden.11.0.bias\", \"flows.27.theta.hidden.11.2.weight\", \"flows.27.theta.hidden.11.2.bias\", \"flows.27.theta.dims.weight\", \"flows.27.theta.dims.bias\", \"flows.28.theta.input.weight\", \"flows.28.theta.input.bias\", \"flows.28.theta.hidden.0.0.weight\", \"flows.28.theta.hidden.0.0.bias\", \"flows.28.theta.hidden.0.2.weight\", \"flows.28.theta.hidden.0.2.bias\", \"flows.28.theta.hidden.1.0.weight\", \"flows.28.theta.hidden.1.0.bias\", \"flows.28.theta.hidden.1.2.weight\", \"flows.28.theta.hidden.1.2.bias\", \"flows.28.theta.hidden.2.0.weight\", \"flows.28.theta.hidden.2.0.bias\", \"flows.28.theta.hidden.2.2.weight\", \"flows.28.theta.hidden.2.2.bias\", \"flows.28.theta.hidden.3.0.weight\", \"flows.28.theta.hidden.3.0.bias\", \"flows.28.theta.hidden.3.2.weight\", \"flows.28.theta.hidden.3.2.bias\", \"flows.28.theta.hidden.4.0.weight\", \"flows.28.theta.hidden.4.0.bias\", \"flows.28.theta.hidden.4.2.weight\", \"flows.28.theta.hidden.4.2.bias\", \"flows.28.theta.hidden.5.0.weight\", \"flows.28.theta.hidden.5.0.bias\", \"flows.28.theta.hidden.5.2.weight\", \"flows.28.theta.hidden.5.2.bias\", \"flows.28.theta.hidden.6.0.weight\", \"flows.28.theta.hidden.6.0.bias\", \"flows.28.theta.hidden.6.2.weight\", \"flows.28.theta.hidden.6.2.bias\", \"flows.28.theta.hidden.7.0.weight\", \"flows.28.theta.hidden.7.0.bias\", \"flows.28.theta.hidden.7.2.weight\", \"flows.28.theta.hidden.7.2.bias\", \"flows.28.theta.hidden.8.0.weight\", \"flows.28.theta.hidden.8.0.bias\", \"flows.28.theta.hidden.8.2.weight\", \"flows.28.theta.hidden.8.2.bias\", \"flows.28.theta.hidden.9.0.weight\", \"flows.28.theta.hidden.9.0.bias\", \"flows.28.theta.hidden.9.2.weight\", \"flows.28.theta.hidden.9.2.bias\", \"flows.28.theta.hidden.10.0.weight\", \"flows.28.theta.hidden.10.0.bias\", \"flows.28.theta.hidden.10.2.weight\", \"flows.28.theta.hidden.10.2.bias\", \"flows.28.theta.hidden.11.0.weight\", \"flows.28.theta.hidden.11.0.bias\", \"flows.28.theta.hidden.11.2.weight\", \"flows.28.theta.hidden.11.2.bias\", \"flows.28.theta.dims.weight\", \"flows.28.theta.dims.bias\", \"flows.29.theta.input.weight\", \"flows.29.theta.input.bias\", \"flows.29.theta.hidden.0.0.weight\", \"flows.29.theta.hidden.0.0.bias\", \"flows.29.theta.hidden.0.2.weight\", \"flows.29.theta.hidden.0.2.bias\", \"flows.29.theta.hidden.1.0.weight\", \"flows.29.theta.hidden.1.0.bias\", \"flows.29.theta.hidden.1.2.weight\", \"flows.29.theta.hidden.1.2.bias\", \"flows.29.theta.hidden.2.0.weight\", \"flows.29.theta.hidden.2.0.bias\", \"flows.29.theta.hidden.2.2.weight\", \"flows.29.theta.hidden.2.2.bias\", \"flows.29.theta.hidden.3.0.weight\", \"flows.29.theta.hidden.3.0.bias\", \"flows.29.theta.hidden.3.2.weight\", \"flows.29.theta.hidden.3.2.bias\", \"flows.29.theta.hidden.4.0.weight\", \"flows.29.theta.hidden.4.0.bias\", \"flows.29.theta.hidden.4.2.weight\", \"flows.29.theta.hidden.4.2.bias\", \"flows.29.theta.hidden.5.0.weight\", \"flows.29.theta.hidden.5.0.bias\", \"flows.29.theta.hidden.5.2.weight\", \"flows.29.theta.hidden.5.2.bias\", \"flows.29.theta.hidden.6.0.weight\", \"flows.29.theta.hidden.6.0.bias\", \"flows.29.theta.hidden.6.2.weight\", \"flows.29.theta.hidden.6.2.bias\", \"flows.29.theta.hidden.7.0.weight\", \"flows.29.theta.hidden.7.0.bias\", \"flows.29.theta.hidden.7.2.weight\", \"flows.29.theta.hidden.7.2.bias\", \"flows.29.theta.hidden.8.0.weight\", \"flows.29.theta.hidden.8.0.bias\", \"flows.29.theta.hidden.8.2.weight\", \"flows.29.theta.hidden.8.2.bias\", \"flows.29.theta.hidden.9.0.weight\", \"flows.29.theta.hidden.9.0.bias\", \"flows.29.theta.hidden.9.2.weight\", \"flows.29.theta.hidden.9.2.bias\", \"flows.29.theta.hidden.10.0.weight\", \"flows.29.theta.hidden.10.0.bias\", \"flows.29.theta.hidden.10.2.weight\", \"flows.29.theta.hidden.10.2.bias\", \"flows.29.theta.hidden.11.0.weight\", \"flows.29.theta.hidden.11.0.bias\", \"flows.29.theta.hidden.11.2.weight\", \"flows.29.theta.hidden.11.2.bias\", \"flows.29.theta.dims.weight\", \"flows.29.theta.dims.bias\", \"flows.30.theta.input.weight\", \"flows.30.theta.input.bias\", \"flows.30.theta.hidden.0.0.weight\", \"flows.30.theta.hidden.0.0.bias\", \"flows.30.theta.hidden.0.2.weight\", \"flows.30.theta.hidden.0.2.bias\", \"flows.30.theta.hidden.1.0.weight\", \"flows.30.theta.hidden.1.0.bias\", \"flows.30.theta.hidden.1.2.weight\", \"flows.30.theta.hidden.1.2.bias\", \"flows.30.theta.hidden.2.0.weight\", \"flows.30.theta.hidden.2.0.bias\", \"flows.30.theta.hidden.2.2.weight\", \"flows.30.theta.hidden.2.2.bias\", \"flows.30.theta.hidden.3.0.weight\", \"flows.30.theta.hidden.3.0.bias\", \"flows.30.theta.hidden.3.2.weight\", \"flows.30.theta.hidden.3.2.bias\", \"flows.30.theta.hidden.4.0.weight\", \"flows.30.theta.hidden.4.0.bias\", \"flows.30.theta.hidden.4.2.weight\", \"flows.30.theta.hidden.4.2.bias\", \"flows.30.theta.hidden.5.0.weight\", \"flows.30.theta.hidden.5.0.bias\", \"flows.30.theta.hidden.5.2.weight\", \"flows.30.theta.hidden.5.2.bias\", \"flows.30.theta.hidden.6.0.weight\", \"flows.30.theta.hidden.6.0.bias\", \"flows.30.theta.hidden.6.2.weight\", \"flows.30.theta.hidden.6.2.bias\", \"flows.30.theta.hidden.7.0.weight\", \"flows.30.theta.hidden.7.0.bias\", \"flows.30.theta.hidden.7.2.weight\", \"flows.30.theta.hidden.7.2.bias\", \"flows.30.theta.hidden.8.0.weight\", \"flows.30.theta.hidden.8.0.bias\", \"flows.30.theta.hidden.8.2.weight\", \"flows.30.theta.hidden.8.2.bias\", \"flows.30.theta.hidden.9.0.weight\", \"flows.30.theta.hidden.9.0.bias\", \"flows.30.theta.hidden.9.2.weight\", \"flows.30.theta.hidden.9.2.bias\", \"flows.30.theta.hidden.10.0.weight\", \"flows.30.theta.hidden.10.0.bias\", \"flows.30.theta.hidden.10.2.weight\", \"flows.30.theta.hidden.10.2.bias\", \"flows.30.theta.hidden.11.0.weight\", \"flows.30.theta.hidden.11.0.bias\", \"flows.30.theta.hidden.11.2.weight\", \"flows.30.theta.hidden.11.2.bias\", \"flows.30.theta.dims.weight\", \"flows.30.theta.dims.bias\", \"flows.31.theta.input.weight\", \"flows.31.theta.input.bias\", \"flows.31.theta.hidden.0.0.weight\", \"flows.31.theta.hidden.0.0.bias\", \"flows.31.theta.hidden.0.2.weight\", \"flows.31.theta.hidden.0.2.bias\", \"flows.31.theta.hidden.1.0.weight\", \"flows.31.theta.hidden.1.0.bias\", \"flows.31.theta.hidden.1.2.weight\", \"flows.31.theta.hidden.1.2.bias\", \"flows.31.theta.hidden.2.0.weight\", \"flows.31.theta.hidden.2.0.bias\", \"flows.31.theta.hidden.2.2.weight\", \"flows.31.theta.hidden.2.2.bias\", \"flows.31.theta.hidden.3.0.weight\", \"flows.31.theta.hidden.3.0.bias\", \"flows.31.theta.hidden.3.2.weight\", \"flows.31.theta.hidden.3.2.bias\", \"flows.31.theta.hidden.4.0.weight\", \"flows.31.theta.hidden.4.0.bias\", \"flows.31.theta.hidden.4.2.weight\", \"flows.31.theta.hidden.4.2.bias\", \"flows.31.theta.hidden.5.0.weight\", \"flows.31.theta.hidden.5.0.bias\", \"flows.31.theta.hidden.5.2.weight\", \"flows.31.theta.hidden.5.2.bias\", \"flows.31.theta.hidden.6.0.weight\", \"flows.31.theta.hidden.6.0.bias\", \"flows.31.theta.hidden.6.2.weight\", \"flows.31.theta.hidden.6.2.bias\", \"flows.31.theta.hidden.7.0.weight\", \"flows.31.theta.hidden.7.0.bias\", \"flows.31.theta.hidden.7.2.weight\", \"flows.31.theta.hidden.7.2.bias\", \"flows.31.theta.hidden.8.0.weight\", \"flows.31.theta.hidden.8.0.bias\", \"flows.31.theta.hidden.8.2.weight\", \"flows.31.theta.hidden.8.2.bias\", \"flows.31.theta.hidden.9.0.weight\", \"flows.31.theta.hidden.9.0.bias\", \"flows.31.theta.hidden.9.2.weight\", \"flows.31.theta.hidden.9.2.bias\", \"flows.31.theta.hidden.10.0.weight\", \"flows.31.theta.hidden.10.0.bias\", \"flows.31.theta.hidden.10.2.weight\", \"flows.31.theta.hidden.10.2.bias\", \"flows.31.theta.hidden.11.0.weight\", \"flows.31.theta.hidden.11.0.bias\", \"flows.31.theta.hidden.11.2.weight\", \"flows.31.theta.hidden.11.2.bias\", \"flows.31.theta.dims.weight\", \"flows.31.theta.dims.bias\", \"flows.32.theta.input.weight\", \"flows.32.theta.input.bias\", \"flows.32.theta.hidden.0.0.weight\", \"flows.32.theta.hidden.0.0.bias\", \"flows.32.theta.hidden.0.2.weight\", \"flows.32.theta.hidden.0.2.bias\", \"flows.32.theta.hidden.1.0.weight\", \"flows.32.theta.hidden.1.0.bias\", \"flows.32.theta.hidden.1.2.weight\", \"flows.32.theta.hidden.1.2.bias\", \"flows.32.theta.hidden.2.0.weight\", \"flows.32.theta.hidden.2.0.bias\", \"flows.32.theta.hidden.2.2.weight\", \"flows.32.theta.hidden.2.2.bias\", \"flows.32.theta.hidden.3.0.weight\", \"flows.32.theta.hidden.3.0.bias\", \"flows.32.theta.hidden.3.2.weight\", \"flows.32.theta.hidden.3.2.bias\", \"flows.32.theta.hidden.4.0.weight\", \"flows.32.theta.hidden.4.0.bias\", \"flows.32.theta.hidden.4.2.weight\", \"flows.32.theta.hidden.4.2.bias\", \"flows.32.theta.hidden.5.0.weight\", \"flows.32.theta.hidden.5.0.bias\", \"flows.32.theta.hidden.5.2.weight\", \"flows.32.theta.hidden.5.2.bias\", \"flows.32.theta.hidden.6.0.weight\", \"flows.32.theta.hidden.6.0.bias\", \"flows.32.theta.hidden.6.2.weight\", \"flows.32.theta.hidden.6.2.bias\", \"flows.32.theta.hidden.7.0.weight\", \"flows.32.theta.hidden.7.0.bias\", \"flows.32.theta.hidden.7.2.weight\", \"flows.32.theta.hidden.7.2.bias\", \"flows.32.theta.hidden.8.0.weight\", \"flows.32.theta.hidden.8.0.bias\", \"flows.32.theta.hidden.8.2.weight\", \"flows.32.theta.hidden.8.2.bias\", \"flows.32.theta.hidden.9.0.weight\", \"flows.32.theta.hidden.9.0.bias\", \"flows.32.theta.hidden.9.2.weight\", \"flows.32.theta.hidden.9.2.bias\", \"flows.32.theta.hidden.10.0.weight\", \"flows.32.theta.hidden.10.0.bias\", \"flows.32.theta.hidden.10.2.weight\", \"flows.32.theta.hidden.10.2.bias\", \"flows.32.theta.hidden.11.0.weight\", \"flows.32.theta.hidden.11.0.bias\", \"flows.32.theta.hidden.11.2.weight\", \"flows.32.theta.hidden.11.2.bias\", \"flows.32.theta.dims.weight\", \"flows.32.theta.dims.bias\", \"flows.33.theta.input.weight\", \"flows.33.theta.input.bias\", \"flows.33.theta.hidden.0.0.weight\", \"flows.33.theta.hidden.0.0.bias\", \"flows.33.theta.hidden.0.2.weight\", \"flows.33.theta.hidden.0.2.bias\", \"flows.33.theta.hidden.1.0.weight\", \"flows.33.theta.hidden.1.0.bias\", \"flows.33.theta.hidden.1.2.weight\", \"flows.33.theta.hidden.1.2.bias\", \"flows.33.theta.hidden.2.0.weight\", \"flows.33.theta.hidden.2.0.bias\", \"flows.33.theta.hidden.2.2.weight\", \"flows.33.theta.hidden.2.2.bias\", \"flows.33.theta.hidden.3.0.weight\", \"flows.33.theta.hidden.3.0.bias\", \"flows.33.theta.hidden.3.2.weight\", \"flows.33.theta.hidden.3.2.bias\", \"flows.33.theta.hidden.4.0.weight\", \"flows.33.theta.hidden.4.0.bias\", \"flows.33.theta.hidden.4.2.weight\", \"flows.33.theta.hidden.4.2.bias\", \"flows.33.theta.hidden.5.0.weight\", \"flows.33.theta.hidden.5.0.bias\", \"flows.33.theta.hidden.5.2.weight\", \"flows.33.theta.hidden.5.2.bias\", \"flows.33.theta.hidden.6.0.weight\", \"flows.33.theta.hidden.6.0.bias\", \"flows.33.theta.hidden.6.2.weight\", \"flows.33.theta.hidden.6.2.bias\", \"flows.33.theta.hidden.7.0.weight\", \"flows.33.theta.hidden.7.0.bias\", \"flows.33.theta.hidden.7.2.weight\", \"flows.33.theta.hidden.7.2.bias\", \"flows.33.theta.hidden.8.0.weight\", \"flows.33.theta.hidden.8.0.bias\", \"flows.33.theta.hidden.8.2.weight\", \"flows.33.theta.hidden.8.2.bias\", \"flows.33.theta.hidden.9.0.weight\", \"flows.33.theta.hidden.9.0.bias\", \"flows.33.theta.hidden.9.2.weight\", \"flows.33.theta.hidden.9.2.bias\", \"flows.33.theta.hidden.10.0.weight\", \"flows.33.theta.hidden.10.0.bias\", \"flows.33.theta.hidden.10.2.weight\", \"flows.33.theta.hidden.10.2.bias\", \"flows.33.theta.hidden.11.0.weight\", \"flows.33.theta.hidden.11.0.bias\", \"flows.33.theta.hidden.11.2.weight\", \"flows.33.theta.hidden.11.2.bias\", \"flows.33.theta.dims.weight\", \"flows.33.theta.dims.bias\", \"flows.34.theta.input.weight\", \"flows.34.theta.input.bias\", \"flows.34.theta.hidden.0.0.weight\", \"flows.34.theta.hidden.0.0.bias\", \"flows.34.theta.hidden.0.2.weight\", \"flows.34.theta.hidden.0.2.bias\", \"flows.34.theta.hidden.1.0.weight\", \"flows.34.theta.hidden.1.0.bias\", \"flows.34.theta.hidden.1.2.weight\", \"flows.34.theta.hidden.1.2.bias\", \"flows.34.theta.hidden.2.0.weight\", \"flows.34.theta.hidden.2.0.bias\", \"flows.34.theta.hidden.2.2.weight\", \"flows.34.theta.hidden.2.2.bias\", \"flows.34.theta.hidden.3.0.weight\", \"flows.34.theta.hidden.3.0.bias\", \"flows.34.theta.hidden.3.2.weight\", \"flows.34.theta.hidden.3.2.bias\", \"flows.34.theta.hidden.4.0.weight\", \"flows.34.theta.hidden.4.0.bias\", \"flows.34.theta.hidden.4.2.weight\", \"flows.34.theta.hidden.4.2.bias\", \"flows.34.theta.hidden.5.0.weight\", \"flows.34.theta.hidden.5.0.bias\", \"flows.34.theta.hidden.5.2.weight\", \"flows.34.theta.hidden.5.2.bias\", \"flows.34.theta.hidden.6.0.weight\", \"flows.34.theta.hidden.6.0.bias\", \"flows.34.theta.hidden.6.2.weight\", \"flows.34.theta.hidden.6.2.bias\", \"flows.34.theta.hidden.7.0.weight\", \"flows.34.theta.hidden.7.0.bias\", \"flows.34.theta.hidden.7.2.weight\", \"flows.34.theta.hidden.7.2.bias\", \"flows.34.theta.hidden.8.0.weight\", \"flows.34.theta.hidden.8.0.bias\", \"flows.34.theta.hidden.8.2.weight\", \"flows.34.theta.hidden.8.2.bias\", \"flows.34.theta.hidden.9.0.weight\", \"flows.34.theta.hidden.9.0.bias\", \"flows.34.theta.hidden.9.2.weight\", \"flows.34.theta.hidden.9.2.bias\", \"flows.34.theta.hidden.10.0.weight\", \"flows.34.theta.hidden.10.0.bias\", \"flows.34.theta.hidden.10.2.weight\", \"flows.34.theta.hidden.10.2.bias\", \"flows.34.theta.hidden.11.0.weight\", \"flows.34.theta.hidden.11.0.bias\", \"flows.34.theta.hidden.11.2.weight\", \"flows.34.theta.hidden.11.2.bias\", \"flows.34.theta.dims.weight\", \"flows.34.theta.dims.bias\", \"flows.35.theta.input.weight\", \"flows.35.theta.input.bias\", \"flows.35.theta.hidden.0.0.weight\", \"flows.35.theta.hidden.0.0.bias\", \"flows.35.theta.hidden.0.2.weight\", \"flows.35.theta.hidden.0.2.bias\", \"flows.35.theta.hidden.1.0.weight\", \"flows.35.theta.hidden.1.0.bias\", \"flows.35.theta.hidden.1.2.weight\", \"flows.35.theta.hidden.1.2.bias\", \"flows.35.theta.hidden.2.0.weight\", \"flows.35.theta.hidden.2.0.bias\", \"flows.35.theta.hidden.2.2.weight\", \"flows.35.theta.hidden.2.2.bias\", \"flows.35.theta.hidden.3.0.weight\", \"flows.35.theta.hidden.3.0.bias\", \"flows.35.theta.hidden.3.2.weight\", \"flows.35.theta.hidden.3.2.bias\", \"flows.35.theta.hidden.4.0.weight\", \"flows.35.theta.hidden.4.0.bias\", \"flows.35.theta.hidden.4.2.weight\", \"flows.35.theta.hidden.4.2.bias\", \"flows.35.theta.hidden.5.0.weight\", \"flows.35.theta.hidden.5.0.bias\", \"flows.35.theta.hidden.5.2.weight\", \"flows.35.theta.hidden.5.2.bias\", \"flows.35.theta.hidden.6.0.weight\", \"flows.35.theta.hidden.6.0.bias\", \"flows.35.theta.hidden.6.2.weight\", \"flows.35.theta.hidden.6.2.bias\", \"flows.35.theta.hidden.7.0.weight\", \"flows.35.theta.hidden.7.0.bias\", \"flows.35.theta.hidden.7.2.weight\", \"flows.35.theta.hidden.7.2.bias\", \"flows.35.theta.hidden.8.0.weight\", \"flows.35.theta.hidden.8.0.bias\", \"flows.35.theta.hidden.8.2.weight\", \"flows.35.theta.hidden.8.2.bias\", \"flows.35.theta.hidden.9.0.weight\", \"flows.35.theta.hidden.9.0.bias\", \"flows.35.theta.hidden.9.2.weight\", \"flows.35.theta.hidden.9.2.bias\", \"flows.35.theta.hidden.10.0.weight\", \"flows.35.theta.hidden.10.0.bias\", \"flows.35.theta.hidden.10.2.weight\", \"flows.35.theta.hidden.10.2.bias\", \"flows.35.theta.hidden.11.0.weight\", \"flows.35.theta.hidden.11.0.bias\", \"flows.35.theta.hidden.11.2.weight\", \"flows.35.theta.hidden.11.2.bias\", \"flows.35.theta.dims.weight\", \"flows.35.theta.dims.bias\", \"flows.36.theta.input.weight\", \"flows.36.theta.input.bias\", \"flows.36.theta.hidden.0.0.weight\", \"flows.36.theta.hidden.0.0.bias\", \"flows.36.theta.hidden.0.2.weight\", \"flows.36.theta.hidden.0.2.bias\", \"flows.36.theta.hidden.1.0.weight\", \"flows.36.theta.hidden.1.0.bias\", \"flows.36.theta.hidden.1.2.weight\", \"flows.36.theta.hidden.1.2.bias\", \"flows.36.theta.hidden.2.0.weight\", \"flows.36.theta.hidden.2.0.bias\", \"flows.36.theta.hidden.2.2.weight\", \"flows.36.theta.hidden.2.2.bias\", \"flows.36.theta.hidden.3.0.weight\", \"flows.36.theta.hidden.3.0.bias\", \"flows.36.theta.hidden.3.2.weight\", \"flows.36.theta.hidden.3.2.bias\", \"flows.36.theta.hidden.4.0.weight\", \"flows.36.theta.hidden.4.0.bias\", \"flows.36.theta.hidden.4.2.weight\", \"flows.36.theta.hidden.4.2.bias\", \"flows.36.theta.hidden.5.0.weight\", \"flows.36.theta.hidden.5.0.bias\", \"flows.36.theta.hidden.5.2.weight\", \"flows.36.theta.hidden.5.2.bias\", \"flows.36.theta.hidden.6.0.weight\", \"flows.36.theta.hidden.6.0.bias\", \"flows.36.theta.hidden.6.2.weight\", \"flows.36.theta.hidden.6.2.bias\", \"flows.36.theta.hidden.7.0.weight\", \"flows.36.theta.hidden.7.0.bias\", \"flows.36.theta.hidden.7.2.weight\", \"flows.36.theta.hidden.7.2.bias\", \"flows.36.theta.hidden.8.0.weight\", \"flows.36.theta.hidden.8.0.bias\", \"flows.36.theta.hidden.8.2.weight\", \"flows.36.theta.hidden.8.2.bias\", \"flows.36.theta.hidden.9.0.weight\", \"flows.36.theta.hidden.9.0.bias\", \"flows.36.theta.hidden.9.2.weight\", \"flows.36.theta.hidden.9.2.bias\", \"flows.36.theta.hidden.10.0.weight\", \"flows.36.theta.hidden.10.0.bias\", \"flows.36.theta.hidden.10.2.weight\", \"flows.36.theta.hidden.10.2.bias\", \"flows.36.theta.hidden.11.0.weight\", \"flows.36.theta.hidden.11.0.bias\", \"flows.36.theta.hidden.11.2.weight\", \"flows.36.theta.hidden.11.2.bias\", \"flows.36.theta.dims.weight\", \"flows.36.theta.dims.bias\", \"flows.37.theta.input.weight\", \"flows.37.theta.input.bias\", \"flows.37.theta.hidden.0.0.weight\", \"flows.37.theta.hidden.0.0.bias\", \"flows.37.theta.hidden.0.2.weight\", \"flows.37.theta.hidden.0.2.bias\", \"flows.37.theta.hidden.1.0.weight\", \"flows.37.theta.hidden.1.0.bias\", \"flows.37.theta.hidden.1.2.weight\", \"flows.37.theta.hidden.1.2.bias\", \"flows.37.theta.hidden.2.0.weight\", \"flows.37.theta.hidden.2.0.bias\", \"flows.37.theta.hidden.2.2.weight\", \"flows.37.theta.hidden.2.2.bias\", \"flows.37.theta.hidden.3.0.weight\", \"flows.37.theta.hidden.3.0.bias\", \"flows.37.theta.hidden.3.2.weight\", \"flows.37.theta.hidden.3.2.bias\", \"flows.37.theta.hidden.4.0.weight\", \"flows.37.theta.hidden.4.0.bias\", \"flows.37.theta.hidden.4.2.weight\", \"flows.37.theta.hidden.4.2.bias\", \"flows.37.theta.hidden.5.0.weight\", \"flows.37.theta.hidden.5.0.bias\", \"flows.37.theta.hidden.5.2.weight\", \"flows.37.theta.hidden.5.2.bias\", \"flows.37.theta.hidden.6.0.weight\", \"flows.37.theta.hidden.6.0.bias\", \"flows.37.theta.hidden.6.2.weight\", \"flows.37.theta.hidden.6.2.bias\", \"flows.37.theta.hidden.7.0.weight\", \"flows.37.theta.hidden.7.0.bias\", \"flows.37.theta.hidden.7.2.weight\", \"flows.37.theta.hidden.7.2.bias\", \"flows.37.theta.hidden.8.0.weight\", \"flows.37.theta.hidden.8.0.bias\", \"flows.37.theta.hidden.8.2.weight\", \"flows.37.theta.hidden.8.2.bias\", \"flows.37.theta.hidden.9.0.weight\", \"flows.37.theta.hidden.9.0.bias\", \"flows.37.theta.hidden.9.2.weight\", \"flows.37.theta.hidden.9.2.bias\", \"flows.37.theta.hidden.10.0.weight\", \"flows.37.theta.hidden.10.0.bias\", \"flows.37.theta.hidden.10.2.weight\", \"flows.37.theta.hidden.10.2.bias\", \"flows.37.theta.hidden.11.0.weight\", \"flows.37.theta.hidden.11.0.bias\", \"flows.37.theta.hidden.11.2.weight\", \"flows.37.theta.hidden.11.2.bias\", \"flows.37.theta.dims.weight\", \"flows.37.theta.dims.bias\", \"flows.38.theta.input.weight\", \"flows.38.theta.input.bias\", \"flows.38.theta.hidden.0.0.weight\", \"flows.38.theta.hidden.0.0.bias\", \"flows.38.theta.hidden.0.2.weight\", \"flows.38.theta.hidden.0.2.bias\", \"flows.38.theta.hidden.1.0.weight\", \"flows.38.theta.hidden.1.0.bias\", \"flows.38.theta.hidden.1.2.weight\", \"flows.38.theta.hidden.1.2.bias\", \"flows.38.theta.hidden.2.0.weight\", \"flows.38.theta.hidden.2.0.bias\", \"flows.38.theta.hidden.2.2.weight\", \"flows.38.theta.hidden.2.2.bias\", \"flows.38.theta.hidden.3.0.weight\", \"flows.38.theta.hidden.3.0.bias\", \"flows.38.theta.hidden.3.2.weight\", \"flows.38.theta.hidden.3.2.bias\", \"flows.38.theta.hidden.4.0.weight\", \"flows.38.theta.hidden.4.0.bias\", \"flows.38.theta.hidden.4.2.weight\", \"flows.38.theta.hidden.4.2.bias\", \"flows.38.theta.hidden.5.0.weight\", \"flows.38.theta.hidden.5.0.bias\", \"flows.38.theta.hidden.5.2.weight\", \"flows.38.theta.hidden.5.2.bias\", \"flows.38.theta.hidden.6.0.weight\", \"flows.38.theta.hidden.6.0.bias\", \"flows.38.theta.hidden.6.2.weight\", \"flows.38.theta.hidden.6.2.bias\", \"flows.38.theta.hidden.7.0.weight\", \"flows.38.theta.hidden.7.0.bias\", \"flows.38.theta.hidden.7.2.weight\", \"flows.38.theta.hidden.7.2.bias\", \"flows.38.theta.hidden.8.0.weight\", \"flows.38.theta.hidden.8.0.bias\", \"flows.38.theta.hidden.8.2.weight\", \"flows.38.theta.hidden.8.2.bias\", \"flows.38.theta.hidden.9.0.weight\", \"flows.38.theta.hidden.9.0.bias\", \"flows.38.theta.hidden.9.2.weight\", \"flows.38.theta.hidden.9.2.bias\", \"flows.38.theta.hidden.10.0.weight\", \"flows.38.theta.hidden.10.0.bias\", \"flows.38.theta.hidden.10.2.weight\", \"flows.38.theta.hidden.10.2.bias\", \"flows.38.theta.hidden.11.0.weight\", \"flows.38.theta.hidden.11.0.bias\", \"flows.38.theta.hidden.11.2.weight\", \"flows.38.theta.hidden.11.2.bias\", \"flows.38.theta.dims.weight\", \"flows.38.theta.dims.bias\", \"flows.39.theta.input.weight\", \"flows.39.theta.input.bias\", \"flows.39.theta.hidden.0.0.weight\", \"flows.39.theta.hidden.0.0.bias\", \"flows.39.theta.hidden.0.2.weight\", \"flows.39.theta.hidden.0.2.bias\", \"flows.39.theta.hidden.1.0.weight\", \"flows.39.theta.hidden.1.0.bias\", \"flows.39.theta.hidden.1.2.weight\", \"flows.39.theta.hidden.1.2.bias\", \"flows.39.theta.hidden.2.0.weight\", \"flows.39.theta.hidden.2.0.bias\", \"flows.39.theta.hidden.2.2.weight\", \"flows.39.theta.hidden.2.2.bias\", \"flows.39.theta.hidden.3.0.weight\", \"flows.39.theta.hidden.3.0.bias\", \"flows.39.theta.hidden.3.2.weight\", \"flows.39.theta.hidden.3.2.bias\", \"flows.39.theta.hidden.4.0.weight\", \"flows.39.theta.hidden.4.0.bias\", \"flows.39.theta.hidden.4.2.weight\", \"flows.39.theta.hidden.4.2.bias\", \"flows.39.theta.hidden.5.0.weight\", \"flows.39.theta.hidden.5.0.bias\", \"flows.39.theta.hidden.5.2.weight\", \"flows.39.theta.hidden.5.2.bias\", \"flows.39.theta.hidden.6.0.weight\", \"flows.39.theta.hidden.6.0.bias\", \"flows.39.theta.hidden.6.2.weight\", \"flows.39.theta.hidden.6.2.bias\", \"flows.39.theta.hidden.7.0.weight\", \"flows.39.theta.hidden.7.0.bias\", \"flows.39.theta.hidden.7.2.weight\", \"flows.39.theta.hidden.7.2.bias\", \"flows.39.theta.hidden.8.0.weight\", \"flows.39.theta.hidden.8.0.bias\", \"flows.39.theta.hidden.8.2.weight\", \"flows.39.theta.hidden.8.2.bias\", \"flows.39.theta.hidden.9.0.weight\", \"flows.39.theta.hidden.9.0.bias\", \"flows.39.theta.hidden.9.2.weight\", \"flows.39.theta.hidden.9.2.bias\", \"flows.39.theta.hidden.10.0.weight\", \"flows.39.theta.hidden.10.0.bias\", \"flows.39.theta.hidden.10.2.weight\", \"flows.39.theta.hidden.10.2.bias\", \"flows.39.theta.hidden.11.0.weight\", \"flows.39.theta.hidden.11.0.bias\", \"flows.39.theta.hidden.11.2.weight\", \"flows.39.theta.hidden.11.2.bias\", \"flows.39.theta.dims.weight\", \"flows.39.theta.dims.bias\", \"flows.40.theta.input.weight\", \"flows.40.theta.input.bias\", \"flows.40.theta.hidden.0.0.weight\", \"flows.40.theta.hidden.0.0.bias\", \"flows.40.theta.hidden.0.2.weight\", \"flows.40.theta.hidden.0.2.bias\", \"flows.40.theta.hidden.1.0.weight\", \"flows.40.theta.hidden.1.0.bias\", \"flows.40.theta.hidden.1.2.weight\", \"flows.40.theta.hidden.1.2.bias\", \"flows.40.theta.hidden.2.0.weight\", \"flows.40.theta.hidden.2.0.bias\", \"flows.40.theta.hidden.2.2.weight\", \"flows.40.theta.hidden.2.2.bias\", \"flows.40.theta.hidden.3.0.weight\", \"flows.40.theta.hidden.3.0.bias\", \"flows.40.theta.hidden.3.2.weight\", \"flows.40.theta.hidden.3.2.bias\", \"flows.40.theta.hidden.4.0.weight\", \"flows.40.theta.hidden.4.0.bias\", \"flows.40.theta.hidden.4.2.weight\", \"flows.40.theta.hidden.4.2.bias\", \"flows.40.theta.hidden.5.0.weight\", \"flows.40.theta.hidden.5.0.bias\", \"flows.40.theta.hidden.5.2.weight\", \"flows.40.theta.hidden.5.2.bias\", \"flows.40.theta.hidden.6.0.weight\", \"flows.40.theta.hidden.6.0.bias\", \"flows.40.theta.hidden.6.2.weight\", \"flows.40.theta.hidden.6.2.bias\", \"flows.40.theta.hidden.7.0.weight\", \"flows.40.theta.hidden.7.0.bias\", \"flows.40.theta.hidden.7.2.weight\", \"flows.40.theta.hidden.7.2.bias\", \"flows.40.theta.hidden.8.0.weight\", \"flows.40.theta.hidden.8.0.bias\", \"flows.40.theta.hidden.8.2.weight\", \"flows.40.theta.hidden.8.2.bias\", \"flows.40.theta.hidden.9.0.weight\", \"flows.40.theta.hidden.9.0.bias\", \"flows.40.theta.hidden.9.2.weight\", \"flows.40.theta.hidden.9.2.bias\", \"flows.40.theta.hidden.10.0.weight\", \"flows.40.theta.hidden.10.0.bias\", \"flows.40.theta.hidden.10.2.weight\", \"flows.40.theta.hidden.10.2.bias\", \"flows.40.theta.hidden.11.0.weight\", \"flows.40.theta.hidden.11.0.bias\", \"flows.40.theta.hidden.11.2.weight\", \"flows.40.theta.hidden.11.2.bias\", \"flows.40.theta.dims.weight\", \"flows.40.theta.dims.bias\", \"flows.41.weight\". \n\tUnexpected key(s) in state_dict: \"flows.14.theta.input.weight\", \"flows.14.theta.input.bias\", \"flows.14.theta.hidden.0.0.weight\", \"flows.14.theta.hidden.0.0.bias\", \"flows.14.theta.hidden.0.2.weight\", \"flows.14.theta.hidden.0.2.bias\", \"flows.14.theta.hidden.1.0.weight\", \"flows.14.theta.hidden.1.0.bias\", \"flows.14.theta.hidden.1.2.weight\", \"flows.14.theta.hidden.1.2.bias\", \"flows.14.theta.hidden.2.0.weight\", \"flows.14.theta.hidden.2.0.bias\", \"flows.14.theta.hidden.2.2.weight\", \"flows.14.theta.hidden.2.2.bias\", \"flows.14.theta.hidden.3.0.weight\", \"flows.14.theta.hidden.3.0.bias\", \"flows.14.theta.hidden.3.2.weight\", \"flows.14.theta.hidden.3.2.bias\", \"flows.14.theta.hidden.4.0.weight\", \"flows.14.theta.hidden.4.0.bias\", \"flows.14.theta.hidden.4.2.weight\", \"flows.14.theta.hidden.4.2.bias\", \"flows.14.theta.hidden.5.0.weight\", \"flows.14.theta.hidden.5.0.bias\", \"flows.14.theta.hidden.5.2.weight\", \"flows.14.theta.hidden.5.2.bias\", \"flows.14.theta.hidden.6.0.weight\", \"flows.14.theta.hidden.6.0.bias\", \"flows.14.theta.hidden.6.2.weight\", \"flows.14.theta.hidden.6.2.bias\", \"flows.14.theta.hidden.7.0.weight\", \"flows.14.theta.hidden.7.0.bias\", \"flows.14.theta.hidden.7.2.weight\", \"flows.14.theta.hidden.7.2.bias\", \"flows.14.theta.hidden.8.0.weight\", \"flows.14.theta.hidden.8.0.bias\", \"flows.14.theta.hidden.8.2.weight\", \"flows.14.theta.hidden.8.2.bias\", \"flows.14.theta.hidden.9.0.weight\", \"flows.14.theta.hidden.9.0.bias\", \"flows.14.theta.hidden.9.2.weight\", \"flows.14.theta.hidden.9.2.bias\", \"flows.14.theta.hidden.10.0.weight\", \"flows.14.theta.hidden.10.0.bias\", \"flows.14.theta.hidden.10.2.weight\", \"flows.14.theta.hidden.10.2.bias\", \"flows.14.theta.hidden.11.0.weight\", \"flows.14.theta.hidden.11.0.bias\", \"flows.14.theta.hidden.11.2.weight\", \"flows.14.theta.hidden.11.2.bias\", \"flows.14.theta.dims.weight\", \"flows.14.theta.dims.bias\", \"flows.16.theta.input.weight\", \"flows.16.theta.input.bias\", \"flows.16.theta.hidden.0.0.weight\", \"flows.16.theta.hidden.0.0.bias\", \"flows.16.theta.hidden.0.2.weight\", \"flows.16.theta.hidden.0.2.bias\", \"flows.16.theta.hidden.1.0.weight\", \"flows.16.theta.hidden.1.0.bias\", \"flows.16.theta.hidden.1.2.weight\", \"flows.16.theta.hidden.1.2.bias\", \"flows.16.theta.hidden.2.0.weight\", \"flows.16.theta.hidden.2.0.bias\", \"flows.16.theta.hidden.2.2.weight\", \"flows.16.theta.hidden.2.2.bias\", \"flows.16.theta.hidden.3.0.weight\", \"flows.16.theta.hidden.3.0.bias\", \"flows.16.theta.hidden.3.2.weight\", \"flows.16.theta.hidden.3.2.bias\", \"flows.16.theta.hidden.4.0.weight\", \"flows.16.theta.hidden.4.0.bias\", \"flows.16.theta.hidden.4.2.weight\", \"flows.16.theta.hidden.4.2.bias\", \"flows.16.theta.hidden.5.0.weight\", \"flows.16.theta.hidden.5.0.bias\", \"flows.16.theta.hidden.5.2.weight\", \"flows.16.theta.hidden.5.2.bias\", \"flows.16.theta.hidden.6.0.weight\", \"flows.16.theta.hidden.6.0.bias\", \"flows.16.theta.hidden.6.2.weight\", \"flows.16.theta.hidden.6.2.bias\", \"flows.16.theta.hidden.7.0.weight\", \"flows.16.theta.hidden.7.0.bias\", \"flows.16.theta.hidden.7.2.weight\", \"flows.16.theta.hidden.7.2.bias\", \"flows.16.theta.hidden.8.0.weight\", \"flows.16.theta.hidden.8.0.bias\", \"flows.16.theta.hidden.8.2.weight\", \"flows.16.theta.hidden.8.2.bias\", \"flows.16.theta.hidden.9.0.weight\", \"flows.16.theta.hidden.9.0.bias\", \"flows.16.theta.hidden.9.2.weight\", \"flows.16.theta.hidden.9.2.bias\", \"flows.16.theta.hidden.10.0.weight\", \"flows.16.theta.hidden.10.0.bias\", \"flows.16.theta.hidden.10.2.weight\", \"flows.16.theta.hidden.10.2.bias\", \"flows.16.theta.hidden.11.0.weight\", \"flows.16.theta.hidden.11.0.bias\", \"flows.16.theta.hidden.11.2.weight\", \"flows.16.theta.hidden.11.2.bias\", \"flows.16.theta.dims.weight\", \"flows.16.theta.dims.bias\", \"flows.18.theta.input.weight\", \"flows.18.theta.input.bias\", \"flows.18.theta.hidden.0.0.weight\", \"flows.18.theta.hidden.0.0.bias\", \"flows.18.theta.hidden.0.2.weight\", \"flows.18.theta.hidden.0.2.bias\", \"flows.18.theta.hidden.1.0.weight\", \"flows.18.theta.hidden.1.0.bias\", \"flows.18.theta.hidden.1.2.weight\", \"flows.18.theta.hidden.1.2.bias\", \"flows.18.theta.hidden.2.0.weight\", \"flows.18.theta.hidden.2.0.bias\", \"flows.18.theta.hidden.2.2.weight\", \"flows.18.theta.hidden.2.2.bias\", \"flows.18.theta.hidden.3.0.weight\", \"flows.18.theta.hidden.3.0.bias\", \"flows.18.theta.hidden.3.2.weight\", \"flows.18.theta.hidden.3.2.bias\", \"flows.18.theta.hidden.4.0.weight\", \"flows.18.theta.hidden.4.0.bias\", \"flows.18.theta.hidden.4.2.weight\", \"flows.18.theta.hidden.4.2.bias\", \"flows.18.theta.hidden.5.0.weight\", \"flows.18.theta.hidden.5.0.bias\", \"flows.18.theta.hidden.5.2.weight\", \"flows.18.theta.hidden.5.2.bias\", \"flows.18.theta.hidden.6.0.weight\", \"flows.18.theta.hidden.6.0.bias\", \"flows.18.theta.hidden.6.2.weight\", \"flows.18.theta.hidden.6.2.bias\", \"flows.18.theta.hidden.7.0.weight\", \"flows.18.theta.hidden.7.0.bias\", \"flows.18.theta.hidden.7.2.weight\", \"flows.18.theta.hidden.7.2.bias\", \"flows.18.theta.hidden.8.0.weight\", \"flows.18.theta.hidden.8.0.bias\", \"flows.18.theta.hidden.8.2.weight\", \"flows.18.theta.hidden.8.2.bias\", \"flows.18.theta.hidden.9.0.weight\", \"flows.18.theta.hidden.9.0.bias\", \"flows.18.theta.hidden.9.2.weight\", \"flows.18.theta.hidden.9.2.bias\", \"flows.18.theta.hidden.10.0.weight\", \"flows.18.theta.hidden.10.0.bias\", \"flows.18.theta.hidden.10.2.weight\", \"flows.18.theta.hidden.10.2.bias\", \"flows.18.theta.hidden.11.0.weight\", \"flows.18.theta.hidden.11.0.bias\", \"flows.18.theta.hidden.11.2.weight\", \"flows.18.theta.hidden.11.2.bias\", \"flows.18.theta.dims.weight\", \"flows.18.theta.dims.bias\", \"flows.20.theta.input.weight\", \"flows.20.theta.input.bias\", \"flows.20.theta.hidden.0.0.weight\", \"flows.20.theta.hidden.0.0.bias\", \"flows.20.theta.hidden.0.2.weight\", \"flows.20.theta.hidden.0.2.bias\", \"flows.20.theta.hidden.1.0.weight\", \"flows.20.theta.hidden.1.0.bias\", \"flows.20.theta.hidden.1.2.weight\", \"flows.20.theta.hidden.1.2.bias\", \"flows.20.theta.hidden.2.0.weight\", \"flows.20.theta.hidden.2.0.bias\", \"flows.20.theta.hidden.2.2.weight\", \"flows.20.theta.hidden.2.2.bias\", \"flows.20.theta.hidden.3.0.weight\", \"flows.20.theta.hidden.3.0.bias\", \"flows.20.theta.hidden.3.2.weight\", \"flows.20.theta.hidden.3.2.bias\", \"flows.20.theta.hidden.4.0.weight\", \"flows.20.theta.hidden.4.0.bias\", \"flows.20.theta.hidden.4.2.weight\", \"flows.20.theta.hidden.4.2.bias\", \"flows.20.theta.hidden.5.0.weight\", \"flows.20.theta.hidden.5.0.bias\", \"flows.20.theta.hidden.5.2.weight\", \"flows.20.theta.hidden.5.2.bias\", \"flows.20.theta.hidden.6.0.weight\", \"flows.20.theta.hidden.6.0.bias\", \"flows.20.theta.hidden.6.2.weight\", \"flows.20.theta.hidden.6.2.bias\", \"flows.20.theta.hidden.7.0.weight\", \"flows.20.theta.hidden.7.0.bias\", \"flows.20.theta.hidden.7.2.weight\", \"flows.20.theta.hidden.7.2.bias\", \"flows.20.theta.hidden.8.0.weight\", \"flows.20.theta.hidden.8.0.bias\", \"flows.20.theta.hidden.8.2.weight\", \"flows.20.theta.hidden.8.2.bias\", \"flows.20.theta.hidden.9.0.weight\", \"flows.20.theta.hidden.9.0.bias\", \"flows.20.theta.hidden.9.2.weight\", \"flows.20.theta.hidden.9.2.bias\", \"flows.20.theta.hidden.10.0.weight\", \"flows.20.theta.hidden.10.0.bias\", \"flows.20.theta.hidden.10.2.weight\", \"flows.20.theta.hidden.10.2.bias\", \"flows.20.theta.hidden.11.0.weight\", \"flows.20.theta.hidden.11.0.bias\", \"flows.20.theta.hidden.11.2.weight\", \"flows.20.theta.hidden.11.2.bias\", \"flows.20.theta.dims.weight\", \"flows.20.theta.dims.bias\", \"flows.22.theta.input.weight\", \"flows.22.theta.input.bias\", \"flows.22.theta.hidden.0.0.weight\", \"flows.22.theta.hidden.0.0.bias\", \"flows.22.theta.hidden.0.2.weight\", \"flows.22.theta.hidden.0.2.bias\", \"flows.22.theta.hidden.1.0.weight\", \"flows.22.theta.hidden.1.0.bias\", \"flows.22.theta.hidden.1.2.weight\", \"flows.22.theta.hidden.1.2.bias\", \"flows.22.theta.hidden.2.0.weight\", \"flows.22.theta.hidden.2.0.bias\", \"flows.22.theta.hidden.2.2.weight\", \"flows.22.theta.hidden.2.2.bias\", \"flows.22.theta.hidden.3.0.weight\", \"flows.22.theta.hidden.3.0.bias\", \"flows.22.theta.hidden.3.2.weight\", \"flows.22.theta.hidden.3.2.bias\", \"flows.22.theta.hidden.4.0.weight\", \"flows.22.theta.hidden.4.0.bias\", \"flows.22.theta.hidden.4.2.weight\", \"flows.22.theta.hidden.4.2.bias\", \"flows.22.theta.hidden.5.0.weight\", \"flows.22.theta.hidden.5.0.bias\", \"flows.22.theta.hidden.5.2.weight\", \"flows.22.theta.hidden.5.2.bias\", \"flows.22.theta.hidden.6.0.weight\", \"flows.22.theta.hidden.6.0.bias\", \"flows.22.theta.hidden.6.2.weight\", \"flows.22.theta.hidden.6.2.bias\", \"flows.22.theta.hidden.7.0.weight\", \"flows.22.theta.hidden.7.0.bias\", \"flows.22.theta.hidden.7.2.weight\", \"flows.22.theta.hidden.7.2.bias\", \"flows.22.theta.hidden.8.0.weight\", \"flows.22.theta.hidden.8.0.bias\", \"flows.22.theta.hidden.8.2.weight\", \"flows.22.theta.hidden.8.2.bias\", \"flows.22.theta.hidden.9.0.weight\", \"flows.22.theta.hidden.9.0.bias\", \"flows.22.theta.hidden.9.2.weight\", \"flows.22.theta.hidden.9.2.bias\", \"flows.22.theta.hidden.10.0.weight\", \"flows.22.theta.hidden.10.0.bias\", \"flows.22.theta.hidden.10.2.weight\", \"flows.22.theta.hidden.10.2.bias\", \"flows.22.theta.hidden.11.0.weight\", \"flows.22.theta.hidden.11.0.bias\", \"flows.22.theta.hidden.11.2.weight\", \"flows.22.theta.hidden.11.2.bias\", \"flows.22.theta.dims.weight\", \"flows.22.theta.dims.bias\", \"flows.23.weight\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-99-cd6e69fb861a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mset_random_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNormalizingFlow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnormal_dist\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mflows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfigure_flows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconv_flows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfigure_conv_flows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mnf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model_weights1.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mKL_ur\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLBFGS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"lr\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.0001\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   2039\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2040\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2041\u001b[0;31m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0m\u001b[1;32m   2042\u001b[0m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[1;32m   2043\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for NormalizingFlow:\n\tMissing key(s) in state_dict: \"flows.14.weight\", \"flows.16.weight\", \"flows.18.weight\", \"flows.20.weight\", \"flows.22.weight\", \"flows.23.theta.input.weight\", \"flows.23.theta.input.bias\", \"flows.23.theta.hidden.0.0.weight\", \"flows.23.theta.hidden.0.0.bias\", \"flows.23.theta.hidden.0.2.weight\", \"flows.23.theta.hidden.0.2.bias\", \"flows.23.theta.hidden.1.0.weight\", \"flows.23.theta.hidden.1.0.bias\", \"flows.23.theta.hidden.1.2.weight\", \"flows.23.theta.hidden.1.2.bias\", \"flows.23.theta.hidden.2.0.weight\", \"flows.23.theta.hidden.2.0.bias\", \"flows.23.theta.hidden.2.2.weight\", \"flows.23.theta.hidden.2.2.bias\", \"flows.23.theta.hidden.3.0.weight\", \"flows.23.theta.hidden.3.0.bias\", \"flows.23.theta.hidden.3.2.weight\", \"flows.23.theta.hidden.3.2.bias\", \"flows.23.theta.hidden.4.0.weight\", \"flows.23.theta.hidden.4.0.bias\", \"flows.23.theta.hidden.4.2.weight\", \"flows.23.theta.hidden.4.2.bias\", \"flows.23.theta.hidden.5.0.weight\", \"flows.23.theta.hidden.5.0.bias\", \"flows.23.theta.hidden.5.2.weight\", \"flows.23.theta.hidden.5.2.bias\", \"flows.23.theta.hidden.6.0.weight\", \"flows.23.theta.hidden.6.0.bias\", \"flows.23.theta.hidden.6.2.weight\", \"flows.23.theta.hidden.6.2.bias\", \"flows.23.theta.hidden.7.0.weight\", \"flows.23.theta.hidden.7.0.bias\", \"flows.23.theta.hidden.7.2.weight\", \"flows.23.theta.hidden.7.2.bias\", \"flows.23.theta.hidden.8.0.weight\", \"flows.23.theta.hidden.8.0.bias\", \"flows.23.theta.hidden.8.2.weight\", \"flows.23.theta.hidden.8.2.bias\", \"flows.23.theta.hidden.9.0.weight\", \"flows.23.theta.hidden.9.0.bias\", \"flows.23.theta.hidden.9.2.weight\", \"flows.23.theta.hidden.9.2.bias\", \"flows.23.theta.hidden.10.0.weight\", \"flows.23.theta.hidden.10.0.bias\", \"flows.23.theta.hidden.10.2.weight\", \"flows.23.theta.hidden.10.2.bias\", \"flows.23.theta.hidden.11.0.weight\", \"flows.23.theta.hidden.11.0.bias\", \"flows.23.theta.hidden.11.2.weight\", \"flows.23.theta.hidden.11.2.bias\", \"flows.23.theta.dims.weight\", \"flows.23.theta.dims.bias\", \"flows.24.weight\", \"flows.25.theta.input.weight\", \"flows.25.theta.input.bias\", \"flows.25.theta.hidden.0.0.weight\", \"flows.25.theta.hidden.0.0.bias\", \"flows.25.theta.hidden.0.2.weight\", \"flows.25.theta.hidden.0.2.bias\", \"flows.25.theta.hidden.1.0.weight\", \"flows.25.theta.hidden.1.0.bias\", \"flows.25.theta.hidden.1.2.weight\", \"flows.25.theta.hidden.1.2.bias\", \"flows.25.theta.hidden.2.0.weight\", \"flows.25.theta.hidden.2.0.bias\", \"flows.25.theta.hidden.2.2.weight\", \"flows.25.theta.hidden.2.2.bias\", \"flows.25.theta.hidden.3.0.weight\", \"flows.25.theta.hidden.3.0.bias\", \"flows.25.theta.hidden.3.2.weight\", \"flows.25.theta.hidden.3.2.bias\", \"flows.25.theta.hidden.4.0.weight\", \"flows.25.theta.hidden.4.0.bias\", \"flows.25.theta.hidden.4.2.weight\", \"flows.25.theta.hidden.4.2.bias\", \"flows.25.theta.hidden.5.0.weight\", \"flows.25.theta.hidden.5.0.bias\", \"flows.25.theta.hidden.5.2.weight\", \"flows.25.theta.hidden.5.2.bias\", \"flows.25.theta.hidden.6.0.weight\", \"flows.25.theta.hidden.6.0.bias\", \"flows.25.theta.hidden.6.2.weight\", \"flows.25.theta.hidden.6.2.bias\", \"flows.25.theta.hidden.7.0.weight\", \"flows.25.theta.hidden.7.0.bias\", \"flows.25.theta.hidden.7.2.weight\", \"flows.25.theta.hidden.7.2.bias\", \"flows.25.theta.hidden.8.0.weight\", \"flows.25.theta.hidden.8.0.bias\", \"flows.25.theta.hidden.8.2.weight\", \"flows.25.theta.hidden.8.2.bias\", \"flows.25.theta.hidden.9.0.weight\", \"flows.25.theta.hidden.9.0.bias\", \"flows.25.theta.hidden.9.2.weight\", \"flows.25.theta.hidden.9.2.bias\", \"flows.25.theta.hidden.10.0.weight\", \"flows.25.theta.hidden.10.0.bias\", \"flows.25.theta.hidden.10.2.weight\", \"flows.25.theta.hidden.10.2.bias\", \"flows.25.theta.hidden.11.0.weight\", \"flows.25.theta.hidden.11.0.bias\", \"flows.25.theta.hidden.11.2.weight\", \"flows.25.theta.hidden.11.2.bias\", \"flows.25.theta.dims.weight\", \"flows.25.theta.dims.bias\", \"flows.26.theta.input.weight\", \"flows.26.theta.input.bias\", \"flows.26.theta.hidden.0.0.weight\", \"flows.26.theta.hidden.0.0.bias\", \"flows.26.theta.hidden.0.2.weight\", \"flows.26.theta.hidden.0.2.bias\", \"flows.26.theta.hidden.1.0.weight\", \"flows.26.theta.hidden.1.0.bias\", \"flows.26.theta.hidden.1.2.weight\", \"flows.26.theta.hidden.1.2.bias\", \"flows.26.theta.hidden.2.0.weight\", \"flows.26.theta.hidden.2.0.bias\", \"flows.26.theta.hidden.2.2.weight\", \"flows.26.theta.hidden.2.2.bias\", \"flows.26.theta.hidden.3.0.weight\", \"flows.26.theta.hidden.3.0.bias\", \"flows.26.theta.hidden.3.2.weight\", \"flows.26.theta.hidden.3.2.bias\", \"flows.26.theta.hidden.4.0.weight\", \"flows.26.theta.hidden.4.0.bias\", \"flows.26.theta.hidden.4.2.weight\", \"flows.26.theta.hidden.4.2.bias\", \"flows.26.theta.hidden.5.0.weight\", \"flows.26.theta.hidden.5.0.bias\", \"flows.26.theta.hidden.5.2.weight\", \"flows.26.theta.hidden.5.2.bias\", \"flows.26.theta.hidden.6.0.weight\", \"flows.26.theta.hidden.6.0.bias\", \"flows.26.theta.hidden.6.2.weight\", \"flows.26.theta.hidden.6.2.bias\", \"flows.26.theta.hidden.7.0.weight\", \"flows.26.theta.hidden.7.0.bias\", \"flows.26.theta.hidden.7.2.weight\", \"flows.26.theta.hidden.7.2.bias\", \"flows.26.theta.hidden.8.0.weight\", \"flows.26.theta.hidden.8.0.bias\", \"flows.26.theta.hidden.8.2.weight\", \"flows.26.theta.hidden.8.2.bias\", \"flows.26.theta.hidden.9.0.weight\", \"flows.26.theta.hidden.9.0.bias\", \"flows.26.theta.hidden.9.2.weight\", \"flows.26.theta.hidden.9.2.bias\", \"flows.26.theta.hidden.10.0.weight\", \"flows.26.theta.hidden.10.0.bias\", \"flows.26.theta.hidden.10.2.weight\", \"flows.26.theta.hidden.10.2.bias\", \"flows.26.theta.hidden.11.0.weight\", \"flows.26.theta.hidden.11.0.bias\", \"flows.26.theta.hidden.11.2.weight\", \"flows.26.theta.hidden.11.2.bias\", \"flows.26.theta.dims.weight\", \"flows.26.theta.dims.bias\", \"flows.27.theta.input.weight\", \"flows.27.theta.input.bias\", \"flows.27.theta.hidden.0.0.weight\", \"flows.27.theta.hidden.0.0.bias\", \"flows.27.theta.hidden.0.2.weight\", \"flows.27.theta.hidden.0.2.bias\", \"flows.27.theta.hidden.1.0.weight\", \"flows.27.theta.hidden.1.0.bias\", \"flows.27.theta.hidden.1.2.weight\", \"flows.27.theta.hidden.1.2.bias\", \"flows.27.theta.hidden.2.0.weight\", \"flows.27.theta.hidden.2.0.bias\", \"flows.27.theta.hidden.2.2.weight\", \"flows.27.theta.hidden.2.2.bias\", \"flows.27.theta.hidden.3.0.weight\", \"flows.27.theta.hidden.3.0.bias\", \"flows.27.theta.hidden.3.2.weight\", \"flows.27.theta.hidden.3.2.bias\", \"flows.27.theta.hidden.4.0.weight\", \"flows.27.theta.hidden.4.0.bias\", \"flows.27.theta.hidden.4.2.weight\", \"flows.27.theta.hidden.4.2.bias\", \"flows.27.theta.hidden.5.0.weight\", \"flows.27.theta.hidden.5.0.bias\", \"flows.27.theta.hidden.5.2.weight\", \"flows.27.theta.hidden.5.2.bias\", \"flows.27.theta.hidden.6.0.weight\", \"flows.27.theta.hidden.6.0.bias\", \"flows.27.theta.hidden.6.2.weight\", \"flows.27.theta.hidden.6.2.bias\", \"flows.27.theta.hidden.7.0.weight\", \"flows.27.theta.hidden.7.0.bias\", \"flows.27.theta.hidden.7.2.weight\", \"flows.27.theta.hidden.7.2.bias\", \"flows.27.theta.hidden.8.0.weight\", \"flows.27.theta.hidden.8.0.bias\", \"flows.27.theta.hidden.8.2.weight\", \"flows.27.theta.hidden.8.2.bias\", \"flows.27.theta.hidden.9.0.weight\", \"flows.27.theta.hidden.9.0.bias\", \"flows.27.theta.hidden.9.2.weight\", \"flows.27.theta.hidden.9.2.bias\", \"flows.27.theta.hidden.10.0.weight\", \"flows.27.theta.hidden.10.0.bias\", \"flows.27.theta.hidden.10.2.weight\", \"flows.27.theta.hidden.10.2.bias\", \"flows.27.theta.hidden.11.0.weight\", \"flows.27.theta.hidden.11.0.bias\", \"flows.27.theta.hidden.11.2.weight\", \"flows.27.theta.hidden.11.2.bias\", \"flows.27.theta.dims.weight\", \"flows.27.theta.dims.bias\", \"flows.28.theta.input.weight\", \"flows.28.theta.input.bias\", \"flows.28.theta.hidden.0.0.weight\", \"flows.28.theta.hidden.0.0.bias\", \"flows.28.theta.hidden.0.2.weight\", \"flows.28.theta.hidden.0.2.bias\", \"flows.28.theta.hidden.1.0.weight\", \"flows.28.theta.hidden.1.0.bias\", \"flows.28.theta.hidden.1.2.weight\", \"flows.28.theta.hidden.1.2.bias\", \"flows.28.theta.hidden.2.0.weight\", \"flows.28.theta.hidden.2.0.bias\", \"flows.28.theta.hidden.2.2.weight\", \"flows.28.theta.hidden.2.2.bias\", \"flows.28.theta.hidden.3.0.weight\", \"flows.28.theta.hidden.3.0.bias\", \"flows.28.theta.hidden.3.2.weight\", \"flows.28.theta.hidden.3.2.bias\", \"flows.28.theta.hidden.4.0.weight\", \"flows.28.theta.hidden.4.0.bias\", \"flows.28.theta.hidden.4.2.weight\", \"flows.28.theta.hidden.4.2.bias\", \"flows.28.theta.hidden.5.0.weight\", \"flows.28.theta.hidden.5.0.bias\", \"flows.28.theta.hidden.5.2.weight\", \"flows.28.theta.hidden.5.2.bias\", \"flows.28.theta.hidden.6.0.weight\", \"flows.28.theta.hidden.6.0.bias\", \"flows.28.theta.hidden.6.2.weight\", \"flows.28.theta.hidden.6.2.bias\", \"flows.28.theta.hidden.7.0.weight\", \"flows.28.theta.hidden.7.0.bias\", \"flows.28.theta.hidden.7.2.weight\", \"flows.28.theta.hidden.7.2.bias\", \"flows.28.theta.hidden.8.0.weight\", \"flows.28.theta.hidden.8.0.bias\", \"flows.28.theta.hidden.8.2.weight\", \"flows.28.theta.hidden.8.2.bias\", \"flows.28.theta.hidden.9.0.weight\", \"flows.28.theta.hidden.9.0.bias\", \"flows.28.theta.hidden.9.2.weight\", \"flows.28.theta.hidden.9.2.bias\", \"flows.28.theta.hidden.10.0.weight\", \"flows.28.theta.hidden.10.0.bias\", \"flows.28.theta.hidden.10.2.weight\", \"flows.28.theta.hidden.10.2.bias\", \"flows.28.theta.hidden.11.0.weight\", \"flows.28.theta.hidden.11.0.bias\", \"flows.28.theta.hidden.11.2.weight\", \"flows.28.theta.hidden.11.2.bias\", \"flows.28.theta.dims.weight\", \"flows.28.theta.dims.bias\", \"flows.29.theta.input.weight\", \"flows.29.theta.input.bias\", \"flows.29.theta.hidden.0.0.weight\", \"flows.29.theta.hidden.0.0.bias\", \"flows.29.theta.hidden.0.2.weight\", \"flows.29.theta.hidden.0.2.bias\", \"flows.29.theta.hidden.1.0.weight\", \"flows.29.theta.hidden.1.0.bias\", \"flows.29.theta.hidden.1.2.weight\", \"flows.29.theta.hidden.1.2.bias\", \"flows.29.theta.hidden.2.0.weight\", \"flows.29.theta.hidden.2.0.bias\", \"flows.29.theta.hidden.2.2.weight\", \"flows.29.theta.hidden.2.2.bias\", \"flows.29.theta.hidden.3.0.weight\", \"flows.29.theta.hidden.3.0.bias\", \"flows.29.theta.hidden.3.2.weight\", \"flows.29.theta.hidden.3.2.bias\", \"flows.29.theta.hidden.4.0.weight\", \"flows.29.theta.hidden.4.0.bias\", \"flows.29.theta.hidden.4.2.weight\", \"flows.29.theta.hidden.4.2.bias\", \"flows.29.theta.hidden.5.0.weight\", \"flows.29.theta.hidden.5.0.bias\", \"flows.29.theta.hidden.5.2.weight\", \"flows.29.theta.hidden.5.2.bias\", \"flows.29.theta.hidden.6.0.weight\", \"flows.29.theta.hidden.6.0.bias\", \"flows.29.theta.hidden.6.2.weight\", \"flows.29.theta.hidden.6.2.bias\", \"flows.29.theta.hidden.7.0.weight\", \"flows.29.theta.hidden.7.0.bias\", \"flows.29.theta.hidden.7.2.weight\", \"flows.29.theta.hidden.7.2.bias\", \"flows.29.theta.hidden.8.0.weight\", \"flows.29.theta.hidden.8.0.bias\", \"flows.29.theta.hidden.8.2.weight\", \"flows.29.theta.hidden.8.2.bias\", \"flows.29.theta.hidden.9.0.weight\", \"flows.29.theta.hidden.9.0.bias\", \"flows.29.theta.hidden.9.2.weight\", \"flows.29.theta.hidden.9.2.bias\", \"flows.29.theta.hidden.10.0.weight\", \"flows.29.theta.hidden.10.0.bias\", \"flows.29.theta.hidden.10.2.weight\", \"flows.29.theta.hidden.10.2.bias\", \"flows.29.theta.hidden.11.0.weight\", \"flows.29.theta.hidden.11.0.bias\", \"flows.29.theta.hidden.11.2.weight\", \"flows.29.theta.hidden.11.2.bias\", \"flows.29.theta.dims.weight\", \"flows.29.theta.dims.bias\", \"flows.30.theta.input.weight\", \"flows.30.theta.input.bias\", \"flows.30.theta.hidden.0.0.weight\", \"flows.30.theta.hidden.0.0.bias\", \"flows.30.theta.hidden.0.2.weight\", \"flows.30.theta.hidden.0.2.bias\", \"flows.30.theta.hidden.1.0.weight\", \"flows.30.theta.hidden.1.0.bias\", \"flows.30.theta.hidden.1.2.weight\", \"flows.30.theta.hidden.1.2.bias\", \"flows.30.theta.hidden.2.0.weight\", \"flows.30.theta.hidden.2.0.bias\", \"flows.30.theta.hidden.2.2.weight\", \"flows.30.theta.hidden.2.2.bias\", \"flows.30.theta.hidden.3.0.weight\", \"flows.30.theta.hidden.3.0.bias\", \"flows.30.theta.hidden.3.2.weight\", \"flows.30.theta.hidden.3.2.bias\", \"flows.30.theta.hidden.4.0.weight\", \"flows.30.theta.hidden.4.0.bias\", \"flows.30.theta.hidden.4.2.weight\", \"flows.30.theta.hidden.4.2.bias\", \"flows.30.theta.hidden.5.0.weight\", \"flows.30.theta.hidden.5.0.bias\", \"flows.30.theta.hidden.5.2.weight\", \"flows.30.theta.hidden.5.2.bias\", \"flows.30.theta.hidden.6.0.weight\", \"flows.30.theta.hidden.6.0.bias\", \"flows.30.theta.hidden.6.2.weight\", \"flows.30.theta.hidden.6.2.bias\", \"flows.30.theta.hidden.7.0.weight\", \"flows.30.theta.hidden.7.0.bias\", \"flows.30.theta.hidden.7.2.weight\", \"flows.30.theta.hidden.7.2.bias\", \"flows.30.theta.hidden.8.0.weight\", \"flows.30.theta.hidden.8.0.bias\", \"flows.30.theta.hidden.8.2.weight\", \"flows.30.theta.hidden.8.2.bias\", \"flows.30.theta.hidden.9.0.weight\", \"flows.30.theta.hidden.9.0.bias\", \"flows.30.theta.hidden.9.2.weight\", \"flows.30.theta.hidden.9.2.bias\", \"flows.30.theta.hidden.10.0.weight\", \"flows.30.theta.hidden.10.0.bias\", \"flows.30.theta.hidden.10.2.weight\", \"flows.30.theta.hidden.10.2.bias\", \"flows.30.theta.hidden.11.0.weight\", \"flows.30.theta.hidden.11.0.bias\", \"flows.30.theta.hidden.11.2.weight\", \"flows.30.theta.hidden.11.2.bias\", \"flows.30.theta.dims.weight\", \"flows.30.theta.dims.bias\", \"flows.31.theta.input.weight\", \"flows.31.theta.input.bias\", \"flows.31.theta.hidden.0.0.weight\", \"flows.31.theta.hidden.0.0.bias\", \"flows.31.theta.hidden.0.2.weight\", \"flows.31.theta.hidden.0.2.bias\", \"flows.31.theta.hidden.1.0.weight\", \"flows.31.theta.hidden.1.0.bias\", \"flows.31.theta.hidden.1.2.weight\", \"flows.31.theta.hidden.1.2.bias\", \"flows.31.theta.hidden.2.0.weight\", \"flows.31.theta.hidden.2.0.bias\", \"flows.31.theta.hidden.2.2.weight\", \"flows.31.theta.hidden.2.2.bias\", \"flows.31.theta.hidden.3.0.weight\", \"flows.31.theta.hidden.3.0.bias\", \"flows.31.theta.hidden.3.2.weight\", \"flows.31.theta.hidden.3.2.bias\", \"flows.31.theta.hidden.4.0.weight\", \"flows.31.theta.hidden.4.0.bias\", \"flows.31.theta.hidden.4.2.weight\", \"flows.31.theta.hidden.4.2.bias\", \"flows.31.theta.hidden.5.0.weight\", \"flows.31.theta.hidden.5.0.bias\", \"flows.31.theta.hidden.5.2.weight\", \"flows.31.theta.hidden.5.2.bias\", \"flows.31.theta.hidden.6.0.weight\", \"flows.31.theta.hidden.6.0.bias\", \"flows.31.theta.hidden.6.2.weight\", \"flows.31.theta.hidden.6.2.bias\", \"flows.31.theta.hidden.7.0.weight\", \"flows.31.theta.hidden.7.0.bias\", \"flows.31.theta.hidden.7.2.weight\", \"flows.31.theta.hidden.7.2.bias\", \"flows.31.theta.hidden.8.0.weight\", \"flows.31.theta.hidden.8.0.bias\", \"flows.31.theta.hidden.8.2.weight\", \"flows.31.theta.hidden.8.2.bias\", \"flows.31.theta.hidden.9.0.weight\", \"flows.31.theta.hidden.9.0.bias\", \"flows.31.theta.hidden.9.2.weight\", \"flows.31.theta.hidden.9.2.bias\", \"flows.31.theta.hidden.10.0.weight\", \"flows.31.theta.hidden.10.0.bias\", \"flows.31.theta.hidden.10.2.weight\", \"flows.31.theta.hidden.10.2.bias\", \"flows.31.theta.hidden.11.0.weight\", \"flows.31.theta.hidden.11.0.bias\", \"flows.31.theta.hidden.11.2.weight\", \"flows.31.theta.hidden.11.2.bias\", \"flows.31.theta.dims.weight\", \"flows.31.theta.dims.bias\", \"flows.32.theta.input.weight\", \"flows.32.theta.input.bias\", \"flows.32.theta.hidden.0.0.weight\", \"flows.32.theta.hidden.0.0.bias\", \"flows.32.theta.hidden.0.2.weight\", \"flows.32.theta.hidden.0.2.bias\", \"flows.32.theta.hidden.1.0.weight\", \"flows.32.theta.hidden.1.0.bias\", \"flows.32.theta.hidden.1.2.weight\", \"flows.32.theta.hidden.1.2.bias\", \"flows.32.theta.hidden.2.0.weight\", \"flows.32.theta.hidden.2.0.bias\", \"flows.32.theta.hidden.2.2.weight\", \"flows.32.theta.hidden.2.2.bias\", \"flows.32.theta.hidden.3.0.weight\", \"flows.32.theta.hidden.3.0.bias\", \"flows.32.theta.hidden.3.2.weight\", \"flows.32.theta.hidden.3.2.bias\", \"flows.32.theta.hidden.4.0.weight\", \"flows.32.theta.hidden.4.0.bias\", \"flows.32.theta.hidden.4.2.weight\", \"flows.32.theta.hidden.4.2.bias\", \"flows.32.theta.hidden.5.0.weight\", \"flows.32.theta.hidden.5.0.bias\", \"flows.32.theta.hidden.5.2.weight\", \"flows.32.theta.hidden.5.2.bias\", \"flows.32.theta.hidden.6.0.weight\", \"flows.32.theta.hidden.6.0.bias\", \"flows.32.theta.hidden.6.2.weight\", \"flows.32.theta.hidden.6.2.bias\", \"flows.32.theta.hidden.7.0.weight\", \"flows.32.theta.hidden.7.0.bias\", \"flows.32.theta.hidden.7.2.weight\", \"flows.32.theta.hidden.7.2.bias\", \"flows.32.theta.hidden.8.0.weight\", \"flows.32.theta.hidden.8.0.bias\", \"flows.32.theta.hidden.8.2.weight\", \"flows.32.theta.hidden.8.2.bias\", \"flows.32.theta.hidden.9.0.weight\", \"flows.32.theta.hidden.9.0.bias\", \"flows.32.theta.hidden.9.2.weight\", \"flows.32.theta.hidden.9.2.bias\", \"flows.32.theta.hidden.10.0.weight\", \"flows.32.theta.hidden.10.0.bias\", \"flows.32.theta.hidden.10.2.weight\", \"flows.32.theta.hidden.10.2.bias\", \"flows.32.theta.hidden.11.0.weight\", \"flows.32.theta.hidden.11.0.bias\", \"flows.32.theta.hidden.11.2.weight\", \"flows.32.theta.hidden.11.2.bias\", \"flows.32.theta.dims.weight\", \"flows.32.theta.dims.bias\", \"flows.33.theta.input.weight\", \"flows.33.theta.input.bias\", \"flows.33.theta.hidden.0.0.weight\", \"flows.33.theta.hidden.0.0.bias\", \"flows.33.theta.hidden.0.2.weight\", \"flows.33.theta.hidden.0.2.bias\", \"flows.33.theta.hidden.1.0.weight\", \"flows.33.theta.hidden.1.0.bias\", \"flows.33.theta.hidden.1.2.weight\", \"flows.33.theta.hidden.1.2.bias\", \"flows.33.theta.hidden.2.0.weight\", \"flows.33.theta.hidden.2.0.bias\", \"flows.33.theta.hidden.2.2.weight\", \"flows.33.theta.hidden.2.2.bias\", \"flows.33.theta.hidden.3.0.weight\", \"flows.33.theta.hidden.3.0.bias\", \"flows.33.theta.hidden.3.2.weight\", \"flows.33.theta.hidden.3.2.bias\", \"flows.33.theta.hidden.4.0.weight\", \"flows.33.theta.hidden.4.0.bias\", \"flows.33.theta.hidden.4.2.weight\", \"flows.33.theta.hidden.4.2.bias\", \"flows.33.theta.hidden.5.0.weight\", \"flows.33.theta.hidden.5.0.bias\", \"flows.33.theta.hidden.5.2.weight\", \"flows.33.theta.hidden.5.2.bias\", \"flows.33.theta.hidden.6.0.weight\", \"flows.33.theta.hidden.6.0.bias\", \"flows.33.theta.hidden.6.2.weight\", \"flows.33.theta.hidden.6.2.bias\", \"flows.33.theta.hidden.7.0.weight\", \"flows.33.theta.hidden.7.0.bias\", \"flows.33.theta.hidden.7.2.weight\", \"flows.33.theta.hidden.7.2.bias\", \"flows.33.theta.hidden.8.0.weight\", \"flows.33.theta.hidden.8.0.bias\", \"flows.33.theta.hidden.8.2.weight\", \"flows.33.theta.hidden.8.2.bias\", \"flows.33.theta.hidden.9.0.weight\", \"flows.33.theta.hidden.9.0.bias\", \"flows.33.theta.hidden.9.2.weight\", \"flows.33.theta.hidden.9.2.bias\", \"flows.33.theta.hidden.10.0.weight\", \"flows.33.theta.hidden.10.0.bias\", \"flows.33.theta.hidden.10.2.weight\", \"flows.33.theta.hidden.10.2.bias\", \"flows.33.theta.hidden.11.0.weight\", \"flows.33.theta.hidden.11.0.bias\", \"flows.33.theta.hidden.11.2.weight\", \"flows.33.theta.hidden.11.2.bias\", \"flows.33.theta.dims.weight\", \"flows.33.theta.dims.bias\", \"flows.34.theta.input.weight\", \"flows.34.theta.input.bias\", \"flows.34.theta.hidden.0.0.weight\", \"flows.34.theta.hidden.0.0.bias\", \"flows.34.theta.hidden.0.2.weight\", \"flows.34.theta.hidden.0.2.bias\", \"flows.34.theta.hidden.1.0.weight\", \"flows.34.theta.hidden.1.0.bias\", \"flows.34.theta.hidden.1.2.weight\", \"flows.34.theta.hidden.1.2.bias\", \"flows.34.theta.hidden.2.0.weight\", \"flows.34.theta.hidden.2.0.bias\", \"flows.34.theta.hidden.2.2.weight\", \"flows.34.theta.hidden.2.2.bias\", \"flows.34.theta.hidden.3.0.weight\", \"flows.34.theta.hidden.3.0.bias\", \"flows.34.theta.hidden.3.2.weight\", \"flows.34.theta.hidden.3.2.bias\", \"flows.34.theta.hidden.4.0.weight\", \"flows.34.theta.hidden.4.0.bias\", \"flows.34.theta.hidden.4.2.weight\", \"flows.34.theta.hidden.4.2.bias\", \"flows.34.theta.hidden.5.0.weight\", \"flows.34.theta.hidden.5.0.bias\", \"flows.34.theta.hidden.5.2.weight\", \"flows.34.theta.hidden.5.2.bias\", \"flows.34.theta.hidden.6.0.weight\", \"flows.34.theta.hidden.6.0.bias\", \"flows.34.theta.hidden.6.2.weight\", \"flows.34.theta.hidden.6.2.bias\", \"flows.34.theta.hidden.7.0.weight\", \"flows.34.theta.hidden.7.0.bias\", \"flows.34.theta.hidden.7.2.weight\", \"flows.34.theta.hidden.7.2.bias\", \"flows.34.theta.hidden.8.0.weight\", \"flows.34.theta.hidden.8.0.bias\", \"flows.34.theta.hidden.8.2.weight\", \"flows.34.theta.hidden.8.2.bias\", \"flows.34.theta.hidden.9.0.weight\", \"flows.34.theta.hidden.9.0.bias\", \"flows.34.theta.hidden.9.2.weight\", \"flows.34.theta.hidden.9.2.bias\", \"flows.34.theta.hidden.10.0.weight\", \"flows.34.theta.hidden.10.0.bias\", \"flows.34.theta.hidden.10.2.weight\", \"flows.34.theta.hidden.10.2.bias\", \"flows.34.theta.hidden.11.0.weight\", \"flows.34.theta.hidden.11.0.bias\", \"flows.34.theta.hidden.11.2.weight\", \"flows.34.theta.hidden.11.2.bias\", \"flows.34.theta.dims.weight\", \"flows.34.theta.dims.bias\", \"flows.35.theta.input.weight\", \"flows.35.theta.input.bias\", \"flows.35.theta.hidden.0.0.weight\", \"flows.35.theta.hidden.0.0.bias\", \"flows.35.theta.hidden.0.2.weight\", \"flows.35.theta.hidden.0.2.bias\", \"flows.35.theta.hidden.1.0.weight\", \"flows.35.theta.hidden.1.0.bias\", \"flows.35.theta.hidden.1.2.weight\", \"flows.35.theta.hidden.1.2.bias\", \"flows.35.theta.hidden.2.0.weight\", \"flows.35.theta.hidden.2.0.bias\", \"flows.35.theta.hidden.2.2.weight\", \"flows.35.theta.hidden.2.2.bias\", \"flows.35.theta.hidden.3.0.weight\", \"flows.35.theta.hidden.3.0.bias\", \"flows.35.theta.hidden.3.2.weight\", \"flows.35.theta.hidden.3.2.bias\", \"flows.35.theta.hidden.4.0.weight\", \"flows.35.theta.hidden.4.0.bias\", \"flows.35.theta.hidden.4.2.weight\", \"flows.35.theta.hidden.4.2.bias\", \"flows.35.theta.hidden.5.0.weight\", \"flows.35.theta.hidden.5.0.bias\", \"flows.35.theta.hidden.5.2.weight\", \"flows.35.theta.hidden.5.2.bias\", \"flows.35.theta.hidden.6.0.weight\", \"flows.35.theta.hidden.6.0.bias\", \"flows.35.theta.hidden.6.2.weight\", \"flows.35.theta.hidden.6.2.bias\", \"flows.35.theta.hidden.7.0.weight\", \"flows.35.theta.hidden.7.0.bias\", \"flows.35.theta.hidden.7.2.weight\", \"flows.35.theta.hidden.7.2.bias\", \"flows.35.theta.hidden.8.0.weight\", \"flows.35.theta.hidden.8.0.bias\", \"flows.35.theta.hidden.8.2.weight\", \"flows.35.theta.hidden.8.2.bias\", \"flows.35.theta.hidden.9.0.weight\", \"flows.35.theta.hidden.9.0.bias\", \"flows.35.theta.hidden.9.2.weight\", \"flows.35.theta.hidden.9.2.bias\", \"flows.35.theta.hidden.10.0.weight\", \"flows.35.theta.hidden.10.0.bias\", \"flows.35.theta.hidden.10.2.weight\", \"flows.35.theta.hidden.10.2.bias\", \"flows.35.theta.hidden.11.0.weight\", \"flows.35.theta.hidden.11.0.bias\", \"flows.35.theta.hidden.11.2.weight\", \"flows.35.theta.hidden.11.2.bias\", \"flows.35.theta.dims.weight\", \"flows.35.theta.dims.bias\", \"flows.36.theta.input.weight\", \"flows.36.theta.input.bias\", \"flows.36.theta.hidden.0.0.weight\", \"flows.36.theta.hidden.0.0.bias\", \"flows.36.theta.hidden.0.2.weight\", \"flows.36.theta.hidden.0.2.bias\", \"flows.36.theta.hidden.1.0.weight\", \"flows.36.theta.hidden.1.0.bias\", \"flows.36.theta.hidden.1.2.weight\", \"flows.36.theta.hidden.1.2.bias\", \"flows.36.theta.hidden.2.0.weight\", \"flows.36.theta.hidden.2.0.bias\", \"flows.36.theta.hidden.2.2.weight\", \"flows.36.theta.hidden.2.2.bias\", \"flows.36.theta.hidden.3.0.weight\", \"flows.36.theta.hidden.3.0.bias\", \"flows.36.theta.hidden.3.2.weight\", \"flows.36.theta.hidden.3.2.bias\", \"flows.36.theta.hidden.4.0.weight\", \"flows.36.theta.hidden.4.0.bias\", \"flows.36.theta.hidden.4.2.weight\", \"flows.36.theta.hidden.4.2.bias\", \"flows.36.theta.hidden.5.0.weight\", \"flows.36.theta.hidden.5.0.bias\", \"flows.36.theta.hidden.5.2.weight\", \"flows.36.theta.hidden.5.2.bias\", \"flows.36.theta.hidden.6.0.weight\", \"flows.36.theta.hidden.6.0.bias\", \"flows.36.theta.hidden.6.2.weight\", \"flows.36.theta.hidden.6.2.bias\", \"flows.36.theta.hidden.7.0.weight\", \"flows.36.theta.hidden.7.0.bias\", \"flows.36.theta.hidden.7.2.weight\", \"flows.36.theta.hidden.7.2.bias\", \"flows.36.theta.hidden.8.0.weight\", \"flows.36.theta.hidden.8.0.bias\", \"flows.36.theta.hidden.8.2.weight\", \"flows.36.theta.hidden.8.2.bias\", \"flows.36.theta.hidden.9.0.weight\", \"flows.36.theta.hidden.9.0.bias\", \"flows.36.theta.hidden.9.2.weight\", \"flows.36.theta.hidden.9.2.bias\", \"flows.36.theta.hidden.10.0.weight\", \"flows.36.theta.hidden.10.0.bias\", \"flows.36.theta.hidden.10.2.weight\", \"flows.36.theta.hidden.10.2.bias\", \"flows.36.theta.hidden.11.0.weight\", \"flows.36.theta.hidden.11.0.bias\", \"flows.36.theta.hidden.11.2.weight\", \"flows.36.theta.hidden.11.2.bias\", \"flows.36.theta.dims.weight\", \"flows.36.theta.dims.bias\", \"flows.37.theta.input.weight\", \"flows.37.theta.input.bias\", \"flows.37.theta.hidden.0.0.weight\", \"flows.37.theta.hidden.0.0.bias\", \"flows.37.theta.hidden.0.2.weight\", \"flows.37.theta.hidden.0.2.bias\", \"flows.37.theta.hidden.1.0.weight\", \"flows.37.theta.hidden.1.0.bias\", \"flows.37.theta.hidden.1.2.weight\", \"flows.37.theta.hidden.1.2.bias\", \"flows.37.theta.hidden.2.0.weight\", \"flows.37.theta.hidden.2.0.bias\", \"flows.37.theta.hidden.2.2.weight\", \"flows.37.theta.hidden.2.2.bias\", \"flows.37.theta.hidden.3.0.weight\", \"flows.37.theta.hidden.3.0.bias\", \"flows.37.theta.hidden.3.2.weight\", \"flows.37.theta.hidden.3.2.bias\", \"flows.37.theta.hidden.4.0.weight\", \"flows.37.theta.hidden.4.0.bias\", \"flows.37.theta.hidden.4.2.weight\", \"flows.37.theta.hidden.4.2.bias\", \"flows.37.theta.hidden.5.0.weight\", \"flows.37.theta.hidden.5.0.bias\", \"flows.37.theta.hidden.5.2.weight\", \"flows.37.theta.hidden.5.2.bias\", \"flows.37.theta.hidden.6.0.weight\", \"flows.37.theta.hidden.6.0.bias\", \"flows.37.theta.hidden.6.2.weight\", \"flows.37.theta.hidden.6.2.bias\", \"flows.37.theta.hidden.7.0.weight\", \"flows.37.theta.hidden.7.0.bias\", \"flows.37.theta.hidden.7.2.weight\", \"flows.37.theta.hidden.7.2.bias\", \"flows.37.theta.hidden.8.0.weight\", \"flows.37.theta.hidden.8.0.bias\", \"flows.37.theta.hidden.8.2.weight\", \"flows.37.theta.hidden.8.2.bias\", \"flows.37.theta.hidden.9.0.weight\", \"flows.37.theta.hidden.9.0.bias\", \"flows.37.theta.hidden.9.2.weight\", \"flows.37.theta.hidden.9.2.bias\", \"flows.37.theta.hidden.10.0.weight\", \"flows.37.theta.hidden.10.0.bias\", \"flows.37.theta.hidden.10.2.weight\", \"flows.37.theta.hidden.10.2.bias\", \"flows.37.theta.hidden.11.0.weight\", \"flows.37.theta.hidden.11.0.bias\", \"flows.37.theta.hidden.11.2.weight\", \"flows.37.theta.hidden.11.2.bias\", \"flows.37.theta.dims.weight\", \"flows.37.theta.dims.bias\", \"flows.38.theta.input.weight\", \"flows.38.theta.input.bias\", \"flows.38.theta.hidden.0.0.weight\", \"flows.38.theta.hidden.0.0.bias\", \"flows.38.theta.hidden.0.2.weight\", \"flows.38.theta.hidden.0.2.bias\", \"flows.38.theta.hidden.1.0.weight\", \"flows.38.theta.hidden.1.0.bias\", \"flows.38.theta.hidden.1.2.weight\", \"flows.38.theta.hidden.1.2.bias\", \"flows.38.theta.hidden.2.0.weight\", \"flows.38.theta.hidden.2.0.bias\", \"flows.38.theta.hidden.2.2.weight\", \"flows.38.theta.hidden.2.2.bias\", \"flows.38.theta.hidden.3.0.weight\", \"flows.38.theta.hidden.3.0.bias\", \"flows.38.theta.hidden.3.2.weight\", \"flows.38.theta.hidden.3.2.bias\", \"flows.38.theta.hidden.4.0.weight\", \"flows.38.theta.hidden.4.0.bias\", \"flows.38.theta.hidden.4.2.weight\", \"flows.38.theta.hidden.4.2.bias\", \"flows.38.theta.hidden.5.0.weight\", \"flows.38.theta.hidden.5.0.bias\", \"flows.38.theta.hidden.5.2.weight\", \"flows.38.theta.hidden.5.2.bias\", \"flows.38.theta.hidden.6.0.weight\", \"flows.38.theta.hidden.6.0.bias\", \"flows.38.theta.hidden.6.2.weight\", \"flows.38.theta.hidden.6.2.bias\", \"flows.38.theta.hidden.7.0.weight\", \"flows.38.theta.hidden.7.0.bias\", \"flows.38.theta.hidden.7.2.weight\", \"flows.38.theta.hidden.7.2.bias\", \"flows.38.theta.hidden.8.0.weight\", \"flows.38.theta.hidden.8.0.bias\", \"flows.38.theta.hidden.8.2.weight\", \"flows.38.theta.hidden.8.2.bias\", \"flows.38.theta.hidden.9.0.weight\", \"flows.38.theta.hidden.9.0.bias\", \"flows.38.theta.hidden.9.2.weight\", \"flows.38.theta.hidden.9.2.bias\", \"flows.38.theta.hidden.10.0.weight\", \"flows.38.theta.hidden.10.0.bias\", \"flows.38.theta.hidden.10.2.weight\", \"flows.38.theta.hidden.10.2.bias\", \"flows.38.theta.hidden.11.0.weight\", \"flows.38.theta.hidden.11.0.bias\", \"flows.38.theta.hidden.11.2.weight\", \"flows.38.theta.hidden.11.2.bias\", \"flows.38.theta.dims.weight\", \"flows.38.theta.dims.bias\", \"flows.39.theta.input.weight\", \"flows.39.theta.input.bias\", \"flows.39.theta.hidden.0.0.weight\", \"flows.39.theta.hidden.0.0.bias\", \"flows.39.theta.hidden.0.2.weight\", \"flows.39.theta.hidden.0.2.bias\", \"flows.39.theta.hidden.1.0.weight\", \"flows.39.theta.hidden.1.0.bias\", \"flows.39.theta.hidden.1.2.weight\", \"flows.39.theta.hidden.1.2.bias\", \"flows.39.theta.hidden.2.0.weight\", \"flows.39.theta.hidden.2.0.bias\", \"flows.39.theta.hidden.2.2.weight\", \"flows.39.theta.hidden.2.2.bias\", \"flows.39.theta.hidden.3.0.weight\", \"flows.39.theta.hidden.3.0.bias\", \"flows.39.theta.hidden.3.2.weight\", \"flows.39.theta.hidden.3.2.bias\", \"flows.39.theta.hidden.4.0.weight\", \"flows.39.theta.hidden.4.0.bias\", \"flows.39.theta.hidden.4.2.weight\", \"flows.39.theta.hidden.4.2.bias\", \"flows.39.theta.hidden.5.0.weight\", \"flows.39.theta.hidden.5.0.bias\", \"flows.39.theta.hidden.5.2.weight\", \"flows.39.theta.hidden.5.2.bias\", \"flows.39.theta.hidden.6.0.weight\", \"flows.39.theta.hidden.6.0.bias\", \"flows.39.theta.hidden.6.2.weight\", \"flows.39.theta.hidden.6.2.bias\", \"flows.39.theta.hidden.7.0.weight\", \"flows.39.theta.hidden.7.0.bias\", \"flows.39.theta.hidden.7.2.weight\", \"flows.39.theta.hidden.7.2.bias\", \"flows.39.theta.hidden.8.0.weight\", \"flows.39.theta.hidden.8.0.bias\", \"flows.39.theta.hidden.8.2.weight\", \"flows.39.theta.hidden.8.2.bias\", \"flows.39.theta.hidden.9.0.weight\", \"flows.39.theta.hidden.9.0.bias\", \"flows.39.theta.hidden.9.2.weight\", \"flows.39.theta.hidden.9.2.bias\", \"flows.39.theta.hidden.10.0.weight\", \"flows.39.theta.hidden.10.0.bias\", \"flows.39.theta.hidden.10.2.weight\", \"flows.39.theta.hidden.10.2.bias\", \"flows.39.theta.hidden.11.0.weight\", \"flows.39.theta.hidden.11.0.bias\", \"flows.39.theta.hidden.11.2.weight\", \"flows.39.theta.hidden.11.2.bias\", \"flows.39.theta.dims.weight\", \"flows.39.theta.dims.bias\", \"flows.40.theta.input.weight\", \"flows.40.theta.input.bias\", \"flows.40.theta.hidden.0.0.weight\", \"flows.40.theta.hidden.0.0.bias\", \"flows.40.theta.hidden.0.2.weight\", \"flows.40.theta.hidden.0.2.bias\", \"flows.40.theta.hidden.1.0.weight\", \"flows.40.theta.hidden.1.0.bias\", \"flows.40.theta.hidden.1.2.weight\", \"flows.40.theta.hidden.1.2.bias\", \"flows.40.theta.hidden.2.0.weight\", \"flows.40.theta.hidden.2.0.bias\", \"flows.40.theta.hidden.2.2.weight\", \"flows.40.theta.hidden.2.2.bias\", \"flows.40.theta.hidden.3.0.weight\", \"flows.40.theta.hidden.3.0.bias\", \"flows.40.theta.hidden.3.2.weight\", \"flows.40.theta.hidden.3.2.bias\", \"flows.40.theta.hidden.4.0.weight\", \"flows.40.theta.hidden.4.0.bias\", \"flows.40.theta.hidden.4.2.weight\", \"flows.40.theta.hidden.4.2.bias\", \"flows.40.theta.hidden.5.0.weight\", \"flows.40.theta.hidden.5.0.bias\", \"flows.40.theta.hidden.5.2.weight\", \"flows.40.theta.hidden.5.2.bias\", \"flows.40.theta.hidden.6.0.weight\", \"flows.40.theta.hidden.6.0.bias\", \"flows.40.theta.hidden.6.2.weight\", \"flows.40.theta.hidden.6.2.bias\", \"flows.40.theta.hidden.7.0.weight\", \"flows.40.theta.hidden.7.0.bias\", \"flows.40.theta.hidden.7.2.weight\", \"flows.40.theta.hidden.7.2.bias\", \"flows.40.theta.hidden.8.0.weight\", \"flows.40.theta.hidden.8.0.bias\", \"flows.40.theta.hidden.8.2.weight\", \"flows.40.theta.hidden.8.2.bias\", \"flows.40.theta.hidden.9.0.weight\", \"flows.40.theta.hidden.9.0.bias\", \"flows.40.theta.hidden.9.2.weight\", \"flows.40.theta.hidden.9.2.bias\", \"flows.40.theta.hidden.10.0.weight\", \"flows.40.theta.hidden.10.0.bias\", \"flows.40.theta.hidden.10.2.weight\", \"flows.40.theta.hidden.10.2.bias\", \"flows.40.theta.hidden.11.0.weight\", \"flows.40.theta.hidden.11.0.bias\", \"flows.40.theta.hidden.11.2.weight\", \"flows.40.theta.hidden.11.2.bias\", \"flows.40.theta.dims.weight\", \"flows.40.theta.dims.bias\", \"flows.41.weight\". \n\tUnexpected key(s) in state_dict: \"flows.14.theta.input.weight\", \"flows.14.theta.input.bias\", \"flows.14.theta.hidden.0.0.weight\", \"flows.14.theta.hidden.0.0.bias\", \"flows.14.theta.hidden.0.2.weight\", \"flows.14.theta.hidden.0.2.bias\", \"flows.14.theta.hidden.1.0.weight\", \"flows.14.theta.hidden.1.0.bias\", \"flows.14.theta.hidden.1.2.weight\", \"flows.14.theta.hidden.1.2.bias\", \"flows.14.theta.hidden.2.0.weight\", \"flows.14.theta.hidden.2.0.bias\", \"flows.14.theta.hidden.2.2.weight\", \"flows.14.theta.hidden.2.2.bias\", \"flows.14.theta.hidden.3.0.weight\", \"flows.14.theta.hidden.3.0.bias\", \"flows.14.theta.hidden.3.2.weight\", \"flows.14.theta.hidden.3.2.bias\", \"flows.14.theta.hidden.4.0.weight\", \"flows.14.theta.hidden.4.0.bias\", \"flows.14.theta.hidden.4.2.weight\", \"flows.14.theta.hidden.4.2.bias\", \"flows.14.theta.hidden.5.0.weight\", \"flows.14.theta.hidden.5.0.bias\", \"flows.14.theta.hidden.5.2.weight\", \"flows.14.theta.hidden.5.2.bias\", \"flows.14.theta.hidden.6.0.weight\", \"flows.14.theta.hidden.6.0.bias\", \"flows.14.theta.hidden.6.2.weight\", \"flows.14.theta.hidden.6.2.bias\", \"flows.14.theta.hidden.7.0.weight\", \"flows.14.theta.hidden.7.0.bias\", \"flows.14.theta.hidden.7.2.weight\", \"flows.14.theta.hidden.7.2.bias\", \"flows.14.theta.hidden.8.0.weight\", \"flows.14.theta.hidden.8.0.bias\", \"flows.14.theta.hidden.8.2.weight\", \"flows.14.theta.hidden.8.2.bias\", \"flows.14.theta.hidden.9.0.weight\", \"flows.14.theta.hidden.9.0.bias\", \"flows.14.theta.hidden.9.2.weight\", \"flows.14.theta.hidden.9.2.bias\", \"flows.14.theta.hidden.10.0.weight\", \"flows.14.theta.hidden.10.0.bias\", \"flows.14.theta.hidden.10.2.weight\", \"flows.14.theta.hidden.10.2.bias\", \"flows.14.theta.hidden.11.0.weight\", \"flows.14.theta.hidden.11.0.bias\", \"flows.14.theta.hidden.11.2.weight\", \"flows.14.theta.hidden.11.2.bias\", \"flows.14.theta.dims.weight\", \"flows.14.theta.dims.bias\", \"flows.16.theta.input.weight\", \"flows.16.theta.input.bias\", \"flows.16.theta.hidden.0.0.weight\", \"flows.16.theta.hidden.0.0.bias\", \"flows.16.theta.hidden.0.2.weight\", \"flows.16.theta.hidden.0.2.bias\", \"flows.16.theta.hidden.1.0.weight\", \"flows.16.theta.hidden.1.0.bias\", \"flows.16.theta.hidden.1.2.weight\", \"flows.16.theta.hidden.1.2.bias\", \"flows.16.theta.hidden.2.0.weight\", \"flows.16.theta.hidden.2.0.bias\", \"flows.16.theta.hidden.2.2.weight\", \"flows.16.theta.hidden.2.2.bias\", \"flows.16.theta.hidden.3.0.weight\", \"flows.16.theta.hidden.3.0.bias\", \"flows.16.theta.hidden.3.2.weight\", \"flows.16.theta.hidden.3.2.bias\", \"flows.16.theta.hidden.4.0.weight\", \"flows.16.theta.hidden.4.0.bias\", \"flows.16.theta.hidden.4.2.weight\", \"flows.16.theta.hidden.4.2.bias\", \"flows.16.theta.hidden.5.0.weight\", \"flows.16.theta.hidden.5.0.bias\", \"flows.16.theta.hidden.5.2.weight\", \"flows.16.theta.hidden.5.2.bias\", \"flows.16.theta.hidden.6.0.weight\", \"flows.16.theta.hidden.6.0.bias\", \"flows.16.theta.hidden.6.2.weight\", \"flows.16.theta.hidden.6.2.bias\", \"flows.16.theta.hidden.7.0.weight\", \"flows.16.theta.hidden.7.0.bias\", \"flows.16.theta.hidden.7.2.weight\", \"flows.16.theta.hidden.7.2.bias\", \"flows.16.theta.hidden.8.0.weight\", \"flows.16.theta.hidden.8.0.bias\", \"flows.16.theta.hidden.8.2.weight\", \"flows.16.theta.hidden.8.2.bias\", \"flows.16.theta.hidden.9.0.weight\", \"flows.16.theta.hidden.9.0.bias\", \"flows.16.theta.hidden.9.2.weight\", \"flows.16.theta.hidden.9.2.bias\", \"flows.16.theta.hidden.10.0.weight\", \"flows.16.theta.hidden.10.0.bias\", \"flows.16.theta.hidden.10.2.weight\", \"flows.16.theta.hidden.10.2.bias\", \"flows.16.theta.hidden.11.0.weight\", \"flows.16.theta.hidden.11.0.bias\", \"flows.16.theta.hidden.11.2.weight\", \"flows.16.theta.hidden.11.2.bias\", \"flows.16.theta.dims.weight\", \"flows.16.theta.dims.bias\", \"flows.18.theta.input.weight\", \"flows.18.theta.input.bias\", \"flows.18.theta.hidden.0.0.weight\", \"flows.18.theta.hidden.0.0.bias\", \"flows.18.theta.hidden.0.2.weight\", \"flows.18.theta.hidden.0.2.bias\", \"flows.18.theta.hidden.1.0.weight\", \"flows.18.theta.hidden.1.0.bias\", \"flows.18.theta.hidden.1.2.weight\", \"flows.18.theta.hidden.1.2.bias\", \"flows.18.theta.hidden.2.0.weight\", \"flows.18.theta.hidden.2.0.bias\", \"flows.18.theta.hidden.2.2.weight\", \"flows.18.theta.hidden.2.2.bias\", \"flows.18.theta.hidden.3.0.weight\", \"flows.18.theta.hidden.3.0.bias\", \"flows.18.theta.hidden.3.2.weight\", \"flows.18.theta.hidden.3.2.bias\", \"flows.18.theta.hidden.4.0.weight\", \"flows.18.theta.hidden.4.0.bias\", \"flows.18.theta.hidden.4.2.weight\", \"flows.18.theta.hidden.4.2.bias\", \"flows.18.theta.hidden.5.0.weight\", \"flows.18.theta.hidden.5.0.bias\", \"flows.18.theta.hidden.5.2.weight\", \"flows.18.theta.hidden.5.2.bias\", \"flows.18.theta.hidden.6.0.weight\", \"flows.18.theta.hidden.6.0.bias\", \"flows.18.theta.hidden.6.2.weight\", \"flows.18.theta.hidden.6.2.bias\", \"flows.18.theta.hidden.7.0.weight\", \"flows.18.theta.hidden.7.0.bias\", \"flows.18.theta.hidden.7.2.weight\", \"flows.18.theta.hidden.7.2.bias\", \"flows.18.theta.hidden.8.0.weight\", \"flows.18.theta.hidden.8.0.bias\", \"flows.18.theta.hidden.8.2.weight\", \"flows.18.theta.hidden.8.2.bias\", \"flows.18.theta.hidden.9.0.weight\", \"flows.18.theta.hidden.9.0.bias\", \"flows.18.theta.hidden.9.2.weight\", \"flows.18.theta.hidden.9.2.bias\", \"flows.18.theta.hidden.10.0.weight\", \"flows.18.theta.hidden.10.0.bias\", \"flows.18.theta.hidden.10.2.weight\", \"flows.18.theta.hidden.10.2.bias\", \"flows.18.theta.hidden.11.0.weight\", \"flows.18.theta.hidden.11.0.bias\", \"flows.18.theta.hidden.11.2.weight\", \"flows.18.theta.hidden.11.2.bias\", \"flows.18.theta.dims.weight\", \"flows.18.theta.dims.bias\", \"flows.20.theta.input.weight\", \"flows.20.theta.input.bias\", \"flows.20.theta.hidden.0.0.weight\", \"flows.20.theta.hidden.0.0.bias\", \"flows.20.theta.hidden.0.2.weight\", \"flows.20.theta.hidden.0.2.bias\", \"flows.20.theta.hidden.1.0.weight\", \"flows.20.theta.hidden.1.0.bias\", \"flows.20.theta.hidden.1.2.weight\", \"flows.20.theta.hidden.1.2.bias\", \"flows.20.theta.hidden.2.0.weight\", \"flows.20.theta.hidden.2.0.bias\", \"flows.20.theta.hidden.2.2.weight\", \"flows.20.theta.hidden.2.2.bias\", \"flows.20.theta.hidden.3.0.weight\", \"flows.20.theta.hidden.3.0.bias\", \"flows.20.theta.hidden.3.2.weight\", \"flows.20.theta.hidden.3.2.bias\", \"flows.20.theta.hidden.4.0.weight\", \"flows.20.theta.hidden.4.0.bias\", \"flows.20.theta.hidden.4.2.weight\", \"flows.20.theta.hidden.4.2.bias\", \"flows.20.theta.hidden.5.0.weight\", \"flows.20.theta.hidden.5.0.bias\", \"flows.20.theta.hidden.5.2.weight\", \"flows.20.theta.hidden.5.2.bias\", \"flows.20.theta.hidden.6.0.weight\", \"flows.20.theta.hidden.6.0.bias\", \"flows.20.theta.hidden.6.2.weight\", \"flows.20.theta.hidden.6.2.bias\", \"flows.20.theta.hidden.7.0.weight\", \"flows.20.theta.hidden.7.0.bias\", \"flows.20.theta.hidden.7.2.weight\", \"flows.20.theta.hidden.7.2.bias\", \"flows.20.theta.hidden.8.0.weight\", \"flows.20.theta.hidden.8.0.bias\", \"flows.20.theta.hidden.8.2.weight\", \"flows.20.theta.hidden.8.2.bias\", \"flows.20.theta.hidden.9.0.weight\", \"flows.20.theta.hidden.9.0.bias\", \"flows.20.theta.hidden.9.2.weight\", \"flows.20.theta.hidden.9.2.bias\", \"flows.20.theta.hidden.10.0.weight\", \"flows.20.theta.hidden.10.0.bias\", \"flows.20.theta.hidden.10.2.weight\", \"flows.20.theta.hidden.10.2.bias\", \"flows.20.theta.hidden.11.0.weight\", \"flows.20.theta.hidden.11.0.bias\", \"flows.20.theta.hidden.11.2.weight\", \"flows.20.theta.hidden.11.2.bias\", \"flows.20.theta.dims.weight\", \"flows.20.theta.dims.bias\", \"flows.22.theta.input.weight\", \"flows.22.theta.input.bias\", \"flows.22.theta.hidden.0.0.weight\", \"flows.22.theta.hidden.0.0.bias\", \"flows.22.theta.hidden.0.2.weight\", \"flows.22.theta.hidden.0.2.bias\", \"flows.22.theta.hidden.1.0.weight\", \"flows.22.theta.hidden.1.0.bias\", \"flows.22.theta.hidden.1.2.weight\", \"flows.22.theta.hidden.1.2.bias\", \"flows.22.theta.hidden.2.0.weight\", \"flows.22.theta.hidden.2.0.bias\", \"flows.22.theta.hidden.2.2.weight\", \"flows.22.theta.hidden.2.2.bias\", \"flows.22.theta.hidden.3.0.weight\", \"flows.22.theta.hidden.3.0.bias\", \"flows.22.theta.hidden.3.2.weight\", \"flows.22.theta.hidden.3.2.bias\", \"flows.22.theta.hidden.4.0.weight\", \"flows.22.theta.hidden.4.0.bias\", \"flows.22.theta.hidden.4.2.weight\", \"flows.22.theta.hidden.4.2.bias\", \"flows.22.theta.hidden.5.0.weight\", \"flows.22.theta.hidden.5.0.bias\", \"flows.22.theta.hidden.5.2.weight\", \"flows.22.theta.hidden.5.2.bias\", \"flows.22.theta.hidden.6.0.weight\", \"flows.22.theta.hidden.6.0.bias\", \"flows.22.theta.hidden.6.2.weight\", \"flows.22.theta.hidden.6.2.bias\", \"flows.22.theta.hidden.7.0.weight\", \"flows.22.theta.hidden.7.0.bias\", \"flows.22.theta.hidden.7.2.weight\", \"flows.22.theta.hidden.7.2.bias\", \"flows.22.theta.hidden.8.0.weight\", \"flows.22.theta.hidden.8.0.bias\", \"flows.22.theta.hidden.8.2.weight\", \"flows.22.theta.hidden.8.2.bias\", \"flows.22.theta.hidden.9.0.weight\", \"flows.22.theta.hidden.9.0.bias\", \"flows.22.theta.hidden.9.2.weight\", \"flows.22.theta.hidden.9.2.bias\", \"flows.22.theta.hidden.10.0.weight\", \"flows.22.theta.hidden.10.0.bias\", \"flows.22.theta.hidden.10.2.weight\", \"flows.22.theta.hidden.10.2.bias\", \"flows.22.theta.hidden.11.0.weight\", \"flows.22.theta.hidden.11.0.bias\", \"flows.22.theta.hidden.11.2.weight\", \"flows.22.theta.hidden.11.2.bias\", \"flows.22.theta.dims.weight\", \"flows.22.theta.dims.bias\", \"flows.23.weight\". "
     ]
    }
   ],
   "source": [
    "from Data import train_loader\n",
    "\n",
    "set_random_seed(42)\n",
    "nf=NormalizingFlow(latent=normal_dist,flows=configure_flows(24),conv_flows=configure_conv_flows(0,kernel_size=16),ort=True)\n",
    "nf.load_state_dict(torch.load('model_weights1.pth'))\n",
    "pipeline=Pipeline(model=nf,criterion=KL_ur,optimizer_class=torch.optim.LBFGS,optimizer_kwargs={\"lr\": 0.0001})\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=20,\n",
    "    logger=TensorBoardLogger(save_dir=f\"logs/nf\"),\n",
    "    num_sanity_val_steps=0,\n",
    "    log_every_n_steps=1,\n",
    "    enable_checkpointing=False,\n",
    "    accumulate_grad_batches=8\n",
    ")\n",
    "\n",
    "trainer.fit(model=pipeline, train_dataloaders=train_loader)\n",
    "torch.save(nf.state_dict(), \"model_weights3.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "a808807a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T18:58:44.760034Z",
     "iopub.status.busy": "2024-03-09T18:58:44.759135Z",
     "iopub.status.idle": "2024-03-09T18:58:44.807949Z",
     "shell.execute_reply": "2024-03-09T18:58:44.806644Z",
     "shell.execute_reply.started": "2024-03-09T18:58:44.759984Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "from Data import normal_dist\n",
    "import numpy as np\n",
    "from NFconstants import N_traj\n",
    "NF_trained=NormalizingFlow(latent=normal_dist,flows=configure_flows(24),conv_flows=configure_conv_flows(0,kernel_size=8),ort=True)\n",
    "NF_trained.load_state_dict(torch.load('model_weights1.pth'))\n",
    "NF_trained.eval()\n",
    "print(NF_trained.ort)\n",
    "trajs=NF_trained.sample(N_traj)\n",
    "#trajs=trajs.numpy()\n",
    "#np.savetxt(\"nf_ensemble.txt\",trajs,delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "fe644a5e-8e4a-4536-bec1-78a391b60f97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T18:58:46.341964Z",
     "iopub.status.busy": "2024-03-09T18:58:46.341268Z",
     "iopub.status.idle": "2024-03-09T18:58:46.484707Z",
     "shell.execute_reply": "2024-03-09T18:58:46.483288Z",
     "shell.execute_reply.started": "2024-03-09T18:58:46.341927Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from NFandist import get_T\n",
    "T=torch.tensor(get_T(N_nod)).float()\n",
    "def G(X,n_p=N_nod):\n",
    "    G=np.zeros((n_p))\n",
    "    Y=X.clone()\n",
    "    Xt=torch.t(X)\n",
    "    for s in range(n_p):\n",
    "        G[s]=torch.trace(torch.matmul(Y,Xt))\n",
    "        Y=torch.matmul(Y,T)\n",
    "    return G/(N_traj*N_nod)\n",
    "g_nf=G(trajs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "78c9ffdf-7d11-49a0-8304-3228e4cd69b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T18:40:22.001276Z",
     "iopub.status.busy": "2024-03-09T18:40:22.000282Z",
     "iopub.status.idle": "2024-03-09T18:40:22.050433Z",
     "shell.execute_reply": "2024-03-09T18:40:22.048581Z",
     "shell.execute_reply.started": "2024-03-09T18:40:22.001235Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from NFandist import calc_G\n",
    "from NFconstants import N_nod, N_traj, NG_points,beta\n",
    "g_osc=calc_G(N_nod,beta,N_nod)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d40ea38c-5c07-4349-9872-6f8026d990d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T13:22:54.171690Z",
     "iopub.status.busy": "2024-03-09T13:22:54.170555Z",
     "iopub.status.idle": "2024-03-09T13:22:54.187599Z",
     "shell.execute_reply": "2024-03-09T13:22:54.186409Z",
     "shell.execute_reply.started": "2024-03-09T13:22:54.171657Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "g_ur = [0.476546, 0.148654, 0.060357, 0.0232596, -0.00447499, -0.00224423, -0.00447499, 0.0232596, 0.060357, 0.148654]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "423d9be1-411c-4004-929e-ddd280cb3a77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T18:58:49.428452Z",
     "iopub.status.busy": "2024-03-09T18:58:49.427719Z",
     "iopub.status.idle": "2024-03-09T18:58:49.453295Z",
     "shell.execute_reply": "2024-03-09T18:58:49.451855Z",
     "shell.execute_reply.started": "2024-03-09T18:58:49.428416Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "g_ur = [0.555858, 0.497988, 0.446597, 0.401115, 0.360415, 0.324316, 0.29138, 0.261791, 0.235658, 0.211969, 0.190536, 0.171994, 0.155133, 0.140335, 0.126598, 0.114471, 0.103514, 0.0941716, 0.0852865, 0.0767528, 0.0691313, 0.0619047, 0.0550745, 0.0490998, 0.0443236, 0.0396256, 0.0358628, 0.0324961, 0.0302019, 0.0276177, 0.0251373, 0.0226234, 0.0203086, 0.0179717, 0.0164385, 0.0152739, 0.0143051, 0.0136778, 0.0127566, 0.0118486, 0.0111658, 0.0111462, 0.011026, 0.0110081, 0.0109681, 0.0106729, 0.0101027, 0.010377, 0.010866, 0.0114044, 0.0119873, 0.0114044, 0.010866, 0.010377, 0.0101027, 0.0106729, 0.0109681, 0.0110081, 0.011026, 0.0111462, 0.0111658, 0.0118486, 0.0127566, 0.0136778, 0.0143051, 0.0152739, 0.0164385, 0.0179717, 0.0203086, 0.0226234, 0.0251373, 0.0276177, 0.0302019, 0.0324961, 0.0358628, 0.0396256, 0.0443236, 0.0490998, 0.0550745, 0.0619047, 0.0691313, 0.0767528, 0.0852865, 0.0941716, 0.103514, 0.114471, 0.126598, 0.140335, 0.155133, 0.171994, 0.190536, 0.211969, 0.235658, 0.261791, 0.29138, 0.324316, 0.360415, 0.401115, 0.446597, 0.497988]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "761d4f40-3376-4f0e-9177-6ff5ff928fa4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T13:22:55.491639Z",
     "iopub.status.busy": "2024-03-09T13:22:55.490685Z",
     "iopub.status.idle": "2024-03-09T13:22:55.506950Z",
     "shell.execute_reply": "2024-03-09T13:22:55.505579Z",
     "shell.execute_reply.started": "2024-03-09T13:22:55.491606Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "g_rel = [0.389004, 0.174591, 0.0750764, 0.0320855, 0.0235634, 0.0204869, 0.0235634, 0.0320855, 0.0750764, 0.174591]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "f0639e9e-3fa3-412f-8833-8af468af9fa8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T15:46:47.410324Z",
     "iopub.status.busy": "2024-03-09T15:46:47.409308Z",
     "iopub.status.idle": "2024-03-09T15:46:47.425537Z",
     "shell.execute_reply": "2024-03-09T15:46:47.424327Z",
     "shell.execute_reply.started": "2024-03-09T15:46:47.410270Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "g_rel = [0.392501, 0.361773, 0.333519, 0.307446, 0.283335, 0.261201, 0.240658, 0.221871, 0.204776, 0.188963, 0.174495, 0.161116, 0.148541, 0.136946, 0.126175, 0.116168, 0.106934, 0.0985733, 0.090693, 0.0836987, 0.0773237, 0.0713712, 0.0662134, 0.0611666, 0.0567049, 0.0525145, 0.0489322, 0.045775, 0.043085, 0.0407685, 0.0383386, 0.0365845, 0.0353032, 0.0339074, 0.0324167, 0.0308972, 0.0295226, 0.0285374, 0.0276133, 0.026899, 0.0265193, 0.0267518, 0.027023, 0.0272673, 0.0275789, 0.0277296, 0.0281657, 0.0286108, 0.0289897, 0.0292072, 0.0292838, 0.0292072, 0.0289897, 0.0286108, 0.0281657, 0.0277296, 0.0275789, 0.0272673, 0.027023, 0.0267518, 0.0265193, 0.026899, 0.0276133, 0.0285374, 0.0295226, 0.0308972, 0.0324167, 0.0339074, 0.0353032, 0.0365845, 0.0383386, 0.0407685, 0.043085, 0.045775, 0.0489322, 0.0525145, 0.0567049, 0.0611666, 0.0662134, 0.0713712, 0.0773237, 0.0836987, 0.090693, 0.0985733, 0.106934, 0.116168, 0.126175, 0.136946, 0.148541, 0.161116, 0.174495, 0.188963, 0.204776, 0.221871, 0.240658, 0.261201, 0.283335, 0.307446, 0.333519, 0.361773]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "65e2959c-aa9d-47a0-971a-68fd6575b32e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T13:22:56.600736Z",
     "iopub.status.busy": "2024-03-09T13:22:56.599626Z",
     "iopub.status.idle": "2024-03-09T13:22:56.630766Z",
     "shell.execute_reply": "2024-03-09T13:22:56.629607Z",
     "shell.execute_reply.started": "2024-03-09T13:22:56.600650Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "corr = [0.0049279, 0.00445719, 0.0040318, 0.00364688, 0.00329375, 0.00297512, 0.00268571, 0.00242197, 0.00217813, 0.00195686, 0.00176504, 0.001597, 0.0014406, 0.00130362, 0.00117932, 0.00107197, 0.000971531, 0.000873839, 0.000783014, 0.000698531, 0.000622945, 0.000554938, 0.000497423, 0.000446639, 0.000400234, 0.000360026, 0.000325092, 0.00028936, 0.000252744, 0.000222755, 0.00019756, 0.000178826, 0.000169581, 0.000165766, 0.000161208, 0.000158499, 0.000157808, 0.000156267, 0.000155463, 0.000151827, 0.000137475, 0.000124214, 0.000113485, 0.000104859, 9.63436e-05, 8.8317e-05, 8.17296e-05, 7.9884e-05, 7.83747e-05, 8.01024e-05, 8.44507e-05, 8.01024e-05, 7.83747e-05, 7.9884e-05, 8.17296e-05, 8.8317e-05, 9.63436e-05, 0.000104859, 0.000113485, 0.000124214, 0.000137475, 0.000151827, 0.000155463, 0.000156267, 0.000157808, 0.000158499, 0.000161208, 0.000165766, 0.000169581, 0.000178826, 0.00019756, 0.000222755, 0.000252744, 0.00028936, 0.000325092, 0.000360026, 0.000400234, 0.000446639, 0.000497423, 0.000554938, 0.000622945, 0.000698531, 0.000783014, 0.000873839, 0.000971531, 0.00107197, 0.00117932, 0.00130362, 0.0014406, 0.001597, 0.00176504, 0.00195686, 0.00217813, 0.00242197, 0.00268571, 0.00297512, 0.00329375, 0.00364688, 0.0040318, 0.00445719, 0.0049279]\n",
    "g_rel_001=(100*np.array(corr))[:-1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1cd1e02d-0324-466a-b37e-a60554908a29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T13:23:04.103447Z",
     "iopub.status.busy": "2024-03-09T13:23:04.102339Z",
     "iopub.status.idle": "2024-03-09T13:23:04.120950Z",
     "shell.execute_reply": "2024-03-09T13:23:04.119380Z",
     "shell.execute_reply.started": "2024-03-09T13:23:04.103394Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "corr = [0.0482165, 0.0437875, 0.0397512, 0.0361339, 0.0328051, 0.0297607, 0.0270138, 0.0244825, 0.0222039, 0.0201489, 0.0183026, 0.0166458, 0.0151002, 0.0137192, 0.012421, 0.0112716, 0.0102497, 0.00931179, 0.0084281, 0.00763501, 0.00697282, 0.00637519, 0.00579578, 0.00524782, 0.00469027, 0.00419239, 0.00376016, 0.00335117, 0.00299975, 0.00265075, 0.00236496, 0.00215769, 0.00196452, 0.00178665, 0.00162977, 0.00148276, 0.00135563, 0.00127519, 0.00120796, 0.00115448, 0.0011155, 0.00109623, 0.00112555, 0.00113097, 0.00108849, 0.00108302, 0.00112726, 0.00115736, 0.00118966, 0.00124266, 0.00121678, 0.00124266, 0.00118966, 0.00115736, 0.00112726, 0.00108302, 0.00108849, 0.00113097, 0.00112555, 0.00109623, 0.0011155, 0.00115448, 0.00120796, 0.00127519, 0.00135563, 0.00148276, 0.00162977, 0.00178665, 0.00196452, 0.00215769, 0.00236496, 0.00265075, 0.00299975, 0.00335117, 0.00376016, 0.00419239, 0.00469027, 0.00524782, 0.00579578, 0.00637519, 0.00697282, 0.00763501, 0.0084281, 0.00931179, 0.0102497, 0.0112716, 0.012421, 0.0137192, 0.0151002, 0.0166458, 0.0183026, 0.0201489, 0.0222039, 0.0244825, 0.0270138, 0.0297607, 0.0328051, 0.0361339, 0.0397512, 0.0437875, 0.0482165]\n",
    "g_rel_01=(10*np.array(corr))[:-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "34a5ead7-10a1-445f-abbd-4f8c2478ccd1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T18:58:52.377057Z",
     "iopub.status.busy": "2024-03-09T18:58:52.375700Z",
     "iopub.status.idle": "2024-03-09T18:58:52.661598Z",
     "shell.execute_reply": "2024-03-09T18:58:52.660411Z",
     "shell.execute_reply.started": "2024-03-09T18:58:52.376968Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25260591796875\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#import sys\n",
    "#sys.path.append('../')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from NFconstants import N_nod, N_traj, NG_points,beta\n",
    "#from Value import G\n",
    "#import ensemble\n",
    "#from NFoscillator import basic_oscillator\n",
    "#from time import time\n",
    "#from NFandist import calc_G\n",
    "\n",
    "\"\"\"\n",
    "ens_nf=ensemble.ensemble.load(\"nf_ensemble.txt\",basic_oscillator)\n",
    "g_nf=np.vstack(ensemble.ensemble.Vaverage_and_sigma(ens_nf,G))\n",
    "g_nf=g_nf.transpose()[0]\n",
    "\"\"\"\n",
    "\n",
    "g=g_ur\n",
    "print(g_nf[0])\n",
    "fig=plt.figure()\n",
    "MCMC_list=np.arange(len(g))/len(g)\n",
    "NF_list=np.arange(len(g_nf))/len(g_nf)\n",
    "plt.scatter(MCMC_list,g)\n",
    "plt.scatter(NF_list,g_nf)\n",
    "plt.legend([\"MCMC\",\"normalizing flow\"])\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5537b59a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-04T01:13:45.448783Z",
     "iopub.status.busy": "2024-03-04T01:13:45.448099Z",
     "iopub.status.idle": "2024-03-04T01:13:45.746460Z",
     "shell.execute_reply": "2024-03-04T01:13:45.745700Z",
     "shell.execute_reply.started": "2024-03-04T01:13:45.448743Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11G\tlogs\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "! du -sh logs\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e1f7e3-4121-49e9-95f1-06ecbf041f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -rf logs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0937a257-cdff-4635-801c-dad1eb61f3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_flows(level_size,level_step=1):  # n_flows=8,...,12\n",
    "    flows=[]\n",
    "    n_levels=(N_latent-N_nod)//level_step\n",
    "    \n",
    "    if N_nod==N_latent:\n",
    "        level_step=0\n",
    "    \n",
    "    dim=N_latent//2\n",
    "    \n",
    "    for i in range(n_levels):\n",
    "        for k in range(level_size):\n",
    "            flows.append(AffineCouplingLayer(configure_theta(dim,dim),split=pair_SplitFunc,swap=k%2))\n",
    "        flows.append(nn.Linear(dim,dim-level_step//2))    \n",
    "        dim-=level_step//2    \n",
    "    \n",
    "    if dim!=N_nod//2:\n",
    "        print(\"smth wrong\")\n",
    "        \n",
    "    for k in range(level_size):\n",
    "        flows.append(AffineCouplingLayer(configure_theta(dim,dim),split=pair_SplitFunc,swap=k%2))\n",
    "    flows = nn.ModuleList(flows)\n",
    "    \n",
    "    return flows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67003bd9-b5df-4b89-bf8c-3fe1962ea74f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T22:17:57.203882Z",
     "iopub.status.busy": "2024-03-08T22:17:57.203532Z",
     "iopub.status.idle": "2024-03-08T22:18:00.912289Z",
     "shell.execute_reply": "2024-03-08T22:18:00.911495Z",
     "shell.execute_reply.started": "2024-03-08T22:17:57.203853Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "Normal(loc: torch.Size([100]), scale: torch.Size([100]))\n"
     ]
    }
   ],
   "source": [
    "print(\"start\")\n",
    "from Data import normal_dist\n",
    "\n",
    "def configure_theta():\n",
    "    theta=ThetaNetwork(\n",
    "                in_dim = N_nod//2,\n",
    "                out_dim = N_nod//2,\n",
    "                num_hidden = 16,  #2 to 6\n",
    "                hidden_dim = 2*N_nod , #100-1024\n",
    "                num_params = 2,\n",
    "                p_drop=0.4,\n",
    "    )\n",
    "    return theta\n",
    "\n",
    "def configure_flows(n_flows):  # n_flows=8,...,12\n",
    "    flows=[]\n",
    "    \n",
    "    flows.append(D(N_nod))\n",
    "    \n",
    "    for k in range(n_flows//4):\n",
    "        flows.append(AffineCouplingLayer(configure_theta(),split=pair_SplitFunc,swap=k%2))\n",
    "        flows.append(L1(N_nod))\n",
    "    \n",
    "    for k in range(3 * n_flows//4):\n",
    "        flows.append(AffineCouplingLayer(configure_theta(),split=pair_SplitFunc,swap=k%2))\n",
    "    \n",
    "    flows.append(D(N_nod))    \n",
    "    flows = nn.ModuleList(flows)\n",
    "    return flows \n",
    "\n",
    "def configure_conv_flows(n_conv,kernel_size=3):\n",
    "    conv_flows=[]\n",
    "    for i in range(n_conv):\n",
    "        conv_flows.append(AffineCouplingLayer(Conv_NN(N_nod//2,2,kernel_size),split=pair_SplitFunc,swap=i%2))\n",
    "    conv_flows = nn.ModuleList(conv_flows)\n",
    "    return conv_flows\n",
    "\n",
    "print(normal_dist)\n",
    "\n",
    "                  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
