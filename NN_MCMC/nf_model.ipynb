{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b6f0606-1240-4c92-81c2-26d92afd4fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, List, Tuple\n",
    "\n",
    "import lightning\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.distributions.distribution import Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16aa276b-e680-4426-86f3-adf6501168f1",
   "metadata": {},
   "source": [
    "# coupling layer\n",
    "based on\n",
    "\n",
    "https://lightning.ai/docs/pytorch/stable/notebooks/course_UvA-DL/09-normalizing-flows.html (VPN)\n",
    "\n",
    "https://sebastiancallh.github.io/post/affine-normalizing-flows/\n",
    "\n",
    "https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/tutorial11/NF_image_modeling.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42316e6e-6652-47f8-9e3b-8ff7144378e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AffineCouplingLayer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        theta: nn.Module,\n",
    "        split: Callable[[torch.Tensor], Tuple[torch.Tensor, torch.Tensor]],\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.theta = theta\n",
    "        self.split = split\n",
    "\n",
    "    def f(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"f : x -> z. The inverse of g.\"\"\"\n",
    "        x2, x1 = self.split(x)\n",
    "        t, s = self.theta(x1)\n",
    "        z1, z2 = x1, x2 * torch.exp(s) + t\n",
    "        log_det = s.sum(-1)\n",
    "        return torch.cat((z1, z2), dim=-1), log_det\n",
    "\n",
    "    def g(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"g : z -> x. The inverse of f.\"\"\"\n",
    "        z1, z2 = self.split(z)\n",
    "        t, s = self.theta(z1)\n",
    "        x1, x2 = z1, (z2 - t) * torch.exp(-s)\n",
    "        return torch.cat((x2, x1), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03443fee-33f8-40e3-b437-4b0795b8d0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormalizingFlow(nn.Module):\n",
    "    def __init__(self, latent: Distribution, flows: List[nn.Module]):\n",
    "        super().__init__()\n",
    "        self.latent = latent\n",
    "        self.flows = flows\n",
    "\n",
    "    def latent_log_prob(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        return self.latent.log_prob(z)\n",
    "\n",
    "    def latent_sample(self, num_samples: int = 1) -> torch.Tensor:\n",
    "        return self.latent.sample((num_samples,))\n",
    "\n",
    "    def sample(self, num_samples: int = 1) -> torch.Tensor:\n",
    "        \"\"\"Sample a new observation x by sampling z from\n",
    "        the latent distribution and pass through g.\"\"\"\n",
    "        return self.g(self.latent_sample(num_samples))\n",
    "\n",
    "    def f(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"Maps observation x to latent variable z.\n",
    "        Additionally, computes the log determinant\n",
    "        of the Jacobian for this transformation.\n",
    "        Inveres of g.\"\"\"\n",
    "        z, sum_log_abs_det = x, torch.ones(x.size(0)).to(x.device)\n",
    "        for flow in self.flows:\n",
    "            z, log_abs_det = flow.f(z)\n",
    "            sum_log_abs_det += log_abs_det\n",
    "\n",
    "        return z, sum_log_abs_det\n",
    "\n",
    "    def g(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Maps latent variable z to observation x.\n",
    "        Inverse of f.\"\"\"\n",
    "        with torch.no_grad():\n",
    "            x = z\n",
    "            for flow in reversed(self.flows):\n",
    "                x = flow.g(x)\n",
    "\n",
    "            return x\n",
    "\n",
    "    def g_steps(self, z: torch.Tensor) -> List[torch.Tensor]:\n",
    "        \"\"\"Maps latent variable z to observation x\n",
    "        and stores intermediate results.\"\"\"\n",
    "        xs = [z]\n",
    "        for flow in reversed(self.flows):\n",
    "            xs.append(flow.g(xs[-1]))\n",
    "\n",
    "        return xs\n",
    "\n",
    "    def log_prob(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Computes log p(x) using the change of variable formula.\"\"\"\n",
    "        z, log_abs_det = self.f(x)\n",
    "        return self.latent_log_prob(z) + log_abs_det\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.flows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "25159255-2cf2-4250-a9c1-947ae708a30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThetaNetwork(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_dim: int,\n",
    "        out_dim: int,\n",
    "        num_hidden: int,\n",
    "        hidden_dim: int,\n",
    "        num_params: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.input = nn.Linear(in_dim, hidden_dim)\n",
    "        self.hidden = nn.ModuleList(\n",
    "            [nn.Linear(hidden_dim, hidden_dim) for _ in range(num_hidden)]\n",
    "        )\n",
    "\n",
    "        self.num_params = num_params\n",
    "        self.out_dim = out_dim\n",
    "        self.dims = nn.Linear(hidden_dim, out_dim * num_params)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = F.leaky_relu(self.input(x))\n",
    "        for h in self.hidden:\n",
    "            x = F.leaky_relu(h(x))\n",
    "\n",
    "        batch_params = self.dims(x).reshape(x.size(0), self.out_dim, -1)\n",
    "        params = batch_params.chunk(self.num_params, dim=-1)\n",
    "        return [p.squeeze(-1) for p in params]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "329bdd72-6284-4ac3-ad35-100815e1144f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SplitFunc(x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba84a286-ae41-4bb8-9727-2ab45356fe51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NormalizingFlow()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NormalizingFlow(\n",
    "    latent=torch.distributions.Normal(loc=0.0, scale=1.),\n",
    "    flows=[\n",
    "        AffineCouplingLayer(\n",
    "            theta=ThetaNetwork(\n",
    "                in_dim = 42,\n",
    "                out_dim = 42,\n",
    "                num_hidden = 42,\n",
    "                hidden_dim = 42,\n",
    "                num_params = 42\n",
    "            ),\n",
    "            split=SplitFunc\n",
    "        ),\n",
    "        AffineCouplingLayer(\n",
    "            theta=ThetaNetwork(\n",
    "                in_dim = 42,\n",
    "                out_dim = 42,\n",
    "                num_hidden = 42,\n",
    "                hidden_dim = 42,\n",
    "                num_params = 42\n",
    "            ),\n",
    "            split=SplitFunc\n",
    "        ),\n",
    "        AffineCouplingLayer(\n",
    "            theta=ThetaNetwork(\n",
    "                in_dim = 42,\n",
    "                out_dim = 42,\n",
    "                num_hidden = 42,\n",
    "                hidden_dim = 42,\n",
    "                num_params = 42\n",
    "            ),\n",
    "            split=SplitFunc\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f011c22-51f7-4f8d-99e7-2566ce09931c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
